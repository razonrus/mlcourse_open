{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# загрузим обучающую и тестовую выборки\n",
    "train_df = pd.read_csv('../../data/train_sessions.csv',\n",
    "                       index_col='session_id')\n",
    "test_df = pd.read_csv('../../data/test_sessions.csv',\n",
    "                      index_col='session_id')\n",
    "\n",
    "# приведем колонки time1, ..., time10 к временному формату\n",
    "times = ['time%s' % i for i in range(1, 11)]\n",
    "train_df[times] = train_df[times].apply(pd.to_datetime)\n",
    "test_df[times] = test_df[times].apply(pd.to_datetime)\n",
    "\n",
    "# отсортируем данные по времени\n",
    "train_df = train_df.sort_values(by='time1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "всего сайтов: 48371\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>site</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25075</th>\n",
       "      <td>www.abmecatronique.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13997</th>\n",
       "      <td>groups.live.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42436</th>\n",
       "      <td>majeureliguefootball.wordpress.com</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30911</th>\n",
       "      <td>cdt46.media.tourinsoft.eu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8104</th>\n",
       "      <td>www.hdwallpapers.eu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     site\n",
       "25075              www.abmecatronique.com\n",
       "13997                     groups.live.com\n",
       "42436  majeureliguefootball.wordpress.com\n",
       "30911           cdt46.media.tourinsoft.eu\n",
       "8104                  www.hdwallpapers.eu"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# приведем колонки site1, ..., site10 к целочисленному формату и заменим пропуски нулями\n",
    "sites = ['site%s' % i for i in range(1, 11)]\n",
    "train_df[sites] = train_df[sites].fillna(0).astype('int')\n",
    "test_df[sites] = test_df[sites].fillna(0).astype('int')\n",
    "\n",
    "# загрузим словарик сайтов\n",
    "with open(r\"../../data/site_dic.pkl\", \"rb\") as input_file:\n",
    "    site_dict = pickle.load(input_file)\n",
    "\n",
    "# датафрейм словарика сайтов\n",
    "sites_dict_df = pd.DataFrame(list(site_dict.keys()), \n",
    "                          index=list(site_dict.values()), \n",
    "                          columns=['site'])\n",
    "\n",
    "print(u'всего сайтов:', sites_dict_df.shape[0])\n",
    "\n",
    "sites_dict_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# наша целевая переменная\n",
    "y_train = train_df['target']\n",
    "\n",
    "# объединенная таблица исходных данных\n",
    "full_df = pd.concat([train_df.drop('target', axis=1), test_df])\n",
    "\n",
    "# индекс, по которому будем отделять обучающую выборку от тестовой\n",
    "idx_split = train_df.shape[0]\n",
    "\n",
    "sites = ['site%d' % i for i in range(1, 11)]\n",
    "\n",
    "full_sites = full_df[sites]\n",
    "\n",
    "# последовательность с индексами\n",
    "sites_flatten = full_sites.values.flatten()\n",
    "\n",
    "# искомая матрица\n",
    "full_sites_sparse = csr_matrix(([1] * sites_flatten.shape[0],\n",
    "                                sites_flatten,\n",
    "                                range(0, sites_flatten.shape[0] + 10, 10)))[:, 1:]\n",
    "\n",
    "X_train_sparse = full_sites_sparse[:idx_split]\n",
    "X_test_sparse = full_sites_sparse[idx_split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split, GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_auc_lr_valid(X, y, C=1.0, ratio = 0.9, seed=17):\n",
    "    '''\n",
    "    X, y – выборка\n",
    "    ratio – в каком отношении поделить выборку\n",
    "    C, seed – коэф-т регуляризации и random_state \n",
    "              логистической регрессии\n",
    "    '''\n",
    " #   train_len = int(ratio * X.shape[0])\n",
    " #   X_train = X[:train_len, :]\n",
    " #   X_valid = X[train_len:, :]\n",
    " #   y_train = y[:train_len]\n",
    "#    y_valid = y[train_len:]\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=1-ratio,random_state=seed)\n",
    "    logit = LogisticRegression(C=C, n_jobs=-1, random_state=seed)\n",
    "    \n",
    "    logit.fit(X_train, y_train)\n",
    "    \n",
    "    valid_pred = logit.predict_proba(X_valid)[:, 1]\n",
    "    \n",
    "    return roc_auc_score(y_valid, valid_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96433761440091936"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_auc_lr_valid(X_train_sparse, y_train, ratio = 0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# функция для записи прогнозов в файл\n",
    "def write_to_submission_file(predicted_labels, out_file,\n",
    "                             target='target', index_label=\"session_id\"):\n",
    "    predicted_df = pd.DataFrame(predicted_labels,\n",
    "                                index = np.arange(1, predicted_labels.shape[0] + 1),\n",
    "                                columns=[target])\n",
    "    predicted_df.to_csv(out_file, index_label=index_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_feat_train = pd.DataFrame(index=train_df.index)\n",
    "new_feat_test = pd.DataFrame(index=test_df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_feat_train['alice_tminutes'] = train_df['time1'].apply(lambda ts: 1 if (ts.hour*60+ts.minute >= 723 and ts.hour*60+ts.minute <=832) or (ts.hour*60+ts.minute >= 954 and ts.hour*60+ts.minute <=1100) else 0)\n",
    "new_feat_test['alice_tminutes'] = test_df['time1'].apply(lambda ts: 1 if (ts.hour*60+ts.minute >= 723 and ts.hour*60+ts.minute <=832) or (ts.hour*60+ts.minute >= 954 and ts.hour*60+ts.minute <=1100) else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_sparse_alicemin = csr_matrix(hstack([X_train_sparse, \n",
    "                             new_feat_train['alice_tminutes'].values.reshape(-1, 1)]))\n",
    "X_test_sparse_alicemin  = csr_matrix(hstack([X_test_sparse, \n",
    "                             new_feat_test['alice_tminutes'].values.reshape(-1, 1)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98650035989731588"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_auc_lr_valid(X_train_sparse_alicemin, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_feat_train['alice_tminutes2'] = train_df['time1'].apply(lambda ts: 1 if (ts.hour*60+ts.minute >= 723 and ts.hour*60+ts.minute <=832) or (ts.hour*60+ts.minute >= 954 and ts.hour*60+ts.minute <=1100) or (ts.hour*60+ts.minute >= 548 and ts.hour*60+ts.minute <=559) else 0)\n",
    "new_feat_test['alice_tminutes2'] = test_df['time1'].apply(lambda ts: 1 if (ts.hour*60+ts.minute >= 723 and ts.hour*60+ts.minute <=832) or (ts.hour*60+ts.minute >= 954 and ts.hour*60+ts.minute <=1100) or (ts.hour*60+ts.minute >= 548 and ts.hour*60+ts.minute <=559) else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_sparse_alicemin2 = csr_matrix(hstack([X_train_sparse, \n",
    "                             new_feat_train['alice_tminutes2'].values.reshape(-1, 1)]))\n",
    "X_test_sparse_alicemin2  = csr_matrix(hstack([X_test_sparse, \n",
    "                             new_feat_test['alice_tminutes2'].values.reshape(-1, 1)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98708576028395223"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_auc_lr_valid(X_train_sparse_alicemin2, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_feat_train['day0'] = train_df['time1'].apply(lambda ts: 1 if ts.weekday()==0 else 0)\n",
    "new_feat_test['day0'] = test_df['time1'].apply(lambda ts: 1 if ts.weekday()==0 else 0)\n",
    "\n",
    "new_feat_train['day1'] = train_df['time1'].apply(lambda ts: 1 if ts.weekday()==1 else 0)\n",
    "new_feat_test['day1'] = test_df['time1'].apply(lambda ts: 1 if ts.weekday()==1 else 0)\n",
    "\n",
    "new_feat_train['day2'] = train_df['time1'].apply(lambda ts: 1 if ts.weekday()==2 else 0)\n",
    "new_feat_test['day2'] = test_df['time1'].apply(lambda ts: 1 if ts.weekday()==2 else 0)\n",
    "\n",
    "new_feat_train['day3'] = train_df['time1'].apply(lambda ts: 1 if ts.weekday()==3 else 0)\n",
    "new_feat_test['day3'] = test_df['time1'].apply(lambda ts: 1 if ts.weekday()==3 else 0)\n",
    "\n",
    "new_feat_train['day4'] = train_df['time1'].apply(lambda ts: 1 if ts.weekday()==4 else 0)\n",
    "new_feat_test['day4'] = test_df['time1'].apply(lambda ts: 1 if ts.weekday()==4 else 0)\n",
    "\n",
    "new_feat_train['day5'] = train_df['time1'].apply(lambda ts: 1 if ts.weekday()==5 else 0)\n",
    "new_feat_test['day5'] = test_df['time1'].apply(lambda ts: 1 if ts.weekday()==5 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_sparse_alicemin2_dayall = csr_matrix(hstack([X_train_sparse_alicemin2, \n",
    "                            new_feat_train['day0'].values.reshape(-1, 1),\n",
    "                            new_feat_train['day1'].values.reshape(-1, 1),\n",
    "                            new_feat_train['day2'].values.reshape(-1, 1),\n",
    "                            new_feat_train['day3'].values.reshape(-1, 1),\n",
    "                            new_feat_train['day4'].values.reshape(-1, 1),\n",
    "                            new_feat_train['day5'].values.reshape(-1, 1)\n",
    "                                                                                  ]\n",
    "                                                      ))\n",
    "X_test_sparse_alicemin2_dayall = csr_matrix(hstack([X_test_sparse_alicemin2, \n",
    "                            new_feat_test['day0'].values.reshape(-1, 1),\n",
    "                            new_feat_test['day1'].values.reshape(-1, 1),\n",
    "                            new_feat_test['day2'].values.reshape(-1, 1),\n",
    "                            new_feat_test['day3'].values.reshape(-1, 1),\n",
    "                            new_feat_test['day4'].values.reshape(-1, 1),\n",
    "                            new_feat_test['day5'].values.reshape(-1, 1)\n",
    "                                                                                 ]\n",
    "                                                      ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9910118176175845"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_auc_lr_valid(X_train_sparse_alicemin2_dayall, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9910118176175845"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_auc_lr_valid(X_train_sparse_alicemin2_dayall, y_train, ratio=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_feat_train['alice_morning_minutes'] = train_df['time1'].apply(lambda ts: 1 if (ts.hour*60+ts.minute >= 548 and ts.hour*60+ts.minute <=559) else 0)\n",
    "new_feat_test['alice_morning_minutes'] = test_df['time1'].apply(lambda ts: 1 if (ts.hour*60+ts.minute >= 548 and ts.hour*60+ts.minute <=559) else 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_sparse_alicemin2_dayall_morningMinutes = csr_matrix(hstack([X_train_sparse_alicemin2_dayall, \n",
    "                             new_feat_train['alice_morning_minutes'].values.reshape(-1, 1)]))\n",
    "X_test_sparse_alicemin2_dayall_morningMinutes = csr_matrix(hstack([X_test_sparse_alicemin2_dayall, \n",
    "                             new_feat_test['alice_morning_minutes'].values.reshape(-1, 1)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99119403526923877"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_auc_lr_valid(X_train_sparse_alicemin2_dayall_morningMinutes, y_train, ratio=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df['months_count'] = train_df['time1'].apply(lambda ts: 12 * ts.year + ts.month)\n",
    "test_df['months_count'] = test_df['time1'].apply(lambda ts: 12 * ts.year + ts.month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99287326517974273"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_auc_lr_valid(X_train_sparse_alicemin2_dayall_alicem3, y_train, ratio=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alice_tminutes</th>\n",
       "      <th>alice_tminutes2</th>\n",
       "      <th>day0</th>\n",
       "      <th>day1</th>\n",
       "      <th>day2</th>\n",
       "      <th>day3</th>\n",
       "      <th>day4</th>\n",
       "      <th>day5</th>\n",
       "      <th>alice_morning_minutes</th>\n",
       "      <th>months_count</th>\n",
       "      <th>alice_month_24165</th>\n",
       "      <th>alice_month_24167</th>\n",
       "      <th>alice_month_24169</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>session_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21669</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>24157</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54843</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>24157</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77292</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>24157</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114021</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>24157</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146670</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>24157</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            alice_tminutes  alice_tminutes2  day0  day1  day2  day3  day4  \\\n",
       "session_id                                                                  \n",
       "21669                    0                0     0     0     0     0     0   \n",
       "54843                    0                0     0     0     0     0     0   \n",
       "77292                    0                0     0     0     0     0     0   \n",
       "114021                   0                0     0     0     0     0     0   \n",
       "146670                   0                0     0     0     0     0     0   \n",
       "\n",
       "            day5  alice_morning_minutes  months_count  alice_month_24165  \\\n",
       "session_id                                                                 \n",
       "21669          1                      0         24157              False   \n",
       "54843          1                      0         24157              False   \n",
       "77292          1                      0         24157              False   \n",
       "114021         1                      0         24157              False   \n",
       "146670         1                      0         24157              False   \n",
       "\n",
       "            alice_month_24167  alice_month_24169  \n",
       "session_id                                        \n",
       "21669                   False              False  \n",
       "54843                   False              False  \n",
       "77292                   False              False  \n",
       "114021                  False              False  \n",
       "146670                  False              False  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_feat_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_feat_train['september'] = train_df['time1'].apply(lambda ts: 1 if ts.month == 9 else 0)\n",
    "new_feat_test['september'] = test_df['time1'].apply(lambda ts: 1 if ts.month == 9 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_sparse_alicemin2_dayall_september = csr_matrix(hstack([X_train_sparse_alicemin2_dayall, \n",
    "                             new_feat_train['september'].values.reshape(-1, 1)]\n",
    "                                                      ))\n",
    "X_test_sparse_alicemin2_dayall_september  = csr_matrix(hstack([X_test_sparse_alicemin2_dayall, \n",
    "                              new_feat_test['september'].values.reshape(-1, 1)]\n",
    "                                                      ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99286401466677554"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_auc_lr_valid(X_train_sparse_alicemin2_dayall_alicem3_september, y_train, ratio=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=-1,\n",
       "          penalty='l2', random_state=17, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit = LogisticRegression(n_jobs=-1, random_state=17)\n",
    "logit.fit(X_train_sparse_alicemin2_dayall_alicem3, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_pred = logit.predict_proba(X_test_sparse_alicemin2_dayall_alicem3)[:, 1]\n",
    "write_to_submission_file(test_pred, 'X_train_sparse_alicemin2_dayall_alicem3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time_split = TimeSeriesSplit(n_splits=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "cv_scores = cross_val_score(logit, X_train_sparse_alicemin2_dayall_alicem3, y_train, cv=time_split, \n",
    "                            scoring='roc_auc', n_jobs=2) # hangs with n_jobs > 1, and locally this runs much faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import libraries and set desired options\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import TimeSeriesSplit, cross_val_score, GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.91835528,  0.90208338,  0.93181089,  0.97220051,  0.9355704 ,\n",
       "         0.97387076,  0.89001493,  0.96327636,  0.92910777,  0.98050606]),\n",
       " 0.9396796338729283)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_scores, cv_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 9s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "cv_scores = cross_val_score(logit, X_train_sparse_alicemin2_dayall_alicem3_september, y_train, cv=time_split, \n",
    "                            scoring='roc_auc', n_jobs=-1) # hangs with n_jobs > 1, and locally this runs much faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.92372709,  0.90397435,  0.93229476,  0.97240024,  0.93274822,\n",
       "         0.97392226,  0.88915592,  0.96335468,  0.92938396,  0.98052435]),\n",
       " 0.94014858373416565)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_scores, cv_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_sparse_alicemin2_dayall_september_morningMinutes = csr_matrix(hstack([X_train_sparse_alicemin2_dayall_september, \n",
    "                             new_feat_train['alice_morning_minutes'].values.reshape(-1, 1)]))\n",
    "X_test_sparse_alicemin2_dayall_september_morningMinutes = csr_matrix(hstack([X_test_sparse_alicemin2_dayall_september, \n",
    "                             new_feat_test['alice_morning_minutes'].values.reshape(-1, 1)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "cv_scores = cross_val_score(logit, X_train_sparse_alicemin2_dayall_alicem3_september_morningMinutes, y_train, cv=time_split, \n",
    "                            scoring='roc_auc', n_jobs=-1) # hangs with n_jobs > 1, and locally this runs much faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.91644317,  0.90382931,  0.93308655,  0.97293213,  0.93392838,\n",
       "         0.97505073,  0.8887795 ,  0.96575999,  0.93118757,  0.98118046]),\n",
       " 0.94021777941825613)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_scores, cv_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df['start_hour'] = train_df['time1'].apply(lambda ts: ts.hour)\n",
    "test_df['start_hour'] = test_df['time1'].apply(lambda ts: ts.hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df['month'] = train_df['time1'].apply(lambda ts: ts.month)\n",
    "test_df['month'] = test_df['time1'].apply(lambda ts: ts.month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x185d8ac8>"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfIAAAFXCAYAAABZQMyNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3X1YlHXi7/HPwDBEPChePuTJ8ClNk0O6mdbP9TENbbPM\nTYyxcRN3Sy5NpTIRH1tEc/2Fq+ZTrrvtQYsl9RRtXv1KDuU5StTazwiMMlIra73QUJmxHRTn/NEV\nq5Q4mDfDd3y//mLuueeez1cHPvO9577vsfl8Pp8AAICRQgIdAAAAXD6KHAAAg1HkAAAYjCIHAMBg\nFDkAAAajyAEAMJg90AEuR2VldaAjAADQZNq0ib7ofZbOyI8fP67BgweroqJChw8fVnJyspxOpxYu\nXKhz585JkvLy8jR27FglJSWpsLDQyjgAAAQdy4r8zJkzWrBgga655hpJ0tKlSzVz5ky9+OKL8vl8\nKigoUGVlpXJycpSbm6tNmzYpOztbNTU1VkUCACDoWFbky5Yt04MPPqi2bdtKksrKytSvXz9J0qBB\ng7Rnzx6VlJSoT58+cjgcio6OVlxcnMrLy62KBABA0LHkM/Lt27erVatWGjhwoJ5//nlJks/nk81m\nkyRFRkaqurpabrdb0dH/3u8fGRkpt9t9ye3Hxl4ruz3UiugAABjFkiLftm2bbDabioqK9PHHH2v2\n7Nn69ttv6+73eDyKiYlRVFSUPB7PBcvPL/aLqao6bUVsAACapSY/2G3Lli3avHmzcnJy1LNnTy1b\ntkyDBg1ScXGxJGnXrl3q27evEhIStHfvXnm9XlVXV6uiokLdu3e3IhIAAEGpyU4/mz17tubPn6/s\n7Gx16dJFiYmJCg0NlcvlktPplM/nU1pamsLDw5sqEgAAxrOZ+DWmnEcOALiaBOw8cgAATHPq1Em9\n887/uaLbzM//31d0e+ejyAEAOM9nnx3Qe++9e0W3mZu7+Ypu73xGXqIVAACrvPRSjj799BP94hd9\n9eqr21VbW6vIyEgtXfqsXnjhTyotLZHX69XTTy/R00/Pk81mU4sWLdW5cxelpDyilSv/UwcOfCpJ\nmj79CR08WKGjR/+pP/whS089NfeK52VGDgDAeZKTXfrlLwfpxIkqPfPMs1qzZqNqa8/p8OFDkqT4\n+AStXfsnbdnyV40dm6TVqzeoc+cukqTdu/+vzp49qzVrNmrRoiytWvWsRo78ldq1u86SEpeYkQMA\n8JNatmylpUszFRERoaNH/6na2rOSpBtu6ChJ+uKLL/Tggw9Jknr1+p8qK/tIhw8f1H//915Nm/aI\nJOnkyZOW56TIAaCJzFieH+gIF7Vy1r2BjtBs2Gw2nTvn0/r1q/XSS9/vWv/tb1364SSvkJDvr1La\nqVMnffxxma67rr0+/rhM0vclP3DgEE2ZMk0ej1tbt/5NkmTlCWLsWgcA4DzXX99BH320T5I0ebJL\nM2emqkWLljp+/NgF602Y8Bu98sp2zZiRqtLSjxQaGqqBAwfL7XZr2rRHNG3aI3Wz9x49btaCBXMs\nyct55ADQRJiRB5c9e/6frruuvbp06aq//GWj2rW7TnffPdqS52roPHJ2rQMAcBnatGmjJUuelsPh\nUMuWsUpOdgUkB0UOAMBl6NbtJv3pT/8r0DH4jBwAAJNR5AAAGIwiBwDAYBQ5AAAG42A3AMBV60qf\nEujvaXxlZaVat26Vnnvu+Z/9nBQ5AABNaMuWv+q//muHrrkm4opsj13rAAA0oeuv76CsrOVXbHsU\nOQAATWjIkDtlt1+5HeIUOQAABqPIAQAwGEUOAIDBOGodAHDVCtS3vrVv/z/0/PMvXJFtMSMHAMBg\nFDkAAAajyAEAMBhFDgCAwShyAAAMRpEDAGAwihwAAINZdh55bW2t5s2bp4MHD8pms+npp5/W2bNn\n9eijj6pTp06SpOTkZN19993Ky8tTbm6u7Ha7UlNTNXToUKtiAQAQVCwr8sLCQklSbm6uiouLtWLF\nCg0bNkyTJk1SSkpK3XqVlZXKycnRtm3b5PV65XQ6NWDAADkcDquiAQAQNCwr8uHDh2vIkCGSpK+/\n/loxMTEqLS3VwYMHVVBQoI4dOyojI0MlJSXq06ePHA6HHA6H4uLiVF5eroSEBKuiAQAQNCy9RKvd\nbtfs2bP11ltvadWqVTp69KjGjRun+Ph4rVu3TmvWrFGPHj0UHR1d95jIyEi53e4Gtxsbe63s9lAr\nowPAVaVNm+hLr4RmyfJrrS9btkxPPvmkkpKSlJubq3bt2kmSRowYoczMTPXt21cej6dufY/Hc0Gx\n/5SqqtOWZgaAq01lZXWgI6ABDb3Rsuyo9VdeeUUbNmyQJEVERMhms2natGkqKSmRJBUVFalXr15K\nSEjQ3r175fV6VV1drYqKCnXv3t2qWAAABBXLZuR33XWX5syZowkTJujs2bPKyMhQ+/btlZmZqbCw\nMLVu3VqZmZmKioqSy+WS0+mUz+dTWlqawsPDrYoFAEBQsfl8Pl+gQzQWu4AAmGjG8vxAR7ioQH2d\nJ/wTkF3rAADAehQ5AAAGo8gBADAYRQ4AgMEocgAADEaRAwBgMIocAACDUeQAABiMIgcAwGAUOQAA\nBqPIAQAwGEUOAIDBKHIAAAxGkQMAYDCKHAAAg1HkAAAYjCIHAMBgFDkAAAajyAEAMBhFDgCAwShy\nAAAMRpEDAGAwihwAAINR5AAAGIwiBwDAYBQ5AAAGo8gBADAYRQ4AgMEocgAADGa3asO1tbWaN2+e\nDh48KJvNpqefflrh4eFKT0+XzWZTt27dtHDhQoWEhCgvL0+5ubmy2+1KTU3V0KFDrYoFAEBQsazI\nCwsLJUm5ubkqLi7WihUr5PP5NHPmTPXv318LFixQQUGBevfurZycHG3btk1er1dOp1MDBgyQw+Gw\nKhoAAEHDsiIfPny4hgwZIkn6+uuvFRMToz179qhfv36SpEGDBmn37t0KCQlRnz595HA45HA4FBcX\np/LyciUkJFgVDQCAoGFZkUuS3W7X7Nmz9dZbb2nVqlXavXu3bDabJCkyMlLV1dVyu92Kjo6ue0xk\nZKTcbneD242NvVZ2e6iV0QHgqtKmTfSlV0KzZGmRS9KyZcv05JNPKikpSV6vt265x+NRTEyMoqKi\n5PF4Llh+frH/lKqq05blBYCrUWVldaAjoAENvdGy7Kj1V155RRs2bJAkRUREyGazKT4+XsXFxZKk\nXbt2qW/fvkpISNDevXvl9XpVXV2tiooKde/e3apYAAAEFctm5HfddZfmzJmjCRMm6OzZs8rIyFDX\nrl01f/58ZWdnq0uXLkpMTFRoaKhcLpecTqd8Pp/S0tIUHh5uVSwAAIKKzefz+QIdorHYBQTARDOW\n5wc6wkWtnHVvoCOgAQHZtQ4AAKxHkQMAYDCKHAAAg1HkAAAYjCIHAMBgFDkAAAajyAEAMBhFDgCA\nwShyAAAMRpEDAGAwihwAAINR5AAAGIwiBwDAYBQ5AAAGo8gBADAYRQ4AgMEocgAADEaRAwBgMIoc\nAACDUeQAABiMIgcAwGAUOQAABqPIAQAwGEUOAIDBKHIAAAxGkQMAYDCKHAAAg1HkAAAYjCIHAMBg\ndis2eubMGWVkZOjIkSOqqalRamqq2rdvr0cffVSdOnWSJCUnJ+vuu+9WXl6ecnNzZbfblZqaqqFD\nh1oRCQCAoGRJkefn56tly5Zavny5Tpw4oTFjxmjq1KmaNGmSUlJS6tarrKxUTk6Otm3bJq/XK6fT\nqQEDBsjhcFgRCwCAoGNJkY8cOVKJiYmSJJ/Pp9DQUJWWlurgwYMqKChQx44dlZGRoZKSEvXp00cO\nh0MOh0NxcXEqLy9XQkKCFbEAAD/TjOX5gY7QoJWz7g10hCZnSZFHRkZKktxut6ZPn66ZM2eqpqZG\n48aNU3x8vNatW6c1a9aoR48eio6OvuBxbrf7ktuPjb1WdnuoFdEB4KrUpk30pVcyQLCMozEsKXJJ\n+uabbzR16lQ5nU6NHj1ap06dUkxMjCRpxIgRyszMVN++feXxeOoe4/F4Lij2i6mqOm1VbAC4KlVW\nVgc6whURLOOor6E3KJYctX7s2DGlpKRo1qxZeuCBByRJkydPVklJiSSpqKhIvXr1UkJCgvbu3Suv\n16vq6mpVVFSoe/fuVkQCACAoWTIjX79+vU6dOqW1a9dq7dq1kqT09HQtWbJEYWFhat26tTIzMxUV\nFSWXyyWn0ymfz6e0tDSFh4dbEQkAgKBk8/l8vkCHaKxg3XUCILg15wPF/D1IrDmPQQreg92afNc6\nAABoGhQ5AAAGo8gBADAYRQ4AgMEocgAADEaRAwBgMIocAACDUeQAABiMIgcAwGAUOQAABqPIAQAw\nGEUOAIDBKHIAAAxGkQMAYDCKHAAAg1HkAAAYjCIHAMBgFDkAAAbzq8gzMzN/tGz27NlXPAwAAGgc\ne0N3zp07V19++aVKS0t14MCBuuVnz55VdXW15eEAAEDDGizy1NRUHTlyRFlZWZo2bVrd8tDQUHXt\n2tXycAAAoGENFnmHDh3UoUMH5efny+12q7q6Wj6fT5J0+vRptWzZsklCAgCAn9Zgkf9gw4YN2rBh\nwwXFbbPZVFBQYFkwAABwaX4V+csvv6ydO3eqVatWVucBAACN4NdR6+3bt1eLFi2szgIAABrJrxl5\np06d5HQ61b9/fzkcjrrl5x8ABwAAmp5fRd6uXTu1a9fO6iwAAKCR/CpyZt4AADRPfhV5jx49ZLPZ\nLljWtm1bvfPOO5aEAgAA/vGryMvLy+t+PnPmjHbu3Kl9+/ZddP0zZ84oIyNDR44cUU1NjVJTU3Xj\njTcqPT1dNptN3bp108KFCxUSEqK8vDzl5ubKbrcrNTVVQ4cO/fmjAgDgKuFXkZ8vLCxMo0aN0vr1\n6y+6Tn5+vlq2bKnly5frxIkTGjNmjHr06KGZM2eqf//+WrBggQoKCtS7d2/l5ORo27Zt8nq9cjqd\nGjBgwAUH1AEAgIvzq8hfeeWVup99Pp8OHDigsLCwi64/cuRIJSYm1q0fGhqqsrIy9evXT5I0aNAg\n7d69WyEhIerTp48cDoccDofi4uJUXl6uhISEnzMmAACuGn4VeXFx8QW3Y2NjtWLFiouuHxkZKUly\nu92aPn26Zs6cqWXLltV9zh4ZGanq6mq53W5FR0df8Di3233JPLGx18puD/UnOgDAD23aRF96JQME\nyzgaw68iX7p0qc6cOaODBw+qtrZW3bp1k93e8EO/+eYbTZ06VU6nU6NHj9by5cvr7vN4PIqJiVFU\nVJQ8Hs8Fy88v9oupqjrtT2wAgJ8qK4PjGy2DZRz1NfQGxa8iLy0t1fTp09WyZUudO3dOx44d05o1\na3TLLbf85PrHjh1TSkqKFixYoDvuuEOSdPPNN6u4uFj9+/fXrl27dPvttyshIUF//OMf5fV6VVNT\no4qKCnXv3v0yhggAwNXJryJfvHixVqxYUVfc+/btU2ZmprZu3fqT669fv16nTp3S2rVrtXbtWknf\nf7f54sWLlZ2drS5duigxMVGhoaFyuVxyOp3y+XxKS0tTeHj4FRoaAADBz68iP3369AWz7969e8vr\n9V50/Xnz5mnevHk/Wr558+YfLUtKSlJSUpI/MQAAQD1+fWlKixYttHPnzrrbO3fu5LvIAQBoBvya\nkWdmZurRRx/V3Llz65bl5uZaFgoAAPjHrxn5rl27FBERocLCQv31r39Vq1at9N5771mdDQAAXIJf\nM/K8vDy9/PLLioiIUI8ePbR9+3YlJSVp/PjxVueDgWYszw90hAatnHVvoCMAwBXj14z8zJkzF1zJ\nraGrugEAgKbj14x8+PDh+s1vfqNRo0ZJkt58803deeedlgYDAACX5leRz5o1S2+88Ybef/992e12\nTZw4UcOHD7c6GwAAuAS/v/1s5MiRGjlypJVZAABAI/n1GTkAAGieKHIAAAxGkQMAYDCKHAAAg1Hk\nAAAYjCIHAMBgFDkAAAajyAEAMBhFDgCAwShyAAAMRpEDAGAwihwAAINR5AAAGIwiBwDAYBQ5AAAG\no8gBADAYRQ4AgMEocgAADEaRAwBgMIocAACDWVrkH374oVwulyRp//79GjhwoFwul1wul3bs2CFJ\nysvL09ixY5WUlKTCwkIr4wAAEHTsVm1448aNys/PV0REhCSprKxMkyZNUkpKSt06lZWVysnJ0bZt\n2+T1euV0OjVgwAA5HA6rYgEAEFQsm5HHxcVp9erVdbdLS0v19ttva8KECcrIyJDb7VZJSYn69Okj\nh8Oh6OhoxcXFqby83KpIAAAEHctm5ImJifrqq6/qbickJGjcuHGKj4/XunXrtGbNGvXo0UPR0dF1\n60RGRsrtdl9y27Gx18puD7UkN4JfmzbRl14JuMoEy+9FsIyjMSwr8vpGjBihmJiYup8zMzPVt29f\neTyeunU8Hs8FxX4xVVWnLcuJ4FdZWR3oCECzEyy/F8EyjvoaeoPSZEetT548WSUlJZKkoqIi9erV\nSwkJCdq7d6+8Xq+qq6tVUVGh7t27N1UkAACM12Qz8kWLFikzM1NhYWFq3bq1MjMzFRUVJZfLJafT\nKZ/Pp7S0NIWHhzdVJAAAjGdpkXfo0EF5eXmSpF69eik3N/dH6yQlJSkpKcnKGAAABC0uCAMAgMGa\nbNc6YJoZy/MDHaFBK2fdG+gIAJoBZuQAABiMIgcAwGAUOQAABqPIAQAwGEUOAIDBKHIAAAxGkQMA\nYDCKHAAAg1HkAAAYjCIHAMBgFDkAAAajyAEAMBhFDgCAwShyAAAMRpEDAGAwihwAAINR5AAAGIwi\nBwDAYBQ5AAAGo8gBADAYRQ4AgMEocgAADEaRAwBgMIocAACDUeQAABiMIgcAwGAUOQAABrO0yD/8\n8EO5XC5J0uHDh5WcnCyn06mFCxfq3LlzkqS8vDyNHTtWSUlJKiwstDIOAABBx7Ii37hxo+bNmyev\n1ytJWrp0qWbOnKkXX3xRPp9PBQUFqqysVE5OjnJzc7Vp0yZlZ2erpqbGqkgAAAQdy4o8Li5Oq1ev\nrrtdVlamfv36SZIGDRqkPXv2qKSkRH369JHD4VB0dLTi4uJUXl5uVSQAAIKO3aoNJyYm6quvvqq7\n7fP5ZLPZJEmRkZGqrq6W2+1WdHR03TqRkZFyu92X3HZs7LWy20OvfGhcFdq0ib70SgYIlnGgeQiW\n11OwjKMxLCvy+kJC/j3593g8iomJUVRUlDwezwXLzy/2i6mqOm1JRlwdKiurAx3higiWcaB5CJbX\nU7CMo76G3qA02VHrN998s4qLiyVJu3btUt++fZWQkKC9e/fK6/WqurpaFRUV6t69e1NFAgDAeE02\nI589e7bmz5+v7OxsdenSRYmJiQoNDZXL5ZLT6ZTP51NaWprCw8ObKhIAAMaztMg7dOigvLw8SVLn\nzp21efPmH62TlJSkpKQkK2MAABC0uCAMAAAGo8gBADAYRQ4AgMEocgAADEaRAwBgMIocAACDUeQA\nABiMIgcAwGAUOQAABqPIAQAwGEUOAIDBKHIAAAxGkQMAYDCKHAAAg1HkAAAYjCIHAMBgFDkAAAaj\nyAEAMBhFDgCAwShyAAAMRpEDAGAwihwAAINR5AAAGIwiBwDAYBQ5AAAGo8gBADAYRQ4AgMEocgAA\nDEaRAwBgMHtTP+H999+vqKgoSVKHDh00ZcoUpaeny2azqVu3blq4cKFCQnh/AQCAP5q0yL1er3w+\nn3JycuqWTZkyRTNnzlT//v21YMECFRQUaMSIEU0ZCwAAYzXp1Le8vFzfffedUlJSNHHiRO3bt09l\nZWXq16+fJGnQoEHas2dPU0YCAMBoTTojv+aaazR58mSNGzdOhw4d0u9+9zv5fD7ZbDZJUmRkpKqr\nqy+5ndjYa2W3h1odF0GqTZvoQEe4IoJlHGgeguX1FCzjaIwmLfLOnTurY8eOstls6ty5s1q2bKmy\nsrK6+z0ej2JiYi65naqq01bGRJCrrLz0m0UTBMs40DwEy+spWMZRX0NvUJp01/rWrVv1zDPPSJKO\nHj0qt9utAQMGqLi4WJK0a9cu9e3btykjAQBgtCadkT/wwAOaM2eOkpOTZbPZtGTJEsXGxmr+/PnK\nzs5Wly5dlJiY2JSRAAAwWpMWucPh0LPPPvuj5Zs3b27KGAAABA1O2AYAwGBNfkEYAAACbcby/EBH\naNDKWff6vS4zcgAADEaRAwBgsKDZtR5Mu0kAAPAXM3IAAAxGkQMAYDCKHAAAg1HkAAAYjCIHAMBg\nFDkAAAajyAEAMBhFDgCAwShyAAAMRpEDAGAwihwAAINR5AAAGIwiBwDAYBQ5AAAGo8gBADAYRQ4A\ngMEocgAADEaRAwBgMIocAACDUeQAABiMIgcAwGAUOQAABqPIAQAwGEUOAIDB7IEOIEnnzp3TokWL\n9Mknn8jhcGjx4sXq2LFjoGMBANDsNYsi37lzp2pqavS3v/1N+/bt0zPPPKN169YFOhZgvBnL8wMd\noUErZ93r13rBMg7ACs2iyPfu3auBAwdKknr37q3S0tIAJwqc5vwHiz9WAND82Hw+ny/QIebOnau7\n7rpLgwcPliQNGTJEO3fulN3eLN5nAADQbDWLg92ioqLk8Xjqbp87d44SBwDAD82iyH/xi19o165d\nkqR9+/ape/fuAU4EAIAZmsWu9R+OWv/000/l8/m0ZMkSde3aNdCxAABo9ppFkQMAgMvTLHatAwCA\ny0ORAwBgMIr8PDU1NXriiSeUlJSklJQUHTp0KNCRGu3DDz+Uy+W6YNmSJUv00ksvBSjR5Tl/HB9/\n/LGcTqdcLpcmT56sY8eOBTidf84fw2effabk5GQ9+OCDSk9P19mzZwOczn8/9Zp67bXXNH78+AAl\narzzx7B//34NHDhQLpdLLpdLO3bsCHA6/50/juPHjys1NVUTJkzQgw8+qC+++CLA6fx3/jjS0tLq\n/i+GDRumtLS0AKfzT/2/UUlJSUpOTtacOXN07ty5Js3COV7nycvL07XXXqu8vDx9/vnnyszM1KZN\nmwIdy28bN25Ufn6+IiIiJEnffvutnnrqKR06dEiTJ08OcDr/1R9HVlaW5s+fr549eyo3N1cbN27U\nnDlzApyyYfXHkJ2drccff1y33Xab0tPTVVhYqBEjRgQ45aXVH4f0fRFu3bpVphxeU38MZWVlmjRp\nklJSUgKcrHHqj2P58uUaPXq07r77br377rv6/PPPFRcXF+CUl1Z/HCtWrJAknTx5UhMnTmz2v9vS\nj8fw3HPPaerUqRo8eLCeeOIJvf322xo2bFiT5WFGfp7PPvtMgwYNkiR16dJFFRUVAU7UOHFxcVq9\nenXdbY/Ho8cee0z33XdfAFM1Xv1xZGdnq2fPnpKk2tpahYeHByqa3+qPYfXq1brttttUU1OjyspK\nRUVFBTCd/+qPo6qqStnZ2crIyAhgqsapP4bS0lK9/fbbmjBhgjIyMuR2uwOYzn/1x/HBBx/o6NGj\nevjhh/Xaa6+pX79+AUznv/rj+MHq1av10EMPqW3btgFI1Tj1x9CzZ0+dOHFCPp9PHo+nya+DQpGf\np2fPniosLJTP59O+fft09OhR1dbWBjqW3xITEy94Ad1www265ZZbApjo8tQfxw+/2B988IE2b96s\nhx9+OEDJ/Fd/DKGhoTpy5IjuueceVVVVqUePHgFM57/zx1FbW6u5c+dqzpw5ioyMDHAy/9X/v0hI\nSNBTTz2lLVu26IYbbtCaNWsCmM5/9cdx5MgRxcTE6IUXXlD79u21cePGAKbzX/1xSN9/TFBUVKSx\nY8cGKFXj1B9Dp06dlJWVpVGjRun48ePq379/k+ahyM/z61//WlFRUXI6nXrrrbfUq1cvhYaGBjoW\nJO3YsUMLFy7U888/r1atWgU6zmW5/vrr9eabbyo5OVnPPPNMoOM0WllZmQ4fPqxFixbp8ccf12ef\nfaasrKxAx2q0ESNGKD4+vu7n/fv3BzjR5WnZsmXd7tthw4YZ/R0Vb7zxhu655x5j/95mZWVpy5Yt\neuONNzRmzJgm//2myM/z0Ucf6Y477tBLL72kkSNH6oYbbgh0JEh69dVXtXnzZuXk5Bj7fzJlypS6\ngycjIyMVEmLer15CQoJef/115eTkKDs7WzfeeKPmzp0b6FiNNnnyZJWUlEiSioqK1KtXrwAnujy3\n3nqr3nnnHUnS+++/rxtvvDHAiS5fUVFR3ceaJmrRokXdx2Vt27bVqVOnmvT5OdjtPB07dtTKlSu1\nfv16RUdHGznbCDa1tbXKyspS+/bt9dhjj0mSbrvtNk2fPj3AyRrnkUceUXp6usLCwhQREaHFixcH\nOtJVa9GiRcrMzFRYWJhat26tzMzMQEe6LLNnz9a8efOUm5urqKgoPfvss4GOdNkOHjxo7Jt0SVq8\neLHS0tJkt9sVFhbW5K8pruwGAIDBzNu/BwAA6lDkAAAYjCIHAMBgFDkAAAajyAEAMBhFDgS5VatW\n6R//+McVf0x6erq2b9/+c6IBuAIociDIvf/++42+1PDlPAZAYHAeORBE/vnPf+rJJ5/U6dOnFRIS\noiFDhmjTpk1q3bq1nnvuOZ08eVIrVqzQv/71L508eVKzZs3SqFGjlJ6erhMnTujw4cN65JFH9Pvf\n/77uMTfddNNPPld6erpOnz6tr7/+WsePH9eUKVM0fvx4fffdd5o3b54++eQT2Ww2TZ48WWPGjNH2\n7dv13nvv1V2+0uVyadq0aZK+/yavc+fOqVu3blq2bFmT/XsBwYAruwFBZOvWrRoyZIh++9vfqri4\nWKWlpYqPj9e0adN00003afr06Vq8eLG6du2qoqIiLVmyRKNGjZL0/bW7169fL0navn173WMaUlNT\no5dfflkHDhzQxIkTNX78eK1evVqxsbH6+9//rm+//Vbjxo275JfEHDp0SIWFhYqOjr4y/xDAVYRd\n60AQueOOO/TnP/9ZTzzxhI4ePaqHHnrogvuXL1+uAwcOaM2aNfrLX/4ij8dTd19CQkKjn+/OO++U\nzWZTt27dVFVVJUl699139cADD0iSWrVqpTvvvFPvvfdeg9vp3LkzJQ5cJoocCCK33nqrXn/9df3y\nl7/Ujh14mDQ8AAABYklEQVQ7NGXKlAvudzqdKikpUXx8/I/uu+aaaxr9fD98W5XNZqtbVv/TOp/P\np9raWtlstgvuO3PmzM96bgDfo8iBIPKHP/xBr776qu6//34tWLBA+/fvV2hoqGpra3XixAkdOnRI\nM2bM0ODBg7V79+6LHtD2w2Mux+23366tW7dKkr799lsVFBSoX79+io2NVUVFhXw+n7788kt98skn\nlz1OAP9GkQNBxOVy6c0339R9992nadOmaeHChRo4cKAWLlyozz//XOPGjdOvfvUrjRkzRsePH9e/\n/vUvnT59+kfb+eExH3zwQaMzTJ06VSdOnNDo0aP10EMPacqUKerVq5f+4z/+Q+3bt9fIkSOVlZWl\nW2+99UoMGbjqcdQ6AAAG46h1ABe1bNky7dmz50fL4+PjlZWVFYBEAOpjRg4AgMH4jBwAAINR5AAA\nGIwiBwDAYBQ5AAAGo8gBADAYRQ4AgMH+PzLcVBkTSiDNAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1792e390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x=\"start_hour\", hue=\"target\", data=train_df[(train_df['target']==1) & (train_df['year']<2014)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1774b9e8>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfIAAAFXCAYAAABZQMyNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17519860>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x=\"start_hour\", hue=\"target\", data=train_df[(train_df['target']==1) & (train_df['year']==2014)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x19ac3160>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfIAAAFXCAYAAABZQMyNAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a0a5128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x=\"start_hour\", hue=\"target\", data=train_df[(train_df['target']==1) & (train_df['year']==2013)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a62add8>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgMAAAFXCAYAAAA/LE0rAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIwYAADDc/wes/TjvIMMoegAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12ea6898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x=\"year\", hue=\"target\", data=train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x14ff6470>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAf0AAAFXCAYAAACoS5cAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x191f4160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x=\"months_count\", data=test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1dc63a50dd8>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZUAAAEKCAYAAADaa8itAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkroxVCRJ3RgqkqRuDBVJUjf/H+Gt5sCnRSSVAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1dc615cd7b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x=\"month\", data=test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2014-05-01 17:14:03')"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.time1.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "cv_scores = cross_val_score(logit, X_train_sparse_alicemin2_dayall_september_morningMinutes, y_train, cv=time_split, \n",
    "                            scoring='roc_auc', n_jobs=2) # hangs with n_jobs > 1, and locally this runs much faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.91116986,  0.89905979,  0.93087555,  0.97275411,  0.93509801,\n",
       "         0.9753213 ,  0.88548503,  0.96274666,  0.92831253,  0.980911  ]),\n",
       " 0.93817338445561815)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_scores, cv_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_feat_train['day6'] = train_df['time1'].apply(lambda ts: 1 if ts.weekday()==6 else 0)\n",
    "new_feat_test['day6'] = test_df['time1'].apply(lambda ts: 1 if ts.weekday()==6 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_sparse_alicemin2_dayall_september_day6 = csr_matrix(hstack([X_train_sparse_alicemin2_dayall_september, \n",
    "                             new_feat_train['day6'].values.reshape(-1, 1)]\n",
    "                                                      ))\n",
    "X_test_sparse_alicemin2_dayall_september_day6  = csr_matrix(hstack([X_test_sparse_alicemin2_dayall_september, \n",
    "                              new_feat_test['day6'].values.reshape(-1, 1)]\n",
    "                                                      ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 25.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "cv_scores = cross_val_score(logit, X_train_sparse_alicemin2_dayall_september_day6, y_train, cv=time_split, \n",
    "                            scoring='roc_auc', n_jobs=2) # hangs with n_jobs > 1, and locally this runs much faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.91645383,  0.896841  ,  0.93593218,  0.97190743,  0.9344251 ,\n",
       "         0.97398632,  0.88387319,  0.96030011,  0.9329658 ,  0.98004079]),\n",
       " 0.93867257453680719)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_scores, cv_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['56     55      0      0      0      0      0      0      0      0',\n",
       " '   56     55     56     55      0      0      0      0      0      0',\n",
       " '  946    946    951    946    946    945    948    784    949    946',\n",
       " '  945    948    949    948    945    946    947    945    946    946',\n",
       " '  947    950    948    947    950    952    946    951    946    947',\n",
       " '  952    947    953    946    947    946    953    955    946    947',\n",
       " '  953    947    946    953    955    947    953    946    953   1033',\n",
       " '  946    947    954    953    946    954    946    956    957    956',\n",
       " '  946    956    946    946    955    954    946    946    946    948',\n",
       " '  948    946    948    784     49     53    812    982     52     52',\n",
       " '   52     52     52    747    747    747     23    747    568     23',\n",
       " '  513   1116    747     23    747    747     29     49     52     21',\n",
       " ' 4222   3358   4222   3356   4222   3870     21   3870   3358     21',\n",
       " '38667    181     23    181  38667     23    182    181  38667     55',\n",
       " '   56     55    679    676    814     22     39    815    752     50',\n",
       " '  570     23     21   3356     48    222    570    513   1379     21',\n",
       " '  820    820    980     49     56     55     49    784    222     50',\n",
       " '   48     56     55     55      0      0      0      0      0      0',\n",
       " ' 5898   5898   5794     21   5794   5794     21    182     23    181',\n",
       " ' 2570   2570     21     21   1102   1102     23    570    707     21',\n",
       " '   22     39   1102     21   1102   1102   1102     21    177    175',\n",
       " '  177    178    175     48     21     22    176    175    177     55',\n",
       " '   56     55    570    570   1038    847     22    774    570      0',\n",
       " '   56     55      0      0      0      0      0      0      0      0',\n",
       " '   56     55     55   1038     52     53     21   4277     21   4277',\n",
       " ' 4277    342    733    733    733    733    733     23    733    733',\n",
       " '  733     49  17232     50     48     52     23     21    989     38',\n",
       " '  753    532   1020    989   1021   1021     48    990    544     22',\n",
       " '  733    733    733    733    733    733  17232    989  17232     21',\n",
       " '38668    733    733    733    733    733    568     21   1126     52',\n",
       " ' 1127   1127   4279   1126     21    733    733    733    733    733',\n",
       " '   55     56      0      0      0      0      0      0      0      0',\n",
       " '  733    733    733    733    733    733     22     39     38    570',\n",
       " '  733    733    733    177    733    733    733    733    733    733',\n",
       " '  733    733    733    733    733    707     21     50   6803   6803',\n",
       " ' 6803   6803     21     55     56     55    570    733    733    733',\n",
       " '  570    570   1102     75     76     21     52     75    881     75',\n",
       " '   56     55      0      0      0      0      0      0      0      0',\n",
       " '   77     76     75     80    881     76     76     80     80     80',\n",
       " '  784    948    959    948    959    948    959    948    959    948',\n",
       " '   80     80     80     80     80     80    881     80     80     80',\n",
       " '   50     50    753  12386  12385     23  12387   4220  38669  38669',\n",
       " '   22     21    570    570     55     56    570     21     21     38',\n",
       " '  959    948    959    948    948    959    959    948    959    948',\n",
       " '  948    959    948    959      0      0      0      0      0      0',\n",
       " '  242     21    242     21   5898    242     23   5898    242    182',\n",
       " '  242    812    951    947    946    952    945    949    951    953',\n",
       " '  950    948     21    570    951    947    950    947    953    945',\n",
       " '   56     55     56     55      0      0      0      0      0      0',\n",
       " '  952    946    949    948   4087   4087     53     52     52   4087',\n",
       " '   21   4087    513    350    350   4085   1103   1007   1007   1104',\n",
       " ' 1106   1007   1104   1105   1104   1007   4086     23    570     21',\n",
       " ' 1007   1104   1007   1106   1007   1104   1104   1007   1105     56',\n",
       " '  820    820    980     49   1037    812     53     52     52     52',\n",
       " '   55     56     21     21     52     39    812     23    814     22',\n",
       " '  676    679    815    570      0      0      0      0      0      0',\n",
       " '   55    570    812      0      0      0      0      0      0      0',\n",
       " '  848    848      0      0      0      0      0      0      0      0',\n",
       " '   52     53     52     52     21     21   4222   3358   4222   3356',\n",
       " ' 3358     22    570     21     23     56     55     55   3356    784',\n",
       " '  820    820    980    784    784     49   5474   5472     52     53',\n",
       " '  303     52    303    812     21     52     52     57     21     52',\n",
       " '   66    348     48    222     56     55      0      0      0      0',\n",
       " '  222     56     55     55     55    676    679     23     21    812',\n",
       " '  676     23    679     39    815     22    814    570      0      0',\n",
       " '   23    167     66     63      0      0      0      0      0      0',\n",
       " ' 2412   2412      0      0      0      0      0      0      0      0',\n",
       " ' 1547   1547    848    848    848      0      0      0      0      0',\n",
       " '   56     55      0      0      0      0      0      0      0      0',\n",
       " '  848      0      0      0      0      0      0      0      0      0',\n",
       " '  784      0      0      0      0      0      0      0      0      0',\n",
       " '  784     23     52     53     52     52     52     52     52     23',\n",
       " '    2      3     46     47    205     48      3      3     47      3',\n",
       " '   47     50     50     10      8      4   2630      6  37107   2630',\n",
       " '   12     14     14     14     13     56     55     55      7     18',\n",
       " '    7     14    784   2630      6      6     13     14   2630      6',\n",
       " '   21     52     52     52    678    812     21    676     39    679',\n",
       " '   55     56    570     55     22     23    616    677    617    677',\n",
       " '   56     55      0      0      0      0      0      0      0      0',\n",
       " '  570    616    677    616    775    677    570    616     55     56',\n",
       " '  951    947    952    947    952    950    956    946   1033    947',\n",
       " '  953    947    953    955    946    945    946    953    947    953',\n",
       " '  948    946    947    949    957    945    948    945    947    953',\n",
       " '  951    946    945    948    953    957    946    955    953    946',\n",
       " '  946    958    946    946    946    946    946    946    946    946',\n",
       " '  946    951    946    951    946    946    946    946    946    946',\n",
       " '  948    784    948    948     53     52     52     21    989     38',\n",
       " '   56     55      6     13     14   2630      6    950    947    953',\n",
       " '  848      0      0      0      0      0      0      0      0      0',\n",
       " '  952    951    947    953    950    947    953    956    949    946',\n",
       " '  947    948    953    945    956    946    946    947   1033    945',\n",
       " '  953    958    955    948    957    953    947    945    946    947',\n",
       " '  946    945   1033    946    958    958    946   1033    955    946',\n",
       " '  948    946    948    948    222     56     55      0      0      0',\n",
       " '   21    753    532    989   1020   1021     48   1020    544    568',\n",
       " '   55    677    570    616    776    570    677    616    570     49',\n",
       " '  989     56     55     55     23    707     22     21     52    989',\n",
       " '   56     55      0      0      0      0      0      0      0      0',\n",
       " '   21   1021   1020    989    532     29    989     48    990    568',\n",
       " '   21    989    989    532   1020   1021     49     50     48    568',\n",
       " '  568   4208   4208   4208    733    733    733    733    733    733',\n",
       " '  733    733    733    733   4208   4208    733    733    733   4208',\n",
       " ' 6090   6091   6090   5503   6090   5503   6090   5503   6090   5503',\n",
       " '   46   6090     50    753   6090    753   6090     49   6090    570',\n",
       " ' 6090   5505   6092   5507     21   6090     56     55    677    570',\n",
       " '  820    820    980     45     66     67     70     68     69     71',\n",
       " '   69     70     67     71     23   6548  33487      3      3      8',\n",
       " '    8      3      3      4      6   8123     14   8123      8      6',\n",
       " '    7  39278     10   8123      7     12   8123     18     18   2169',\n",
       " '    6   4534   4394     18   4534     18     18   4534     11     18',\n",
       " '   55     56    733    733    733    733    733    733    733    733',\n",
       " ' 6090    784    570    952    949    949    958    946    951    947',\n",
       " ' 3331    784     18     63     63     66     11     18   4534   2634',\n",
       " '39278    784    979      0      0      0      0      0      0      0',\n",
       " '  733    733    733    733    733    733    733    733    733    733',\n",
       " '   56     55     56     55      0      0      0      0      0      0',\n",
       " '  733    733    733    733    733    733    733    989    989   1021',\n",
       " '  946    945    945    948    946    951    947    947    950    945',\n",
       " '  946    955    953    948    953    948    947    946    956    945',\n",
       " '  945    946    947    953   1033    957    947    946    953    953',\n",
       " '  947    946    955    946    953    953    946    946    948    946',\n",
       " '  948    946    946    946    946    946    946    946    946    946',\n",
       " '  946    946    946    948    948    570    950    947    946    949',\n",
       " '   56     55     55      0      0      0      0      0      0      0',\n",
       " '   21   4087     50    543     52   4592   4087   4594   4087   4208',\n",
       " '   21  24083    658    367    655    803    661    660     52    117',\n",
       " '   23  24084    666     32    666    658     23     35    661    658',\n",
       " '  951    948    947    951    945    952    953    677     56     55',\n",
       " '   23    666     52     23  24084     38    666     52    666     52',\n",
       " '   23    803    803     33     45     29    707     38     21    666',\n",
       " '   22    617     39    819     23     52     53     52     21   1007',\n",
       " '   55    570     52     53     52     27     31     21     26     31',\n",
       " '   58     58     59    848      0      0      0      0      0      0',\n",
       " ' 1104   1106   1007   1104   1007   1105   1007   1104   1007   1105',\n",
       " ' 1106   1104    948     49    948   1007   1104   1007   1106   1105',\n",
       " ' 1104   1007     75     76   1007   1104   1007   1105    948     55',\n",
       " '   56     55    167    167     69    167     66     67     70     68',\n",
       " '   71    359     69     70     67    167     71      3    384    167',\n",
       " ' 1007   1104    167   1007   1104   1007   1104   1106   1007   1104',\n",
       " ' 1105     38   1007   1104    948   1106   1007   1104   1105    948',\n",
       " ' 4456    948   4456    948     23     22     21    948    784    784',\n",
       " '   52     34     31     26     35     36     32     31     29     30',\n",
       " '   46     37     29     45     33     27    570     21     38    959',\n",
       " '   63     66    959   1007    959    959   4456    947    952    953',\n",
       " '  947    951   1033    950    946    947    953    950    945    946',\n",
       " '  947    953   1033    948    953    949    945    948    946    947',\n",
       " '  947    953    945    946    947    946    953    945    954    947',\n",
       " '  946    946    947    946    948    946    946    946    946    946',\n",
       " '  946    946    946    946    946    948    946    948    946    946',\n",
       " '  946    946     66     67     69     70     71     71     69      3',\n",
       " ' 6093     21     21    181   1016    181     23   1016   1016    181',\n",
       " '  182     29    197    196    616    570    677     21    570    616',\n",
       " '  820    820    980     49     52    197    196     53     52     49',\n",
       " '   56     55     55     46     50     47      6     13     14   2630',\n",
       " '   29   1104     55     56      0      0      0      0      0      0',\n",
       " '  959     56     55     55    570    570    677    959    570      0',\n",
       " '    6     47      6     13     14   2630     56     55     55      6',\n",
       " '   56     55     55     56     55      0      0      0      0      0',\n",
       " '   21     22     23     22     21     23     63      0      0      0',\n",
       " '   45     63     68     66     70     67     69     67     69     70',\n",
       " '   71     70    167     21     21     22     23     39    676     22',\n",
       " '  784    784      0      0      0      0      0      0      0      0',\n",
       " '  679     21     23    812    676    679     22     21    814     21',\n",
       " '   39    812     23    570    814     22    815    812    812     39',\n",
       " '  815    570     22    812    784     63     66    570     22    812',\n",
       " '  167    167     67     66    359    167     71     68     70     69',\n",
       " '   67     70      3    384    167    167    812     39    812     23',\n",
       " '   39    812     22     23    812     23     22    676     22    679',\n",
       " '  679    812     39    814    676    570     23    812    815    814',\n",
       " '  570     22    815    812    570    812     23     21    812    676',\n",
       " '   39    679     23     66     63      0      0      0      0      0',\n",
       " '  677     55     56     55    570    570    677    570      0      0',\n",
       " '   55     56      0      0      0      0      0      0      0      0',\n",
       " '  820    820    980     49    784     55     56     52     53     21',\n",
       " ' 4088   4088   4087    784    947    946    945    947    946    948',\n",
       " '   55     56     55    570    570    570    677     56     55     55',\n",
       " '   21    188      3     47     46     47    205     48      3     48',\n",
       " '    8     47      3      3     47     50     50      3     10     15',\n",
       " '    8      4     14      6    249     14   4181    249     14     12',\n",
       " '   56     55     56     55     55      0      0      0      0      0',\n",
       " ' 4182    249   4183     23     22     21      3     65    249    268',\n",
       " '  271    167    270    269    167     30    271    273    269      7',\n",
       " '  249     50     49     30    790     32    268     29     35      3',\n",
       " '  792    790    791     46    791    792     46    793    268      8',\n",
       " '  272     33     29   4184     16   4185    274    790    162   4185',\n",
       " ' 4184   1998    167    272   4185    269   1998    793    269     30',\n",
       " '  792     35    131    202    222     37    796     29     33   4184',\n",
       " '   35    272    167   4184   1998   1914   1915   1914     11     64',\n",
       " '  162     37     30     33     45     29     29     50     50    792',\n",
       " '  790     29    790    793    790     29     29   4184   1998   4184',\n",
       " '  272    269     35    793     48     37     33     29     29     29',\n",
       " '  268     29    270    271    790     30    273    268    792     29',\n",
       " '   35      3     37    794    272     29     33      3    274     29',\n",
       " '    3      3      3   4186     48    197      3     10      8     15',\n",
       " '   15   4187   4187     48    222     52     48    796      4      6',\n",
       " '   65    249     12   4188    249     14     14    249     18      7',\n",
       " '   11     16    249     38    784   3346    979     65     14    249',\n",
       " ' 3346   1922     23   4189     21    639   4189     52     52     23',\n",
       " '  950    945    947    950    948    945    953    946    953    946',\n",
       " '  947    949    945    947    946    953    951    945    952    953',\n",
       " '  946    947    946    947    953    957    946    947    953    955',\n",
       " '  958    946    953    946    946   1033    954    957    955    956',\n",
       " '  948    948    948    948    784    949    947    948    947    953',\n",
       " '   45     21     21     22     23     21     23     22     21    733',\n",
       " '  951    948    947    953    952    950    946    957    950    953',\n",
       " '  947    947    957    953    945    946    954    945    948    953',\n",
       " '  947    957    946    953    945    946    955    946    954    945',\n",
       " '  955    958    946   1033    946   1033    955    946    946    946',\n",
       " '  946    946    946    946    948    946    948    946    946    946',\n",
       " '  946    946    946    946    946    784    784     56     55      2',\n",
       " '  733    733     63     21    306    305    306    306     21     21',\n",
       " '   29     23     21     22     39    249   1922     14     56     55',\n",
       " '   66     67     71     70     70     68     69     67     70     71',\n",
       " '  167     66     63    570    570    570     55     56      0      0',\n",
       " '  820    820    980     66     67     71     70     68     69     67',\n",
       " '   70     71    167     63     66    784      0      0      0      0',\n",
       " '   55   1922     23     21    249   1922     14     21     23     38',\n",
       " '    3     46     47     47      3     48    205      3      3     47',\n",
       " '    3     47     50     50     10      8      4   2630  37107      6',\n",
       " ' 2630   2630     14     12     13     14   2630      7      7   2630',\n",
       " '    6     56     55     55      6     13     18     14   2630   7206',\n",
       " '   21    733    733    733    733    733    733    733    733    733',\n",
       " '  733    733    733    733     76     77     75     75     76     23',\n",
       " '   77     23     77     21     75     77     75     52     52     23',\n",
       " '   75     77     76     22     75     75     77    881     75     76',\n",
       " '   80     76     75    881     75     76    881     80     22   1057',\n",
       " ' 1057     77   1057   1057     76     77    881     80    881     80',\n",
       " '  881     77    881     80    881     77    881     80    881    881',\n",
       " '   80     80    881     80    881    881    881     80    881     80',\n",
       " '  881    881     80     77     80     80     80     80     80     80',\n",
       " '   80    881    881    881     80     80    881    881    881     76',\n",
       " '  881     80     80    881    881    881     80    881     80     80',\n",
       " '  881    881    881     80     80    881    881    881    881     80',\n",
       " '   80    881    881    881     80    881    881    881     80     80',\n",
       " '  242    242    182     29   1922     21     21    242    242    182',\n",
       " '  881     80    881    881     80     80     80    733    733    733',\n",
       " '   21     55     56     55     50     46     15      3     47     65',\n",
       " '  570    570    677    570     56     55      0      0      0      0',\n",
       " '   56     55     56     55      0      0      0      0      0      0',\n",
       " '   18     18     18      6     13      6     14   2630      6     56',\n",
       " '  733    733    733    733    733    733    733    733    733    733',\n",
       " '  205     48    167    268    271    273    270     30     50     49',\n",
       " '  790    268     32    792     29    268     35      3    792      8',\n",
       " '   48     37     64     11   1922     29   1919    796     30     33',\n",
       " '   49     53     52     21   2370   2370   2370   2370   2370   2370',\n",
       " '   55     56   2370     55   2370     55   2370    784   2370   2370',\n",
       " ' 2370   2370   2370     49   2370   2370   2370   2370   2370   2370',\n",
       " ' 2370     20     21    747     21    513     23    747     52     23',\n",
       " ' 1116    747     23    747    513    747     22     23    784     21',\n",
       " '  752    222      0      0      0      0      0      0      0      0',\n",
       " '  733    733    733    733    733    733    733    733    733    733',\n",
       " '   55     55     47     50     46     47      6     13     14   2630',\n",
       " '  570    570    570    776     53     52     52     52     21   6094',\n",
       " '  820    820    980    820    820    980      0      0      0      0',\n",
       " '  733    733    733    733    733    733    733    733    733    733',\n",
       " '  733    733    733    733    733    733    733    733    733    733',\n",
       " '  733    733    733    733    733    733    733     21    733    733',\n",
       " '    6     55     56      0      0      0      0      0      0      0',\n",
       " '  733    733    733    733    733    733    733    733    733    733',\n",
       " '  733     21    733    733    733    733    733    733    733    733',\n",
       " ' 6095   6094   3861     22   2870     32     52     35   3187   3863',\n",
       " ' 2543   1643   6096   2538   6096     32   6097     35     29     33',\n",
       " ' 3861   6095     55     56     55   6094     35     33     45     29',\n",
       " '   29     29     33    707    570     21     23     39     52   6098',\n",
       " '   21   6098    784   6098   6098     23     52   6098     22    784',\n",
       " ' 6098   6098    570     21     39   6094   3861   6099   6100   6095',\n",
       " '   56     55      0      0      0      0      0      0      0      0',\n",
       " '  784      0      0      0      0      0      0      0      0      0',\n",
       " '  733    733    733    733    733     75     52     21      0      0',\n",
       " ' 6099   6100   6101   6101   6099     35   1015   6101   6101   6101',\n",
       " '   29     33     29     29     22     29     29     23     23     52',\n",
       " '   49     52     53     55     56    784    784     49     57   1007',\n",
       " '   23     21     52   3861   6094     35   6094     29     33   3861',\n",
       " ' 1007   1008   1007   1008   1007     52     53     52     52     52',\n",
       " ' 6095     35   6102    156     23    322    157   1385    222     21',\n",
       " '  543    678    676     39    679     23    570     29     33     29',\n",
       " '  616    814    617     22    677    677    570     55     56    814',\n",
       " '  222     48     52     52     55     56    814     23     22     39',\n",
       " '  815     38   3346    570    222     48     50     58     58     59',\n",
       " '   48     48    570    570   1007   1008   1007    812     23      0',\n",
       " '  677    677    570    776      0      0      0      0      0      0',\n",
       " '   55     56     55      0      0      0      0      0      0      0',\n",
       " '   56     55     56     55      0      0      0      0      0      0',\n",
       " '   49     52     53     52     52     52     56     52     55     55',\n",
       " '   52     49     21   3350     48     48    961     48     48    961',\n",
       " ' 4329    784    784    979     49     52   1037     53    812     52',\n",
       " '  961   1980   1980   1980     48   1980   1980   1980   1980   4494',\n",
       " ' 1981   1980   1980    543   1980    222   1980    676    679    814',\n",
       " '   39    815     22   1980   1980     48    961   1023    222    202',\n",
       " ' 1023   1024    338    338   1023     23     21   1023   1023   1023',\n",
       " ' 1023   3393   3394     52   3393   3374     48   3393   6618    125',\n",
       " ' 1619    753     32   3393   6618    784    222    677     22    774',\n",
       " '  570     21     21    679    676     23    570    812     39    784',\n",
       " '   52     52     52     56     55     55     49    570     22     23',\n",
       " '   39    812    815    814      0      0      0      0      0      0',\n",
       " '   55     56      0      0      0      0      0      0      0      0',\n",
       " '  784    784      0      0      0      0      0      0      0      0',\n",
       " '   55     56     55     56      0      0      0      0      0      0',\n",
       " '   63     45      0      0      0      0      0      0      0      0',\n",
       " '   56     55     55     56      0      0      0      0      0      0',\n",
       " '  784    784      0      0      0      0      0      0      0      0',\n",
       " ' 1007   1007   1008    197     52    196     53     52      0      0',\n",
       " '  784     48    784     55     56     55     52     52     53     21',\n",
       " '  747    513    747     23    747     23     52    325     50    747',\n",
       " '   23     23    747    513    751    747    747     23     23    747',\n",
       " '  747    747     23   1116     23    323     29     23    747     23',\n",
       " '  322   1049    156    319    324    747     23     23    747    625',\n",
       " '   52     23    747     49     22     21     23    152     21     20',\n",
       " '  784    784    945    946    945    947    946    947    945    948',\n",
       " '   29     21    747     21     23    747     23    753     48   1018',\n",
       " '   21    317   1017   1018    317   1019    320    318    317    315',\n",
       " ' 1018     21  11230  11230     21    752     21     52     21    343',\n",
       " '  820    820    980    784      0      0      0      0      0      0',\n",
       " '  945    946    949    947    947    948    946    949    950    950',\n",
       " '  951    947    946    947    946    952    952    953    946    946',\n",
       " '  954    953    955    953    946    948    956    953    946    953',\n",
       " '  957    958    953    953    954    957    958    957    948    948',\n",
       " '  948    948    959    959    959    948      0      0      0      0',\n",
       " '  784    784    784    784      0      0      0      0      0      0',\n",
       " '  175    175    176    175    343    175    178     48  11231     21',\n",
       " '   38    532  11231    753  11231     48     48    544    343    175',\n",
       " '   56     55      0      0      0      0      0      0      0      0',\n",
       " '  176    568     21    733    733    733    733    733    733   1294',\n",
       " '  784      0      0      0      0      0      0      0      0      0',\n",
       " ' 4105     21     21     23     21  11232  11232     29     21     21',\n",
       " '  544     56     55     55     21    568     21    343    175    175',\n",
       " '  178    733    733    733    733    733    733    733    733    733',\n",
       " '  733     21     21    177    175    175    178    177    175    178',\n",
       " '  176    177     21    733    733    733    733    733     21     21',\n",
       " '   21  11233     30     32  11233  11233     30     35     52  11233',\n",
       " '11233     46  11233  11233  11233     37     33    175     21    177',\n",
       " '  177    175    178     21     22     39   1591     21   1591   1591',\n",
       " '  784     49     52     53     52     49     56     55     22     23',\n",
       " '   29    175    177     21    177    178     21     21    471    471',\n",
       " '   52     52     52    222     21    679    676     23    814    677',\n",
       " '   39    815     22     52     52     50     48     22     23    616',\n",
       " '   21     21   5799     21   5799   5799    566   6880     23    566',\n",
       " '   49    800     52     53     52     49     21     52    812     52',\n",
       " '  617   2415   2414     21     23    617    814     39   2415     22',\n",
       " '   52     56     55     55     21    222    814     23     22     39',\n",
       " '  784    784      0      0      0      0      0      0      0      0',\n",
       " '  566    566     21     22    566    566    566     56     55     55',\n",
       " '  784    784      0      0      0      0      0      0      0      0',\n",
       " '  815    570     50     48    570    570    570     56     55     55',\n",
       " '   21     52     53     21  10690  10690  10690  10690  10690  10690',\n",
       " '  774    616    677    616     55     56   1007   1007   1008    677',\n",
       " '10690     21      0      0      0      0      0      0      0      0',\n",
       " '  784    784     49     52   5472   5047     48     53   5474     52',\n",
       " '   56     55     56     55      0      0      0      0      0      0',\n",
       " '   50  15523     87  15524   1035     23     21     52  15524  15525',\n",
       " '15524     52    303  15525  15526  15523  15523     55     56     55',\n",
       " '   38     23     21     22     23    173     23    707     21    222',\n",
       " '   49     49     55     56    222     50    979     48    959    948',\n",
       " '  570    570    570    812      0      0      0      0      0      0',\n",
       " '   23      0      0      0      0      0      0      0      0      0',\n",
       " '  677    677    677     55     56     55    677      0      0      0',\n",
       " '   56     55    948    959    948    959    948    959     53    196',\n",
       " '   52     53     52     21    812     52     52    815     39    814',\n",
       " '  677    677     56     55     55    677      0      0      0      0',\n",
       " '  570     22     21     23    812      0      0      0      0      0',\n",
       " '   56     55      0      0      0      0      0      0      0      0',\n",
       " '   52    197     52     56     55     55    948    959    948    948',\n",
       " '  959      0      0      0      0      0      0      0      0      0',\n",
       " ' 6725  41475  41475  41476  41476  41476  41476  41475   6725  41475',\n",
       " '41475   6725  41476  41476  41476   6725  41475  41475  41476  41476',\n",
       " ' 6725  41475  41476   6725  41475  41476  41476  41475   6725  41475',\n",
       " ' 6725  41476   6725  41475  41476   6725  41476  41475   6725  41475',\n",
       " '41476  41476  41476   6725  41475  41476  41476  41475   6725  41475',\n",
       " '  820      0      0      0      0      0      0      0      0      0',\n",
       " '  820    820    820    820      0      0      0      0      0      0',\n",
       " '  820      0      0      0      0      0      0      0      0      0',\n",
       " '  820      0      0      0      0      0      0      0      0      0',\n",
       " '   49     23     52     53     52     21    989    989     38    532',\n",
       " '   52     53    197    196    625     56     55     55     55     55',\n",
       " '   23     52     23     52     53    196    197    625     56     55',\n",
       " '  753    989   1020   1021   1021     48     48    990    989     49',\n",
       " '   52     53    196    197    625     23   1035     21     21    229',\n",
       " '   49     56     55     55    532    989     38    753     55   1020',\n",
       " '  544     56     55     55    568     23     22     21    222     50',\n",
       " '  989   1020     55   1021     48     48    990    544     49     52',\n",
       " '  820    820      0      0      0      0      0      0      0      0',\n",
       " '   49    800     55     56     55    222     50     48     23     53',\n",
       " '   45     21     21     22     23     22     23     21     21     21',\n",
       " '  820    820    820    820   1446   1470      0      0      0      0',\n",
       " '   23     53     52     21    177    175    175    177    178    178',\n",
       " '   55     55     55     55     23     52     23     52     52     23',\n",
       " '   48    175    568    176    177    175     22     23     21    707',\n",
       " '   52     53     49     49    304    197     52    196   1037     52',\n",
       " '   21    229    229    229    229     21    229     21    229    229',\n",
       " '  812     52     56     55     52     55     55     57    222     39',\n",
       " '   21  11134  11134    222  11135     21  11135  11135     50     23',\n",
       " '   56     55     55     56     55     55      0      0      0      0',\n",
       " '  676    679    814     23     22    570    815     50     50     48',\n",
       " '   49     53    197     52    196     52    948     55     56    784',\n",
       " '   23     52     23     52     52     52     52     52     52     52',\n",
       " '   21    229     21  18384     21    747     23    747     23    747',\n",
       " '  820    820    980     52     53     52     21    196     52    197',\n",
       " '   52    196     53    197     52     56     55     55    784    784',\n",
       " '   52     53     52     21    982     21    812     52     52     52',\n",
       " '   53     52     52     21    196     52    197     56     55     55',\n",
       " '   23     52     23     52     53    196    197    625     55     56',\n",
       " '  513   1116   1116   2220   2220   2501   2503   2502   2503    747',\n",
       " '   32     23     23    747     52    513     21    229     23     48',\n",
       " '  800     52     55     56     55     55     23     22     21    784',\n",
       " '   48     23     52     23     52     56     55      0      0      0',\n",
       " '   52     52    678     52     22     48    678    678    678    678',\n",
       " '   49    196     53    197     52     55     52     56     55     55',\n",
       " '   48     21    989    989     21   2371    989   1020   1021   2371',\n",
       " '   66     67     69     70     69     71     70     67     69     68',\n",
       " '   55     49     50    784     48    948    959     55     56     55',\n",
       " '   70     71     70    167     63     66    784    784      0      0',\n",
       " '   55     55     55     55   1037    812     52     52     52    812',\n",
       " '   48    197    196     52     55     56     55      0      0      0',\n",
       " '   52     53     21    196     52    197     52     22     23    222',\n",
       " '  820    820    980     70     67     71     66     69     68     69',\n",
       " '  989    753     53   1021     52     56     48    990     55     52',\n",
       " '   48    570    570     21  11158    570     23     21     55     56',\n",
       " '  222     21     39    679    676     23    815    814     22    570',\n",
       " '  812     39   6800    679    812     48      0      0      0      0',\n",
       " '  570     22     23     21    784    784    222     52     21   1102',\n",
       " '   67     70     71    167     63     66    784     21     22     23',\n",
       " '   52    196    197     53     52     55     56     55   4190    753',\n",
       " '  820    820    980     21     22     23     23     22     23     21',\n",
       " '   23     55     23    625    197    196     52     55     55    568',\n",
       " '   55    222     50     48      0      0      0      0      0      0',\n",
       " '   21     63    784  23473  23473     23  23473  23474     21    157',\n",
       " '   52     52     52     21    196     52    197     52     21     52',\n",
       " '  752    229    229     21    229    229    229     21    229     21',\n",
       " '   23     49    570     39    676    812    679     22     23     21',\n",
       " '  982    812     39    812     39     23     23    812     23     23',\n",
       " '  679     39     23    616    616    677    678    617    678    678',\n",
       " '   50    774     48    815     49     49    304     21     30  21276',\n",
       " '   21     50     48     21    177    175    178    175    177     48',\n",
       " '  812     39    676     22    679     39    676    679    812    814',\n",
       " '  568    812     23     52     23    989   1020    989   1021     23',\n",
       " '   23     22    570    814    570     39    815    570    816    812',\n",
       " '  812     22    812     22    570    815    677  22616    677    677',\n",
       " '  222     52     21   1102     52   1102   1102     23     21     22',\n",
       " '   48   4190     48     52    753    202     52     52     49    784',\n",
       " '41475  41476  41476   6725  41475  41476  41475  41475   6725  41476',\n",
       " '  677    678    677    678     21     23     23     21     21     23',\n",
       " '   49     49    513    222     38     23     21   4191   4191     23',\n",
       " '   52     23    679    616     23    677     39     55     56      0',\n",
       " '  820    820    980   1007   1007   1008    167    167    167     71',\n",
       " '  820    820    980     49    800     49    196     52    197     53',\n",
       " '  820    820    980   1007   1008   1007    784    784   1007   1007',\n",
       " '  178     48    177    178    176    177     48      0      0      0',\n",
       " '  989    989     29    532   1020   1021    568     48     55     56',\n",
       " '   23  16302  16875     21    784  23473      0      0      0      0',\n",
       " '   22    677    677    678    677    677    616    570     23    616',\n",
       " '   22    616    617    616    616    812   1529    616     23    617',\n",
       " '  784    784    979     49    222     48     52     53     49     48',\n",
       " '   52    784     55     56     55     50     48    784    222      0',\n",
       " ' 1529    677    616     23     39    306    305    306    570    677',\n",
       " '   70    167     66     67     68     69     70    167     71    359',\n",
       " '   67     69      3    384    167   3346     23   3346    167     38',\n",
       " '   38    784   3346   3346     63     66   4079   4079   4079    951',\n",
       " '21277     38     30     21     46     38    989    532    753  21277',\n",
       " '  989   1020   1021   1021   1020     48  21277    544     37    815',\n",
       " '   20    229     21    229    229     21    229    229     21     23',\n",
       " '   21   4191    784     46     47     47      3     48    205      3',\n",
       " '   21    747     52     23    747    513   1116   2220   1116     53',\n",
       " '   23     39    616    677    570   1529    677    677    570    570',\n",
       " '   52   2502   2503   2501   2503     32     35     29   2501   1643',\n",
       " ' 2504   2502   2276     23     21     35     29    202   2504   2505',\n",
       " '   23     21     21   1980    961   1023    961     21     21     22',\n",
       " '  747   6107     23   2504     29     33    513    747    747     23',\n",
       " '   39   1102     21    242    242     23     38    242     23    182',\n",
       " '  242    242    242     21    182     23    181   2570   2570     56',\n",
       " '  747     23    747    747    747    350    350     56     55     55',\n",
       " '   21    570   8440    961    961    961   1023   1024   1023    961',\n",
       " '  820    820    980     21     22     23     70     68     71     69',\n",
       " '   21     21     22    570   1145     21   1145   1145   1023   1025',\n",
       " '  568    570     23     21     21   1018    317   1017   1018   1017',\n",
       " '  961    961    961    961    961   1980   1980    812   1980     63',\n",
       " '41475   6725  41475  41476   6725  41475  41476  41476  41476  41475',\n",
       " '   67     66     70     69     67     71    167     23     21     22',\n",
       " '   39    812   1981   1980   1981    814   1980   1980    814     21',\n",
       " '   21     22     21     21   4084     23     38   4079     23     30',\n",
       " ' 4079   4079     37     29     37   4084   4079    569   4079   4079',\n",
       " '    3      8      3     47     50     50      3     10      3    249',\n",
       " '  145    569   4079    145      0      0      0      0      0      0',\n",
       " '   65      8    268    271    269    167   1914   1915     30    270',\n",
       " '  791    268     50     49     29    792     30    790   1914     32',\n",
       " '   35    792    268      3    791     46      8     33     29    753',\n",
       " ' 1019    320    315   1018    318   1019    317    815     21     48',\n",
       " '   48     53     52     52   4190    753     48    202     52     49',\n",
       " '   55    747     23    747    322    325     49    342     29    747',\n",
       " '   37    249    249     14      6   4181     14     12   4183    249',\n",
       " '   23    747     23    747   1049   1092    747     23    747    747',\n",
       " '  796     56     55     55      7     11     16      7     64    162',\n",
       " '   63     66    784     58     59     58   1171      3      3      8',\n",
       " '  177    812     39    175    175    177    177    178    177    175',\n",
       " '   23    350   2007     29   2007   2007    747     23     50    350',\n",
       " '  178    176    175    177    175    176     21    177    570     22',\n",
       " '   45     63      0      0      0      0      0      0      0      0',\n",
       " '   55     55     55     55     55    747    747     23    350   1379',\n",
       " '   52   1102   1102     23     21    570     22     39    570     56',\n",
       " '  350     55     55     55     55     55     55     20     21    229',\n",
       " '   30    513     49     49     38     21    784   4191     21     23',\n",
       " '   48   3359     38     56     55     55     50    222   3359   3346',\n",
       " '  229    229    229     21     21  11234  11234     23  11234     55',\n",
       " ' 1008      0      0      0      0      0      0      0      0      0',\n",
       " '  990     21    851    175    851    178    851    175     48     21',\n",
       " '  784   3359   3359   3346   3346   3359   3359   3359   3359   3346',\n",
       " '   55     21  11235   1434     22     38     99    106     30  11235',\n",
       " '  568     23     21     56     55     55      0      0      0      0',\n",
       " '  677    570    812    677    812    677    812    677    570    677',\n",
       " '   21    276    276    338   1981    278    276    338    276   4494',\n",
       " '  181   3253     23    182     23   3253   3253   3253     29    176',\n",
       " '41476  41476  41475  41476   6725  41475  41475  41476   6725   6725',\n",
       " ' 1979   1979     21     21     42     41     26     31     27     32',\n",
       " '  851   3253    181     23    182   3253   3253    181     23    182',\n",
       " '  177    176    175     23     21   1294     21     23     21     21',\n",
       " '  181   4192    181     23   4192    182   4192    181   4191   4191',\n",
       " '  551     38    551  11235    303  11235     46     48     37    752',\n",
       " '  178    175    177    178     21   1980     23     21     21   2397',\n",
       " ' 3253    262    815    570    815     45     21   3772   3772    145',\n",
       " '   29     45  11235     52  11235  11236  11235   1434     52    747',\n",
       " ' 4191    707     22     23     21     21     23    747     23    513',\n",
       " '   23    350    747     23     50     50     23    747   1379    324',\n",
       " '   55     56     55     56     55      0      0      0      0      0',\n",
       " '  981      0      0      0      0      0      0      0      0      0',\n",
       " '  324    747     23    625    625    617    152    747     23    156',\n",
       " '  323    262    747     23     23   1379    747     23    319    747',\n",
       " '  747     23     22     39    747     23    747     23    747     23',\n",
       " '   23   1116     23    747    513     23    747   4191   4191   4191',\n",
       " '   21    117   4642   4643   4642    117     32     30    516     22',\n",
       " '  117     30     30     30     35     29    222     50    516     46',\n",
       " '  117    117     52     48    117     37    117     23     52     33',\n",
       " '   45     29    117    156    117    319     30    117     23    570',\n",
       " '  229     38    989     21    753   1020    989   1021     48    990',\n",
       " '  814    812    570     23   2397    815    812   2397     21     39',\n",
       " '  544    229    229    229    229     21    656    229    229     21',\n",
       " '  812     22     23    570   7842    815    812     38     21   7842',\n",
       " '   21   7842     38   7842   7842     38   7842     39   7842   7842',\n",
       " '41476  41475  41476  41476      0      0      0      0      0      0',\n",
       " '   21   7842   7842   7842     23     22     39   2397     21   1980',\n",
       " '   23     21    752    747     23    747     23    752     56     55',\n",
       " '   21     22    117     39    117    117    117    117    570    117',\n",
       " '   20     21    229    229    229    229    229    229     21    656',\n",
       " '   21    747    747    747     23    747    568   1379    747    747',\n",
       " '   21    989    532    753   1020   1020    989   1021   3012     48',\n",
       " '   48    989     21   1020   1021    989    532   1021    222    544',\n",
       " '  229    229    229     21    568     21    175    177    176    177',\n",
       " '  229    229    229    229    229     21    229   2371     21   2371',\n",
       " '   48    175    178    175    177    178    177     21    747     23',\n",
       " ' 3773   3772     35     21    142   3773     32    125   3772   3772',\n",
       " '  145    177    175    141    175    141   3772   2762    175    177',\n",
       " '  176    175    177    178    178    175   3773    833    314    834',\n",
       " '   29     30     49     30     50   3772     48     37     33    177',\n",
       " '   55     23   1014   1013     21   1013   1015   1013   6103     21',\n",
       " '   56     55     55     45     52    960    961     48     52     52',\n",
       " '   34     26     31     31     26     41     36     35     30     37',\n",
       " '   55     55     49     50     48    784      0      0      0      0',\n",
       " '   38     37     29     31     31     29     42     33     29     21',\n",
       " '   55     56     55     55     55     55     55      0      0      0',\n",
       " '  175   3772     29   1919     39     30     22     21    570    815',\n",
       " '  162     23    812      0      0      0      0      0      0      0',\n",
       " '   21  17940  35254  35254     21      0      0      0      0      0',\n",
       " '  350    350    747     23    747    350    350    752     23     52',\n",
       " '  568    752    747     23    747    747     23     29    752     23',\n",
       " '  820   1446      0      0      0      0      0      0      0      0',\n",
       " '26881  26881     21    570    570   1980   1980    812   1980   1980',\n",
       " '   56     55     55     52     52     22     21     23     56     55',\n",
       " '28173  28174  28173  28173  28173     38     21     21    940     23',\n",
       " '   49    800   4313     53  39279    196     52    175  39280  39281',\n",
       " '   75    197  39282  39283     52  39282  39282  39282   4313   3110',\n",
       " '   23     52    513     50     50     21    851    175    175    851',\n",
       " '  670   6103    669    217    217     23     52    222    341    175',\n",
       " '  851     21    175    178    851     48    851    176     23     21',\n",
       " '  747    157     29     29    747     23    747    747     23    747',\n",
       " ' 4313    516   4314   4315     30   4313    516   4314     48    117',\n",
       " ' 4314     52     48   3110     30    704    704     46    704     46',\n",
       " '39279     52    666    660    661    639   4617    652  39284    658',\n",
       " ' 4271  39284    559    666    558  16862  39284    639  39279    639',\n",
       " ' 3003    559    559  39283    559    559     52     21  39285    759',\n",
       " '  197  39285     37     21   5029   5028  39285   5030   5030   5030',\n",
       " ' 5030  39285     45     55     56     55     39    666    707     22',\n",
       " '  570     39     49    570     50     48    570     56     55      0',\n",
       " '  812    570    677    677    677    812    812    677    677    677',\n",
       " '   23    747   1379     23    747    747    747     23    350    747',\n",
       " '   23     21    222     50     50     48     45     66     67     68',\n",
       " '  747    350     23     23     23    747   1379    747    350     23',\n",
       " '  747    350    229     21     20    229    229     21    229     21',\n",
       " '   23     52     23   2359     23     22    570     23     52     23',\n",
       " '   55     56     45     66     67     69     70     71     68     69',\n",
       " '  117    117    117    117    117    570     56     55    570    570',\n",
       " '  229     21  11235    551     30    752     37     29  11236     56',\n",
       " '    8      3      3   6897      4     14     14      8      6   6898',\n",
       " '  948    959    959    948    167      3    167    384     21     23',\n",
       " ' 3346     53     52     52     52    800     21     23     38    242',\n",
       " '   21     21   4802     23   4803     38     21     22     23     22',\n",
       " ' 6898     14      7     10   1200      3      7     11     15     15',\n",
       " '  176    851    178    178    175    851     21    177    175    175',\n",
       " '   23     21   4804     38     23     21     21    167    268    271',\n",
       " '  167    269    790   1915   1914    270    792   1914    790     30',\n",
       " '  791    268    791     30     32   1914    789    792    793     35',\n",
       " '   29     30      3    796   1915    268    788     67    272     30',\n",
       " ' 4804     70     69     68     71     67    162     71     69      3',\n",
       " '   37    272     30     37     33      3     29   4185      3    269',\n",
       " '    7   6898     12     14   6898     16   6898   6899   6898     14',\n",
       " '  270    271    796      3    268     30    789   1915   9651   1915',\n",
       " '   30    788     29     35    268     29    794    272      3     29',\n",
       " '   30     37      4   9652    272   9652    794      6      8   9653',\n",
       " '    3      4      8     14   9652    272    794   9652      6      8',\n",
       " '    3      4   9652     14   9652   9652      8      7      7    794',\n",
       " '   45     45     45     21     23     21     23   5063    175   5062',\n",
       " '   56     55      0      0      0      0      0      0      0      0',\n",
       " '  272      3     12     10      3   1919     11     16      4   9652',\n",
       " ' 9652   9652      3      8     14     15     11      7     12     16',\n",
       " '   67     70     71     70    167     63     66     55     56     55',\n",
       " ' 1919     45     29     33     18    269   9652     18   9653    269',\n",
       " '  272    272      3     14   9652   9652     65     11     64     63',\n",
       " '13598   1980   3398    570  13598   1980   3398   1980  28480   1980',\n",
       " '   66     29      0      0      0      0      0      0      0      0',\n",
       " '   23     52     23    776     56     55    776    776    776     21',\n",
       " ' 1980    812     21     21     21   1551    570    812     22    570',\n",
       " '   55     55     55     55     22    747     23    513   1379   1379',\n",
       " '  747     23    513    350    350     20     21    229    229    229',\n",
       " ' 6898   6899     21     88   1922     18     21     21     30   6900',\n",
       " '   45    784     45     23     23     21     22     23     22     23',\n",
       " '  812    677    812    677    616    677    570    812    677    570',\n",
       " '  178    177     23     52     20     21    229     21    229    229',\n",
       " '  820    820     45     21     23     23     21     39    982    812',\n",
       " '  229    229    229     21     21  11237  11237  11237    752     56',\n",
       " '  776     23    616    616    677    617    677    679    616    677',\n",
       " '   23     21   2371   2371     23     21   3253    181    182    181',\n",
       " '  202    962     35    962     52     52     50     52     49     46',\n",
       " '   29    962    962    962    962    962     29     35    962     29',\n",
       " '   37     29     21   3346     37   3346   3346     38     23   3346',\n",
       " '   37    962    962     29     35    962    962    962     35     29',\n",
       " ' 3356     38     21   3358   3357   3357   3356     23     21     30',\n",
       " ' 6901    106    896   3346   3358     21     22     39     30     32',\n",
       " ' 6902   6901     35     22     37     39    896   6902     33    569',\n",
       " '  981     66      0      0      0      0      0      0      0      0',\n",
       " '  962    962     35     29    962    962    962    962    962    962',\n",
       " '  962    962    962    962    962    962    962    962    962    962',\n",
       " ' 6903     38     29    569    569   6903   6903     21   6903   6903',\n",
       " '  962    962    962    962    962     37    962    962    962    962',\n",
       " '  962    962    962    962    962    962    962    962    962    962',\n",
       " '  962    962    962    962    962     32     30    812     22    570',\n",
       " ' 6903     88     21     21   6904   4398   6904   6903   6903   4399',\n",
       " ' 6903   4398   4402     21   6903   4399   4398   4400   4399   1033',\n",
       " '   52     23   2360   2360     23     30    352     32     52    202',\n",
       " ' 6903      1   4398   4399   4398   4400   1922   6898      0      0',\n",
       " '  156   2360     35     23   2360     52    131     29   2361     46',\n",
       " ' 2360   2361   2361     37   2361     33     29     45   2361   2361',\n",
       " '   21     63   1547   1547    784    784     73      0      0      0',\n",
       " '  175    175    177    175    177    175    178    177    178    177',\n",
       " '  175    176    177    177    176  19452   2425   2426   2427   2425',\n",
       " '   21     23     39     56     55     55    962     35     29     37',\n",
       " '  812    676    679     39    676    679    812     22     22    814',\n",
       " '   56     55     55    222     23     21     52     53     52     21',\n",
       " '   23    570     23     22    814    812    570    812     22     39',\n",
       " '  815    812     22    812    816    570    616    570    812    815',\n",
       " '   70     71     69     71     67     69     70     23     23     22',\n",
       " '  570    812    616    616    616    616     23     23    616    616',\n",
       " '   49     49     55     56     55    222     50     48      0      0',\n",
       " '   23     39    987    986    988     56     55      0      0      0',\n",
       " ' 2361   2361   2361   2361   2361   2361     22     39   2361   2361',\n",
       " '   21     22     23     21     22   1102     39     22     39   1102',\n",
       " '   67     66    167     67     69     70     71     68     69     67',\n",
       " '   70     70     71     69     29     66     63    270    270    270',\n",
       " ' 1102   1102   1102    570     22     21     23    570   3346    570',\n",
       " '   21    177    175    178    175    178    177     21  18385  18385',\n",
       " ' 3876   3876    570    989     38     21    568   1020    989   1021',\n",
       " '   23     23   2168     23   2168     23     63     66     23    784',\n",
       " ' 1021    990    544    990    544     21     21   4391     23  12375',\n",
       " '  812    570   1980    167    167    167    167    359    384    167',\n",
       " ' 7867   2425   2425   3062   2427   2425   2427   2428   2425   2426',\n",
       " '    1    391  21702    756    756   2428   2427   2425   2425   2427',\n",
       " '  197     53    196     52    625     56     55      0      0      0',\n",
       " ' 2428   2425   2426   2425     76   2426     29    395    140    394',\n",
       " ' 2429   2425    394   3242     42    396    397   2425   2426   2426',\n",
       " '   75   2425  21703   5168   2429     77   5167   5168   2428   5169',\n",
       " '   23     21   4664   5170   2217   5168   2051   4663    936   5168',\n",
       " ' 2458   2458   2428   2428   2428    144    142    141    459   2428',\n",
       " '  570    616     22    812    106    812    812    570    570    816',\n",
       " ' 2361   2361   2361     55     56   2361   2361   2361   2361   2361',\n",
       " ' 2425   2427   2428   2428   2428   2425   2425   2428   2428   2428',\n",
       " '    3   6056     23   1600   1600   6056     38     32     23   6056',\n",
       " '   30   1600   6056     35   6056   6056   1600     29     30   1600',\n",
       " ' 6056     22     22     22     37     37     39     29   4496     29',\n",
       " '   55     56     55     52     53     21     38    989    532    753',\n",
       " '  182     23    242    242     29     29    242     56     55     55',\n",
       " '12375   4391   4391     23     23     21     21     27     26     31',\n",
       " '   23     39     76     39     75     23  28481     76     75     80',\n",
       " '   77     77     80  28481     80     77    812    570  28481  28481',\n",
       " '   22     23     23  39286     23    549     38     30     32  39286',\n",
       " '28481  28481   6056     29   6056     33     29   6056   6056     23',\n",
       " '   35     30     29   6056     29     29     29     29   6056     33',\n",
       " '   55     56     55     55     55     55    986    988    987     56',\n",
       " ' 2426   2425   2426    140    125   2428   2426  21704    465    465',\n",
       " '   38     34     38     41     31     42     21    220   1102   1102',\n",
       " ' 3876     21    940    942     53     52    389    940    388   1359',\n",
       " '   26     31     42     32     22     35   1102     30     31   1102',\n",
       " '   36     31     22     29   1102     37   1102     41     37   3876',\n",
       " '   55     21   1102     21     52   1102   1102     21    181     21',\n",
       " '   55      0      0      0      0      0      0      0      0      0',\n",
       " '   35   6056     29    167     29     37     22     33    359    384',\n",
       " ' 2428   2428   2427   2428   2428   2428   2428   2428   2428   2428',\n",
       " '  167    167   1109   1109    119  28482    812    384     36  28482',\n",
       " ' 1109    151     36  28482  28483   4196     36   1109    119   1980',\n",
       " '  119   1109  28483    119   1109     38   1108  28482     36     22',\n",
       " '   35     29     37    133     30     33     29     37     30     23',\n",
       " '   30     35     22   1980    133     37     29     37    117     30',\n",
       " '  167    167    359    167    167    270    270    270    270    167',\n",
       " '   21     21     29     45     33     29     27     29     23     21',\n",
       " ' 1016   1134    181   1016    182     23   1016     21    181   1134',\n",
       " ' 1980     39     30     22     33     29   1980   1980   1980    305',\n",
       " '   21    181    242     21     21    106     99    747  30285   2377',\n",
       " '  747  30285     23  30285     46    747    639     52    639    747',\n",
       " '   46  30285    639     23     52    639     30  30285     30    513',\n",
       " '  747  30285     37  30285     23    570     22    784     21    784',\n",
       " ' 2428   2428   2425   2428   2428   2427   2428   2428   2428      0',\n",
       " '28708     22     23  28708     23     23     52     22     23    752',\n",
       " '  812    677    812    677    812    570    774    677    812    677',\n",
       " ' 2361   2361   2361   2361   2361   2361   2361   2361   2361   2360',\n",
       " '   23     23    752     23    617     52     23     23    752     23',\n",
       " '  752     39    747     23    513    747    747     23    747     23',\n",
       " '  989   1021   1020   1020     48   1021    544     21     21    242',\n",
       " '  752     23     23     23     23    752     23    752    752     23',\n",
       " '  747    350    747     23     23    751    350    350    350    752',\n",
       " '  718    306    270    721    717    720    719    570   1980   1980',\n",
       " '  752     23    752     23     23    752     23    752    752     52',\n",
       " '  270  32480  22776    167  32480  32481  22776  32480    167   2590',\n",
       " '   23  28708  28708     23  39287     23    752  39287  39287  39287',\n",
       " '32480     23   2589   2589   2589    390    940   2589    941    942',\n",
       " '  940    941    942    942    941    940   2589    940    941    942',\n",
       " '  941   2589   2589    319     29     32     30     22     35     22',\n",
       " '   23    242    242    182     29    568     23     23     21     21',\n",
       " '   39     30     29     30     22     22     39     22     37     22',\n",
       " '   37     22    270    270    270    270    270    270     29    167',\n",
       " '   33    167    167    167    167    362    363    360    364    360',\n",
       " '  167    363    364    362    363    167    360    364    362    167',\n",
       " '    3    167    384    167    167    363    167    363    167    363',\n",
       " '  812     22     99    812     99     99    812     99     22    677',\n",
       " '  167    167    363    362    364    360    363    384    167    362',\n",
       " '  360    363    167    167    167    167    364    363  32482   2427',\n",
       " '  139    609  32483   3285  32484    702  32485   3554   8119  32486',\n",
       " '  167    363   9493  32487   1800    363    167    167    363    167',\n",
       " '  167    167    102     38  32484   1434    106    728  32484    896',\n",
       " '  612  32484    109   1434  32484    107    105   4616    105    102',\n",
       " '  103     99    106    102    106  32484    109    102    113     22',\n",
       " '  105    109    896     39    109    102     22    105     29    113',\n",
       " '   55     56     55   4313   3110    516   4314    516   4315     30',\n",
       " '  570    570    570    197    196     55     56     53     52     52',\n",
       " ' 4314    117   4314    704   3110    704     23     37     29     22',\n",
       " '   23     21     50    963    963    963    963    963    963    963',\n",
       " '   35    516     32  32484     39  32484    270    270    270    270',\n",
       " '  270    167    270    167    167   3749    139    836  14426    138',\n",
       " '   21  18386    106     99    106     99  18386     52     53    196',\n",
       " '   30  14429   3100  14428   3775    836    138    139   3749   3775',\n",
       " '  836     37   3749    125   3749   3749   8085  14430    142    459',\n",
       " '  677    677    678    677    678     22    677     23     22     22',\n",
       " '  144    141  14430    392    139   3749    148     35   3777   3778',\n",
       " ' 3749     30     29     22     39     22     30    836    836    836',\n",
       " '   23    812    677     99     22    616    616    616    677    616',\n",
       " '  677    570    570     23    677    677    776     23    677    570',\n",
       " ' 3749    167    384      3    167    148   3749     33    270    270',\n",
       " '  616    570    812    677    617    678    677    812     99     99',\n",
       " '   48     52     22     52    984    984     23     21     39     22',\n",
       " '  270    270     29     33    270    167    167    167    167    167',\n",
       " '  196    197    570    322    117    117     56     55     55    570',\n",
       " ' 3253     29   3253     21     56     55     55    196    197     52',\n",
       " ' 2360     23     23     53     52     30    319    352     35     32',\n",
       " '   38    500    507    506    504    505    502    503    500    503',\n",
       " '  156     29     23     30     33     29     23     29     23     35',\n",
       " '  501    507     38    167    503  32488    506    622  32488    621',\n",
       " '32489  32490  32489    509    504    503    508  32488  32491     35',\n",
       " '  500    502    501    503     22  32491    506    256    503   1107',\n",
       " '   35    511    256    503    506    500     22  32491    502  32491',\n",
       " '  508     22     39     30    513     22   6831    151    502    500',\n",
       " '  501   2388    503     39    503    502    514    518    157    500',\n",
       " ' 1049    325    324    262     23     23     35     29     29     29',\n",
       " '  516     30     37    117     29  32491    162     39     22     37',\n",
       " '  963    963    963     23    570     21    963    963    963    962',\n",
       " '  946    948    951    950    946    948    945    946    946    949',\n",
       " '  945    947    946    945    951    953    945    947    946    953',\n",
       " '  946    947    952    957    953    947    946    958    953    946',\n",
       " ' 5768    681    338    681    704    681   5768    182    745    704',\n",
       " '  812     99     99     99    812     99    812     99     99     99',\n",
       " '32490    341  32490   2338   1919     37     37  32488     30   1919',\n",
       " '  947    958    946    953    947    946    953    957    947   1033',\n",
       " '  681     32     30    681    516     35    117    516     30     46',\n",
       " '  953    958    946    947    946    958    946   1033    946    958',\n",
       " '   21     21    568    989   1020    568   1021     21    989     21',\n",
       " '  946    954    948    948    946    946    946    946    946    946',\n",
       " '   33     37     23     35     23     29   2361     23    131     35',\n",
       " '  946    946    946    946    951    948    948    570    747     23',\n",
       " '  681     33     29    202     52   5858     37     52     21     21',\n",
       " '  322     23     29   2361   2361     37   2361     33     29     29',\n",
       " '32488     29     33    621  32489  32490  32489  32491     35     29',\n",
       " '  989    568   1020   1021    532    568    948    959     23     21',\n",
       " '  962     35     29    962    962    962     35     29    962    962',\n",
       " '   33     29    500    256    756  32492   1094    756   1094    500',\n",
       " ' 4594   4592     48   4594   4594    989     21    989   1021    532',\n",
       " '   35     29     32     37    962    962    962     35     29    962',\n",
       " '  500     37    167    167      3     22     33     29  32488  32488',\n",
       " '  812   1980   1980   1980   1980   3346   3346   1980    812   3347',\n",
       " ' 2360   2361     33    987    988    986   2361   2361   2361   2361',\n",
       " ' 1020   1021     22     39    568    568   4267     21   4267     21',\n",
       " '  621     30  32490  32489     35     32  32491  32489   1919     22',\n",
       " '  962     35     29    963    963     37     23    707    570     21',\n",
       " '   37     30  32488    621     33     29  32490  32489  32489  32491',\n",
       " '   35     37  32488     33     22     29    621     23  32489     23',\n",
       " '  812     22    812    616    812    616    570    616    616    617',\n",
       " '   52   1037    812     53     52     52     56     55     55     52',\n",
       " '   21   2281   2281     85     48     52  13168     21    679    676',\n",
       " '   30  32490     23     35  32491     22    319    319    117    384',\n",
       " '  197    625    722    722    722    722    722     52     22     52',\n",
       " '  570    812    570    812     99     99     23    616     99     99',\n",
       " '  167     37    167  32493  32493    490  32493    167  32493  32494',\n",
       " ' 2361     22   2361     22     22     22   2361     39   2361   2361',\n",
       " ' 7584   3887  32335   7584   7584   8746  32335   7584  32335   7584',\n",
       " ' 8746  32495    117   7584     29   1919     33   7584   7584    167',\n",
       " '   52     53     21   5406   5406   5406   5406   5406     21   5404',\n",
       " ' 5406   5404   5404   5406   5406   5404   5404   5406   5406   5404',\n",
       " ' 5406   5404   5406   5406   5404   5404   5406   5406   5404   5406',\n",
       " ' 5404   5404   5406   5406   5404   5406   5404   5406   5406   5406',\n",
       " '  722     22     39   7188   7187   7188   1995   7188   1994    890',\n",
       " ' 5406   5406   5406   5406   5406   5406   5406   5406   5406   5406',\n",
       " '   85    388   1359   1122   1359     85   4329   1373   3848    797',\n",
       " ' 5406   5406   5406   5406   5406   5406   5406   5406   5406   5406',\n",
       " ' 5406   5406   5406   5406   5406   5406   5406     23     21     56',\n",
       " ' 5898   5898   5898     23   1228     21   1229     21   1102     21',\n",
       " ' 2361   2361   2361     23     56     55     22    570      0      0',\n",
       " '   56     55     48     48    202     21    513     23   4191    784',\n",
       " '   30   7584   7584      3    167    384    167    167    167    363',\n",
       " ' 1980   1980   1980    812    812   3347   1980   1980   1980   1980',\n",
       " '   23    814     39    815     22    570    570    812      0      0',\n",
       " '   99    812     99     99     99     99     99    812     99    812',\n",
       " '   55     56      0      0      0      0      0      0      0      0',\n",
       " '   23    784     56     55     55   4313    516   3110   4314    117',\n",
       " '   22    570    570    677    677    816    812     39    676    677',\n",
       " '   55     55     55    988    986    987      0      0      0      0',\n",
       " '  896   7188    896    896   7188   7188   1995   1994   1995   1995',\n",
       " '   99     99     99    776     99    812     99    816     99     99',\n",
       " '   55     55     57     49     52     53     52     52     52    800',\n",
       " '  988    986    987      0      0      0      0      0      0      0',\n",
       " ' 1995   1995   1995    896   1995    896   7188    896   7188   7188',\n",
       " ' 1980   1980   3347   1980   1980   1980   1980    815    812     21',\n",
       " ' 3849    942    617    940    941     52     52     21     52     52',\n",
       " ' 7188   7188   7188   7188   7188   7188     45     52     23    656',\n",
       " '  948    959     56     55     55    945    952    945    948    957',\n",
       " '   56     55     55     55     56      0      0      0      0      0',\n",
       " '  962    962     29     35    962     35     29    962    962    962',\n",
       " '  962    962    962    962    962    962    962    962    962    962',\n",
       " '  962    962    962    962    962    962    962    962    962     37',\n",
       " '  959    948    948    959      0      0      0      0      0      0',\n",
       " '28484  28484    570     21     30     38  28484  28484     32  28484',\n",
       " '   99     99     99     99     99     99     99     99     99     99',\n",
       " '   35     29     33     29  28484     30  28484     35    812     29',\n",
       " ' 1980   1980   1980     37     33     29     30  28484  28484  28484',\n",
       " '  962     35    962    962     29    962    962    962    962    962',\n",
       " '  962    962    962    962    962    962    962    962    962    962',\n",
       " '  962    962    962    962    962    962    962    962    962    962',\n",
       " '  962    962    962    962    962     37    962    962    962    962',\n",
       " '  962    962    962    962    962    962    962    962    962    962',\n",
       " '   29     35     33     29    812     21  28485     37  28485    812',\n",
       " '  962    962    962    962    962    962    962    962    962    962',\n",
       " '  962    962    962    962    962    962    962    962    962    962',\n",
       " '  962    962    962    962    962    962    962    962    962    962',\n",
       " ' 1102   1102     23    707     21     56     55     55      0      0',\n",
       " '  962    962    962    962    962    962    962    962    962    962',\n",
       " '   53     52     21     38    989    753   1020    989   1021   1021',\n",
       " '  962    962    962    962    962    962    962    962    962     30',\n",
       " '   48    544     21    989    989   1020   1021     21  25218     30',\n",
       " '  167    167      3    167    167    167    167    363    167    363',\n",
       " '  362    360    363    167    362    500    609    606    766    167',\n",
       " '  363  32496  22705    337   1548  32497    340    167  32498    363',\n",
       " '  384      3    167    167    167    167    363    167    363    363',\n",
       " ' 1798    362    364    384    167    360    363    363    362    360',\n",
       " '  167    363    364    363    360    362    167    364    167    363',\n",
       " '  167    363    167    167    363    167    167    362    363    167',\n",
       " '  360    364    362    364    167    360    363    363    167    167',\n",
       " '   46  25218     46     21    106     38    303    551     30   1434',\n",
       " '  363    364    360    362    167    363    360    364    362    167',\n",
       " '  360    363    362    364    167    363    167    167    363    362',\n",
       " '  962     35    962     29    962     35    962     29    962    962',\n",
       " '  363    167    360    364    167    363    167    360    362    364',\n",
       " '  363    363    167    167    167    167    363    167    167    362',\n",
       " '   99    812     99     99     99    570     99     99     99     99',\n",
       " '   23     52     23     52     23     52     23   1018   1017    317',\n",
       " '11235     22     99    551     56     55     55     37    568    990',\n",
       " '   45     21     20     21     23     22     23     21    812     22',\n",
       " ' 1017   1019    318    317      0      0      0      0      0      0',\n",
       " '  962    962    962    962    962    962    962    962    962    962',\n",
       " ' 3729   7412   9587   8060    384    167   3729    363    687  32499',\n",
       " '32500    655  32501    684  32502  32503    363    167    363    363',\n",
       " '  962    962    962    962    962    962    962    962    962    962',\n",
       " '   39    812     21    812     23     39     23     22    812    812',\n",
       " '  363    167    363    363    167    363    363    167    167    167',\n",
       " '  962    962    962    962    962     37    962    962    962    962',\n",
       " '  676     22    679     22     39    676    679     22    812    812',\n",
       " '  364    167    362    360    363    364    360    362    167    363',\n",
       " '   23     52     23   3480   3480    677     23     21   3480     39',\n",
       " '  962    962    962    962    962    962    962     35     29    962',\n",
       " '  363    364    360    362    167    139      3    384    167    656',\n",
       " '  766    139    500  14869    167    363    363    363    363    167',\n",
       " '   23    570    814    814    815    812    570    812     22    815',\n",
       " '   29     45   1434  11235  11236     52  11235     52    568     23',\n",
       " '  167    139    363   2427  32304    167    363    363    363    167',\n",
       " '  962     35     29     37     55     56     55     39     23     23',\n",
       " '  167    363    363    270    270    167    167    270    270    270',\n",
       " '  774    677     63     66    677    677    677    812     22    774',\n",
       " '   21    570      0      0      0      0      0      0      0      0',\n",
       " '   23   1379   1379     21     38    989    753    989   1021   1020',\n",
       " '  679     22    677    616     23     49     52     53     52    800',\n",
       " '   52     52     52     21    678    679    676     39    677     23',\n",
       " '   21  25219     35     29     30  25219  25219  25219  25219  25219',\n",
       " ' 1021     48    544     55     56     55    752    568     48    990',\n",
       " '   22     21    616     52     52     53     52    800     21    676',\n",
       " '   21   5898   5898     38     21   9691    175   9691    175     21',\n",
       " '  175   9691    178    176    989   1020    989   9691     21   1021',\n",
       " '  568    989    175   1021    532    175   9691     21    568     23',\n",
       " '   55     55     55     55     55     55     55    196    197    625',\n",
       " '   99     99     99    570    776     99    812     99     99     99',\n",
       " '  707    677     39     23    988    987    986     23     52     23',\n",
       " '25219     37  25220     22     39     29     33     32      0      0',\n",
       " ' 1922    784     71   6905   6905     71     14   1922   6898     65',\n",
       " '   52    197    196     53    625      0      0      0      0      0',\n",
       " '   52     52     52     52     56     21    570     22     39     23',\n",
       " '   52     52    676    679   5932    229     21    814     23    815',\n",
       " '  946    948    951    945    948    958    946    945    949    956',\n",
       " '  950    947    951    949    945    946    950    946    953    947',\n",
       " '  946    953    947    953    946    947    947    953    946    946',\n",
       " '  947    953    953    946    947    954    947    946    953    957',\n",
       " '  946    947    946    948    948    948    948    784      0      0',\n",
       " '   23     21    989     21   1021    989     21     21  35776  35776',\n",
       " '   55     56     55    948    959    948    959      0      0      0',\n",
       " '  812    812   6801     52     53   6801     21   6801     21    812',\n",
       " '  812    616     23     23    679     21    616    812    676     39',\n",
       " '   99    816     99     99     99     99     99     99     99     99',\n",
       " '  812    774     21    812    570     21     21    812    812     73',\n",
       " '   52     52   5933     21   5933   5933    812     39     23    679',\n",
       " '   55     56     55    800    784      0      0      0      0      0',\n",
       " '   21     21     21   1021    989   1021     21   9691   9691    175',\n",
       " '28854  35776  35776  35776  35776  35776  35776  35776    570     39',\n",
       " '  677     39    678     23    676    679      0      0      0      0',\n",
       " '  812      0      0      0      0      0      0      0      0      0',\n",
       " '   39   1038     22    847    774    570     21   5933    196    197',\n",
       " '  178   9691     21    989    989   1021    568    568   3346   3346',\n",
       " '  616    677    617    570    677    570    678      0      0      0',\n",
       " '   21     21    707     23    570     21    197    196      0      0',\n",
       " ' 1037    812    676     39    812    679    676    679     39    812',\n",
       " '   99     99     99     99     99     99     99    812     99     21',\n",
       " '   22      0      0      0      0      0      0      0      0      0',\n",
       " '  814     23     22    812     23     22    816    815     39    812',\n",
       " '  815     22     22   9908   1903     30   1903   4238   9908     37',\n",
       " '  722    722    812    812      0      0      0      0      0      0',\n",
       " '   23     39    229     21    940    941    942   5932    679    676',\n",
       " '  812      0      0      0      0      0      0      0      0      0',\n",
       " ' 5932   6800      0      0      0      0      0      0      0      0',\n",
       " '   22     37    812   1547   1547   1547     29     45    106   1921',\n",
       " '  820    820     45     21     21     23     21     23     21    106',\n",
       " ' 6897   1922      0      0      0      0      0      0      0      0',\n",
       " ' 3359      0      0      0      0      0      0      0      0      0',\n",
       " ' 1921   1921   1921   1921   1921   2425  19452   2426   2427   2425',\n",
       " ' 4314   4315    516     30     48   4314   3110    704    704    704',\n",
       " '   23     37     23   2155     23     38   2155    145   2156   2155',\n",
       " ' 3062   2427   2426   2428   2427   2425   2427   2425  21705    399',\n",
       " '  399  11333   2426  11333   2425   2425   2426    395    394    394',\n",
       " '  140    396    397   2426   3106   3634   2376   2426   3634   3106',\n",
       " ' 2428   2428   2428   2428   2428   2428   2428   2428   3106     21',\n",
       " ' 4802     23   4803     38   4804     38   4802   4804   4804     21',\n",
       " '   29   2156   2155   2155     22     23     23     23     23  18598',\n",
       " ' 1035     23     21     21     22     23     21     22      2      3',\n",
       " '   23   2428     22     23     21   2428   2428   2428   2428   2428',\n",
       " '   21     22     21    570    570     22     21   9894    102   1036',\n",
       " ' 1903    106    106    106     21     22     21    229     22     21',\n",
       " ' 9894     76     30   4616     22   9894     75     77      1    103',\n",
       " '  106     22     37    105     75     22     37    102    113     39',\n",
       " '   77     99    103    106     22    102     39     22    103     39',\n",
       " '   21     23     21   9901    102   9894   9894     30     76    105',\n",
       " '  102   9894     99   9895     45     29   9894   9894     99     99',\n",
       " '   22     23     45     21     23     22   4804   4804     63   4804',\n",
       " '  270    167    167    167    360    363    364    362    362    167',\n",
       " '  364    360    363    167    360    362    364    363      3    384',\n",
       " '  167    363    167    167    167    167    363    167    363    167',\n",
       " '37616  20058     21     23      3  20058  20058      3      3      4',\n",
       " '  360    364    362    384    363    167    360    362    364    167',\n",
       " '  363    167    363    363    167    167    363    362    360    167',\n",
       " '  364    363    363    167    362    363    360    364    362    363',\n",
       " '   22   9894     75     99   4616    103     37    106     22    105',\n",
       " ' 2428   2428   2428   2428   2428   2428     21     38   2428   2428',\n",
       " '  106     75     39    103   9894     77     75     39    113    102',\n",
       " '  364    167    360    167    362    360    364    363    362    167',\n",
       " '   37    102     22   9894   9895   9894     76    879     80     76',\n",
       " '  784      0      0      0      0      0      0      0      0      0',\n",
       " '  360    363    363    363    167    360    364    362    270    270',\n",
       " '  270    270    270    270    270    270    270    167   1548    167',\n",
       " '   56     55     55      0      0      0      0      0      0      0',\n",
       " ' 1548   1548   1548    270    270    270    270    270    270    270',\n",
       " '   39    102     80    879     77    879     80     80    879    879',\n",
       " '  568  18598  18598     32     35     29  18598  18598  18598     30',\n",
       " '   77    879     80     77     80    879    879     75     77     77',\n",
       " '20058      5      6  20058      5      7  20058      8      5      7',\n",
       " ' 2155     22     39     37   2155     37     39     33     29  18598',\n",
       " ...]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "column_sites = ['site'+str(i) for i in range(1, 11)]\n",
    "train_df[column_sites].to_string(index=False, header=False, na_rep='').split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "site=[\"site%s\" % i for i in range(1, 11)]\n",
    "full_df = pd.concat([train_df.drop('target', axis=1), test_df])\n",
    "idx=train_df.shape[0]\n",
    "full_df[site]=full_df[site].fillna(float(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_df['str0']=full_df[site].apply(lambda x: str( \" \".join([str(a) for a in x.values if a != 0])), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, TfidfTransformer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from collections import Counter\n",
    "import pickle\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y = train_df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-102-847477591205>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mpipeline0\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfull_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'str0'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mX_train0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpipeline0\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfull_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'str0'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mX_test0\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpipeline0\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfull_df\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'str0'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\sklearn\\pipeline.pyc\u001b[0m in \u001b[0;36m_transform\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    443\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransform\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msteps\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    444\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mtransform\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 445\u001b[1;33m                 \u001b[0mXt\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtransform\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    446\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mXt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\sklearn\\feature_extraction\\text.pyc\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, raw_documents, copy)\u001b[0m\n\u001b[0;32m   1378\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'_tfidf'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'The tfidf vector is not fitted'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1379\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1380\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mTfidfVectorizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1381\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\sklearn\\feature_extraction\\text.pyc\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, raw_documents)\u001b[0m\n\u001b[0;32m    891\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    892\u001b[0m         \u001b[1;31m# use the same matrix-building strategy as fit_transform\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 893\u001b[1;33m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_count_vocab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfixed_vocab\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    894\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    895\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\sklearn\\feature_extraction\\text.pyc\u001b[0m in \u001b[0;36m_count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m    760\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 762\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[1;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    763\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\sklearn\\feature_extraction\\text.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(doc)\u001b[0m\n\u001b[0;32m    239\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m             return lambda doc: self._word_ngrams(\n\u001b[1;32m--> 241\u001b[1;33m                 tokenize(preprocess(self.decode(doc))), stop_words)\n\u001b[0m\u001b[0;32m    242\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\sklearn\\feature_extraction\\text.pyc\u001b[0m in \u001b[0;36m_word_ngrams\u001b[1;34m(self, tokens, stop_words)\u001b[0m\n\u001b[0;32m    138\u001b[0m             for n in xrange(min_n,\n\u001b[0;32m    139\u001b[0m                             min(max_n + 1, n_original_tokens + 1)):\n\u001b[1;32m--> 140\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_original_tokens\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mn\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    141\u001b[0m                     \u001b[0mtokens\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\" \"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moriginal_tokens\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mi\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pipeline0 = Pipeline([(\"vectorize\", TfidfVectorizer(ngram_range=(1, 3), max_features=100000)), (\"tfidf\", TfidfTransformer())])\n",
    "pipeline0.fit(full_df['str0'][:idx].ravel(),y)\n",
    "\n",
    "X_train0 = pipeline0.transform(full_df['str0'][:idx].ravel())\n",
    "X_test0 = pipeline0.transform(full_df['str0'][idx:].ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('../../data/site_dic.pkl', \"rb\") as inp_file:\n",
    "    site_dic = pickle.load(inp_file)\n",
    "\n",
    "inv_site_dic = {v: k for k, v in site_dic.items()}\n",
    "inv_site_dic.update({0: ''})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df['str']=full_df[site].apply(lambda x: \" \".join( [inv_site_dic[a] for a in x.values if a != 0]), axis=1)\n",
    "full_df['str']=full_df['str'].apply(lambda x: x.replace('.', ' '))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 21s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "pipeline = Pipeline([(\"vectorize\", TfidfVectorizer(ngram_range=(1, 3), max_features=100000)), (\"tfidf\", TfidfTransformer())])\n",
    "pipeline.fit(full_df['str'][:idx].ravel(),y)\n",
    "\n",
    "X_train = pipeline.transform(full_df['str'][:idx].ravel())\n",
    "X_test = pipeline.transform(full_df['str'][idx:].ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<253561x100000 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 10782248 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "cv_scores = cross_val_score(logit, X_train, y_train, cv=time_split, \n",
    "                            scoring='roc_auc', n_jobs=2) # hangs with n_jobs > 1, and locally this runs much faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.78775387,  0.65327624,  0.86849087,  0.94255134,  0.83400806,\n",
       "         0.86883177,  0.90653312,  0.88133506,  0.92016224,  0.92841155]),\n",
       " 0.85913541173136654)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_scores, cv_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96117249982623942"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_auc_lr_valid(X_train, y_train, ratio=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_tfidf_alicemin2 = csr_matrix(hstack([X_train, \n",
    "                             new_feat_train['alice_tminutes2'].values.reshape(-1, 1)]))\n",
    "X_test_tfidf_alicemin2  = csr_matrix(hstack([X_test, \n",
    "                             new_feat_test['alice_tminutes2'].values.reshape(-1, 1)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "cv_scores = cross_val_score(logit, X_train_tfidf_alicemin2, y_train, cv=time_split, \n",
    "                            scoring='roc_auc', n_jobs=2) # hangs with n_jobs > 1, and locally this runs much faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.89829926,  0.87260569,  0.9513416 ,  0.94842278,  0.94549648,\n",
       "         0.95119351,  0.84022791,  0.95368611,  0.97250591,  0.96702898]),\n",
       " 0.93008082297696004)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_scores, cv_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgbmodel = XGBRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time_split = TimeSeriesSplit(n_splits=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time_split_3 = TimeSeriesSplit(n_splits=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'time_split' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'time_split' is not defined"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "cv_scores = cross_val_score(xgbmodel, X_train_tfidf_alicemin2, y_train, cv=time_split_3, \n",
    "                            scoring='roc_auc', n_jobs=2) # hangs with n_jobs > 1, and locally this runs much faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.86326632,  0.90499984,  0.92253625]), 0.89693413731495519)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_scores, cv_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 16min 52s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "cv_scores = cross_val_score(xgbmodel, X_train_tfidf_alicemin2, y_train, cv=time_split, \n",
    "                            scoring='roc_auc', n_jobs=2) # hangs with n_jobs > 1, and locally this runs much faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.67617086,  0.83829413,  0.92386525,  0.95371999,  0.87800586,\n",
       "         0.93211837,  0.87948405,  0.93704494,  0.92003284,  0.89931427]),\n",
       " 0.8838050543977628)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_scores, cv_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_tfidf_alicemin2_dayall = csr_matrix(hstack([X_train_tfidf_alicemin2, \n",
    "                            new_feat_train['day0'].values.reshape(-1, 1),\n",
    "                            new_feat_train['day1'].values.reshape(-1, 1),\n",
    "                            new_feat_train['day2'].values.reshape(-1, 1),\n",
    "                            new_feat_train['day3'].values.reshape(-1, 1),\n",
    "                            new_feat_train['day4'].values.reshape(-1, 1),\n",
    "                            new_feat_train['day5'].values.reshape(-1, 1),\n",
    "                            new_feat_train['day6'].values.reshape(-1, 1)\n",
    "                                                                                  ]\n",
    "                                                      ))\n",
    "X_test_tfidf_alicemin2_dayall = csr_matrix(hstack([X_test_tfidf_alicemin2, \n",
    "                            new_feat_test['day0'].values.reshape(-1, 1),\n",
    "                            new_feat_test['day1'].values.reshape(-1, 1),\n",
    "                            new_feat_test['day2'].values.reshape(-1, 1),\n",
    "                            new_feat_test['day3'].values.reshape(-1, 1),\n",
    "                            new_feat_test['day4'].values.reshape(-1, 1),\n",
    "                            new_feat_test['day5'].values.reshape(-1, 1),\n",
    "                            new_feat_test['day6'].values.reshape(-1, 1)\n",
    "                                                                                 ]\n",
    "                                                      ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 10s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "cv_scores = cross_val_score(logit, X_train_tfidf_alicemin2_dayall, y_train, cv=time_split, \n",
    "                            scoring='roc_auc', n_jobs=2) # hangs with n_jobs > 1, and locally this runs much faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.89635226,  0.91144186,  0.91014797,  0.95966958,  0.96374129,\n",
       "         0.96929532,  0.85957648,  0.96527855,  0.83974961,  0.97863498]),\n",
       " 0.92538878914689437)"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_scores, cv_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_tfidf_alicemin2_dayall_morningMinutes = csr_matrix(hstack([X_train_tfidf_alicemin2_dayall, \n",
    "                             new_feat_train['alice_morning_minutes'].values.reshape(-1, 1)]))\n",
    "X_test_tfidf_alicemin2_dayall_morningMinutes = csr_matrix(hstack([X_test_tfidf_alicemin2_dayall, \n",
    "                             new_feat_test['alice_morning_minutes'].values.reshape(-1, 1)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "cv_scores = cross_val_score(logit, X_train_tfidf_alicemin2_dayall_morningMinutes, y_train, cv=time_split, \n",
    "                            scoring='roc_auc', n_jobs=2) # hangs with n_jobs > 1, and locally this runs much faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.87720677,  0.91227852,  0.91142162,  0.95972602,  0.96470756,\n",
       "         0.9708378 ,  0.85991751,  0.96699789,  0.84538225,  0.97927064]),\n",
       " 0.92477465942309356)"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_scores, cv_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_tfidf_alicemin2_day3 = csr_matrix(hstack([X_train_tfidf_alicemin2, \n",
    "                            new_feat_train['day0'].values.reshape(-1, 1),\n",
    "                            new_feat_train['day1'].values.reshape(-1, 1),\n",
    "                            new_feat_train['day4'].values.reshape(-1, 1)\n",
    "                                                                                  ]\n",
    "                                                      ))\n",
    "X_test_tfidf_alicemin2_day3 = csr_matrix(hstack([X_test_tfidf_alicemin2, \n",
    "                            new_feat_test['day0'].values.reshape(-1, 1),\n",
    "                            new_feat_test['day1'].values.reshape(-1, 1),\n",
    "                            new_feat_test['day4'].values.reshape(-1, 1)\n",
    "                                                                                 ]\n",
    "                                                      ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 8s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "cv_scores = cross_val_score(logit, X_train_tfidf_alicemin2_day3, y_train, cv=time_split, \n",
    "                            scoring='roc_auc', n_jobs=2) # hangs with n_jobs > 1, and locally this runs much faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.85500557,  0.89218816,  0.94724231,  0.94813946,  0.93803453,\n",
       "         0.96676856,  0.80106909,  0.96456595,  0.96764676,  0.97982519]),\n",
       " 0.92604855840577116)"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_scores, cv_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# наша целевая переменная\n",
    "y_train = train_df['target']\n",
    "\n",
    "# объединенная таблица исходных данных\n",
    "full_df = pd.concat([train_df.drop('target', axis=1), test_df])\n",
    "\n",
    "# индекс, по которому будем отделять обучающую выборку от тестовой\n",
    "idx_split = train_df.shape[0]\n",
    "\n",
    "sites = ['site%d' % i for i in range(1, 11)]\n",
    "\n",
    "full_sites = full_df[sites]\n",
    "\n",
    "# последовательность с индексами\n",
    "sites_flatten = full_sites.values.flatten()\n",
    "\n",
    "# искомая матрица\n",
    "full_sites_sparse = csr_matrix(([1] * sites_flatten.shape[0],\n",
    "                                sites_flatten,\n",
    "                                range(0, sites_flatten.shape[0] + 10, 10)))[:, 1:]\n",
    "\n",
    "X_train_sparse = full_sites_sparse[:idx_split]\n",
    "X_test_sparse = full_sites_sparse[idx_split:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(253561, 48371)"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_sparse.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(253561, 100001)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tfidf_alicemin2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_tfidf_alicemin2_ids = hstack((X_train_sparse, X_train_tfidf_alicemin2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(253561, 148372)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tfidf_alicemin2_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test_tfidf_alicemin2_ids = hstack((X_test_sparse, X_test_tfidf_alicemin2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "cv_scores = cross_val_score(logit, X_train_tfidf_alicemin2_ids, y_train, cv=time_split, \n",
    "                            scoring='roc_auc', n_jobs=2) # hangs with n_jobs > 1, and locally this runs much faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.92068428,  0.85178662,  0.95073216,  0.95737376,  0.94100836,\n",
       "         0.95542052,  0.90649692,  0.94334691,  0.97464443,  0.96558644]),\n",
       " 0.93670803931351421)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_scores, cv_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_tfidf_alicemin2_ids_day0 = csr_matrix(hstack([X_train_tfidf_alicemin2_ids, \n",
    "                            new_feat_train['day0'].values.reshape(-1, 1)\n",
    "                                                                                  ]\n",
    "                                                      ))\n",
    "X_test_tfidf_alicemin2_ids_day0 = csr_matrix(hstack([X_test_tfidf_alicemin2_ids, \n",
    "                            new_feat_test['day0'].values.reshape(-1, 1)\n",
    "                                                                                 ]\n",
    "                                                      ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 27s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "cv_scores = cross_val_score(logit, X_train_tfidf_alicemin2_ids_day0, y_train, cv=time_split, \n",
    "                            scoring='roc_auc', n_jobs=2) # hangs with n_jobs > 1, and locally this runs much faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.91892893,  0.85369788,  0.95325148,  0.95696778,  0.94581438,\n",
       "         0.96302465,  0.89478692,  0.95367102,  0.97767895,  0.97348202]),\n",
       " 0.93913040142136839)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_scores, cv_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_tfidf_alicemin2_ids_day01 = csr_matrix(hstack([X_train_tfidf_alicemin2_ids_day0, \n",
    "                            new_feat_train['day1'].values.reshape(-1, 1)\n",
    "                                                                                  ]\n",
    "                                                      ))\n",
    "X_test_tfidf_alicemin2_ids_day01 = csr_matrix(hstack([X_test_tfidf_alicemin2_ids_day0, \n",
    "                            new_feat_test['day1'].values.reshape(-1, 1)\n",
    "                                                                                 ]\n",
    "                                                      ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 3min 48s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "cv_scores = cross_val_score(logit, X_train_tfidf_alicemin2_ids_day01, y_train, cv=time_split, \n",
    "                            scoring='roc_auc', n_jobs=2) # hangs with n_jobs > 1, and locally this runs much faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.91880648,  0.84971002,  0.95329867,  0.95622639,  0.94492636,\n",
       "         0.96223507,  0.89253163,  0.95572812,  0.97773912,  0.9771424 ]),\n",
       " 0.93883442599372713)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_scores, cv_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=-1,\n",
       "          penalty='l2', random_state=17, solver='liblinear', tol=0.0001,\n",
       "          verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.fit(X_train_tfidf_alicemin2_ids_day0, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_pred = logit.predict_proba(X_test_tfidf_alicemin2_ids_day0)[:, 1]\n",
    "write_to_submission_file(test_pred, 'X_test_tfidf_alicemin2_ids_day0.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_tfidf_alicemin2_ids_dayall = csr_matrix(hstack([X_train_tfidf_alicemin2_ids_day0, \n",
    "                            new_feat_train['day1'].values.reshape(-1, 1),\n",
    "                            new_feat_train['day2'].values.reshape(-1, 1),\n",
    "                            new_feat_train['day3'].values.reshape(-1, 1),\n",
    "                            new_feat_train['day4'].values.reshape(-1, 1),\n",
    "                            new_feat_train['day5'].values.reshape(-1, 1),\n",
    "                            new_feat_train['day6'].values.reshape(-1, 1)\n",
    "                                                                                  ]\n",
    "                                                      ))\n",
    "X_test_tfidf_alicemin2_ids_dayall = csr_matrix(hstack([X_test_tfidf_alicemin2_ids_day0, \n",
    "                            new_feat_test['day1'].values.reshape(-1, 1),\n",
    "                            new_feat_test['day2'].values.reshape(-1, 1),\n",
    "                            new_feat_test['day3'].values.reshape(-1, 1),\n",
    "                            new_feat_test['day4'].values.reshape(-1, 1),\n",
    "                            new_feat_test['day5'].values.reshape(-1, 1),\n",
    "                            new_feat_test['day6'].values.reshape(-1, 1)\n",
    "                                                                                 ]\n",
    "                                                      ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_tfidf_alicemin2_ids_dayall_mm_September = csr_matrix(hstack([X_train_tfidf_alicemin2_ids_dayall, \n",
    "                            new_feat_train['alice_morning_minutes'].values.reshape(-1, 1),\n",
    "                            new_feat_train['september'].values.reshape(-1, 1)\n",
    "                                                                                  ]\n",
    "                                                      ))\n",
    "X_test_tfidf_alicemin2_ids_dayall_mm_September = csr_matrix(hstack([X_test_tfidf_alicemin2_ids_dayall, \n",
    "                            new_feat_test['alice_morning_minutes'].values.reshape(-1, 1),\n",
    "                            new_feat_test['september'].values.reshape(-1, 1)\n",
    "                                                                                 ]\n",
    "                                                      ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 2min 15s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "cv_scores = cross_val_score(logit, X_train_tfidf_alicemin2_ids_dayall_mm_September, y_train, cv=time_split, \n",
    "                            scoring='roc_auc', n_jobs=2) # hangs with n_jobs > 1, and locally this runs much faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 0.90703669,  0.89730642,  0.93967556,  0.97210282,  0.93604137,\n",
       "         0.97586845,  0.88957095,  0.96522935,  0.93560306,  0.98140853]),\n",
       " 0.93998431838193852)"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_scores, cv_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logit.fit(X_train_tfidf_alicemin2_ids_dayall_mm_September, y_train)\n",
    "test_pred = logit.predict_proba(X_test_tfidf_alicemin2_ids_dayall_mm_September)[:, 1]\n",
    "write_to_submission_file(test_pred, 'X_test_tfidf_alicemin2_ids_dayall_mm_September.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from catboost import Pool, CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cat = CatBoostClassifier(random_state=17)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named xgboost",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-159-b25935c1568f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mxgboost\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mXGBRegressor\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m: No module named xgboost"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "time_split_3 = TimeSeriesSplit(n_splits=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "ename": "JoblibCatboostError",
     "evalue": "JoblibCatboostError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\nC:\\Anaconda2\\lib\\runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    169     pkg_name = mod_name.rpartition('.')[0]\n    170     main_globals = sys.modules[\"__main__\"].__dict__\n    171     if alter_argv:\n    172         sys.argv[0] = fname\n    173     return _run_code(code, main_globals, None,\n--> 174                      \"__main__\", fname, loader, pkg_name)\n        fname = r'C:\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py'\n        loader = <pkgutil.ImpLoader instance>\n        pkg_name = ''\n    175 \n    176 def run_module(mod_name, init_globals=None,\n    177                run_name=None, alter_sys=False):\n    178     \"\"\"Execute a module's code without importing it\n\n...........................................................................\nC:\\Anaconda2\\lib\\runpy.py in _run_code(code=<code object <module> at 0000000004749CB0, file ...lib\\site-packages\\ipykernel_launcher.py\", line 5>, run_globals={'__builtins__': <module '__builtin__' (built-in)>, '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': '', 'app': <module 'ipykernel.kernelapp' from 'C:\\Anaconda2\\lib\\site-packages\\ipykernel\\kernelapp.pyc'>, 'sys': <module 'sys' (built-in)>}, init_globals=None, mod_name='__main__', mod_fname=r'C:\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py', mod_loader=<pkgutil.ImpLoader instance>, pkg_name='')\n     67         run_globals.update(init_globals)\n     68     run_globals.update(__name__ = mod_name,\n     69                        __file__ = mod_fname,\n     70                        __loader__ = mod_loader,\n     71                        __package__ = pkg_name)\n---> 72     exec code in run_globals\n        code = <code object <module> at 0000000004749CB0, file ...lib\\site-packages\\ipykernel_launcher.py\", line 5>\n        run_globals = {'__builtins__': <module '__builtin__' (built-in)>, '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': '', 'app': <module 'ipykernel.kernelapp' from 'C:\\Anaconda2\\lib\\site-packages\\ipykernel\\kernelapp.pyc'>, 'sys': <module 'sys' (built-in)>}\n     73     return run_globals\n     74 \n     75 def _run_module_code(code, init_globals=None,\n     76                     mod_name=None, mod_fname=None,\n\n...........................................................................\nC:\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n     17 \n     18 \n     19 \n     20 \n\n...........................................................................\nC:\\Anaconda2\\lib\\site-packages\\traitlets\\config\\application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\nC:\\Anaconda2\\lib\\site-packages\\ipykernel\\kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    472             return self.subapp.start()\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         try:\n--> 477             ioloop.IOLoop.instance().start()\n    478         except KeyboardInterrupt:\n    479             pass\n    480 \n    481 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\nC:\\Anaconda2\\lib\\site-packages\\zmq\\eventloop\\ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\nC:\\Anaconda2\\lib\\site-packages\\tornado\\ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\nC:\\Anaconda2\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\nC:\\Anaconda2\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\nC:\\Anaconda2\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\nC:\\Anaconda2\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\nC:\\Anaconda2\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\nC:\\Anaconda2\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\nC:\\Anaconda2\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {u'allow_stdin': True, u'code': u\"%%time\\n\\ncv_scores = cross_val_score(cat, X_t...th n_jobs > 1, and locally this runs much faster\", u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 4, 22, 6, 42, 47, 863000, tzinfo=tzutc()), u'msg_id': u'26D25904CA9D40D086BB07E192AE7CB8', u'msg_type': u'execute_request', u'session': u'B79998034CA04350A3C2C7605EF52F93', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'26D25904CA9D40D086BB07E192AE7CB8', 'msg_type': u'execute_request', 'parent_header': {}})\n    230             self.log.warn(\"Unknown message type: %r\", msg_type)\n    231         else:\n    232             self.log.debug(\"%s: %s\", msg_type, msg)\n    233             self.pre_handler_hook()\n    234             try:\n--> 235                 handler(stream, idents, msg)\n        handler = <bound method IPythonKernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = ['B79998034CA04350A3C2C7605EF52F93']\n        msg = {'buffers': [], 'content': {u'allow_stdin': True, u'code': u\"%%time\\n\\ncv_scores = cross_val_score(cat, X_t...th n_jobs > 1, and locally this runs much faster\", u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 4, 22, 6, 42, 47, 863000, tzinfo=tzutc()), u'msg_id': u'26D25904CA9D40D086BB07E192AE7CB8', u'msg_type': u'execute_request', u'session': u'B79998034CA04350A3C2C7605EF52F93', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'26D25904CA9D40D086BB07E192AE7CB8', 'msg_type': u'execute_request', 'parent_header': {}}\n    236             except Exception:\n    237                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    238             finally:\n    239                 self.post_handler_hook()\n\n...........................................................................\nC:\\Anaconda2\\lib\\site-packages\\ipykernel\\kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=['B79998034CA04350A3C2C7605EF52F93'], parent={'buffers': [], 'content': {u'allow_stdin': True, u'code': u\"%%time\\n\\ncv_scores = cross_val_score(cat, X_t...th n_jobs > 1, and locally this runs much faster\", u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 4, 22, 6, 42, 47, 863000, tzinfo=tzutc()), u'msg_id': u'26D25904CA9D40D086BB07E192AE7CB8', u'msg_type': u'execute_request', u'session': u'B79998034CA04350A3C2C7605EF52F93', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'26D25904CA9D40D086BB07E192AE7CB8', 'msg_type': u'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\nC:\\Anaconda2\\lib\\site-packages\\ipykernel\\ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=u\"%%time\\n\\ncv_scores = cross_val_score(cat, X_t...th n_jobs > 1, and locally this runs much faster\", silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = u\"%%time\\n\\ncv_scores = cross_val_score(cat, X_t...th n_jobs > 1, and locally this runs much faster\"\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\nC:\\Anaconda2\\lib\\site-packages\\ipykernel\\zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=(u\"%%time\\n\\ncv_scores = cross_val_score(cat, X_t...th n_jobs > 1, and locally this runs much faster\",), **kwargs={'silent': False, 'store_history': True})\n    528             )\n    529         self.payload_manager.write_payload(payload)\n    530 \n    531     def run_cell(self, *args, **kwargs):\n    532         self._last_traceback = None\n--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = (u\"%%time\\n\\ncv_scores = cross_val_score(cat, X_t...th n_jobs > 1, and locally this runs much faster\",)\n        kwargs = {'silent': False, 'store_history': True}\n    534 \n    535     def _showtraceback(self, etype, evalue, stb):\n    536         # try to preserve ordering of tracebacks and print statements\n    537         sys.stdout.flush()\n\n...........................................................................\nC:\\Anaconda2\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=u\"%%time\\n\\ncv_scores = cross_val_score(cat, X_t...th n_jobs > 1, and locally this runs much faster\", store_history=True, silent=False, shell_futures=True)\n   2712                 self.displayhook.exec_result = result\n   2713 \n   2714                 # Execute the user code\n   2715                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2716                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2717                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler instance>\n   2718                 \n   2719                 self.last_execution_succeeded = not has_raised\n   2720 \n   2721                 # Reset this so later displayed values do not modify the\n\n...........................................................................\nC:\\Anaconda2\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Expr object>], cell_name='<ipython-input-156-855cb4505899>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler instance>, result=<ExecutionResult object at 46e86940, execution_c..._before_exec=None error_in_exec=None result=None>)\n   2822                     return True\n   2823 \n   2824             for i, node in enumerate(to_run_interactive):\n   2825                 mod = ast.Interactive([node])\n   2826                 code = compiler(mod, cell_name, \"single\")\n-> 2827                 if self.run_code(code, result):\n        self.run_code = <bound method ZMQInteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0000000019441E30, file \"<ipython-input-156-855cb4505899>\", line 1>\n        result = <ExecutionResult object at 46e86940, execution_c..._before_exec=None error_in_exec=None result=None>\n   2828                     return True\n   2829 \n   2830             # Flush softspace\n   2831             if softspace(sys.stdout, 0):\n\n...........................................................................\nC:\\Anaconda2\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0000000019441E30, file \"<ipython-input-156-855cb4505899>\", line 1>, result=<ExecutionResult object at 46e86940, execution_c..._before_exec=None error_in_exec=None result=None>)\n   2876         outflag = 1  # happens in more places, so it's easier as default\n   2877         try:\n   2878             try:\n   2879                 self.hooks.pre_run_code_hook()\n   2880                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2881                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0000000019441E30, file \"<ipython-input-156-855cb4505899>\", line 1>\n        self.user_global_ns = {'CatBoostClassifier': <class 'catboost.core.CatBoostClassifier'>, 'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'Counter': <class 'collections.Counter'>, 'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', u\"import pickle\\nimport numpy as np\\nimport pand...tlib import pyplot as plt\\nimport seaborn as sns\", u\"# \\u0437\\u0430\\u0433\\u0440\\u0443\\u0437\\u0438\\u...438\\ntrain_df = train_df.sort_values(by='time1')\", u'# \\u043f\\u0440\\u0438\\u0432\\u0435\\u0434\\u0435\\u... sites_dict_df.shape[0])\\n\\nsites_dict_df.head()', u\"# \\u043d\\u0430\\u0448\\u0430 \\u0446\\u0435\\u043b\\...]\\nX_test_sparse = full_sites_sparse[idx_split:]\", u'from sklearn.model_selection import train_test_split, GridSearchCV', u\"def get_auc_lr_valid(X, y, C=1.0, ratio = 0.9,... \\n    return roc_auc_score(y_valid, valid_pred)\", u'get_auc_lr_valid(X_train_sparse, y_train, ratio = 0.9)', u'# \\u0444\\u0443\\u043d\\u043a\\u0446\\u0438\\u044f \\...ted_df.to_csv(out_file, index_label=index_label)', u'new_feat_train = pd.DataFrame(index=train_df.i...ew_feat_test = pd.DataFrame(index=test_df.index)', u\"new_feat_train['alice_tminutes'] = train_df['t... >= 954 and ts.hour*60+ts.minute <=1100) else 0)\", u\"X_train_sparse_alicemin = csr_matrix(hstack([X..._test['alice_tminutes'].values.reshape(-1, 1)]))\", u'get_auc_lr_valid(X_train_sparse_alicemin, y_train)', u\"new_feat_train['alice_tminutes2'] = train_df['...e >= 548 and ts.hour*60+ts.minute <=559) else 0)\", u\"X_train_sparse_alicemin2 = csr_matrix(hstack([...test['alice_tminutes2'].values.reshape(-1, 1)]))\", u'get_auc_lr_valid(X_train_sparse_alicemin, y_train)', u'get_auc_lr_valid(X_train_sparse_alicemin2, y_train)', u\"new_feat_train['day0'] = train_df['time1'].app...'].apply(lambda ts: 1 if ts.weekday()==5 else 0)\", u\"X_train_sparse_alicemin2_dayall = csr_matrix(h...                                              ))\", u'get_auc_lr_valid(X_train_sparse_alicemin2_dayall, y_train)', ...], 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'LogisticRegressionCV': <class 'sklearn.linear_model.logistic.LogisticRegressionCV'>, 'OneHotEncoder': <class 'sklearn.preprocessing.data.OneHotEncoder'>, 'Out': {3:                                                 ...                         9zouxfza1h.s.ad6media.fr, 7: 0.96433761440091936, 12: 0.98650035989731588, 16: 0.98708576028395223, 19: 0.9910118176175845, 20: 0.9910118176175845, 23: 0.99119403526923877, 24: 0.99119403526923877, 32: 0.99287326517974273, 33:             site1               time1  site2    ...:22       0        24157  \n\n[5 rows x 22 columns], ...}, ...}\n        self.user_ns = {'CatBoostClassifier': <class 'catboost.core.CatBoostClassifier'>, 'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'Counter': <class 'collections.Counter'>, 'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', u\"import pickle\\nimport numpy as np\\nimport pand...tlib import pyplot as plt\\nimport seaborn as sns\", u\"# \\u0437\\u0430\\u0433\\u0440\\u0443\\u0437\\u0438\\u...438\\ntrain_df = train_df.sort_values(by='time1')\", u'# \\u043f\\u0440\\u0438\\u0432\\u0435\\u0434\\u0435\\u... sites_dict_df.shape[0])\\n\\nsites_dict_df.head()', u\"# \\u043d\\u0430\\u0448\\u0430 \\u0446\\u0435\\u043b\\...]\\nX_test_sparse = full_sites_sparse[idx_split:]\", u'from sklearn.model_selection import train_test_split, GridSearchCV', u\"def get_auc_lr_valid(X, y, C=1.0, ratio = 0.9,... \\n    return roc_auc_score(y_valid, valid_pred)\", u'get_auc_lr_valid(X_train_sparse, y_train, ratio = 0.9)', u'# \\u0444\\u0443\\u043d\\u043a\\u0446\\u0438\\u044f \\...ted_df.to_csv(out_file, index_label=index_label)', u'new_feat_train = pd.DataFrame(index=train_df.i...ew_feat_test = pd.DataFrame(index=test_df.index)', u\"new_feat_train['alice_tminutes'] = train_df['t... >= 954 and ts.hour*60+ts.minute <=1100) else 0)\", u\"X_train_sparse_alicemin = csr_matrix(hstack([X..._test['alice_tminutes'].values.reshape(-1, 1)]))\", u'get_auc_lr_valid(X_train_sparse_alicemin, y_train)', u\"new_feat_train['alice_tminutes2'] = train_df['...e >= 548 and ts.hour*60+ts.minute <=559) else 0)\", u\"X_train_sparse_alicemin2 = csr_matrix(hstack([...test['alice_tminutes2'].values.reshape(-1, 1)]))\", u'get_auc_lr_valid(X_train_sparse_alicemin, y_train)', u'get_auc_lr_valid(X_train_sparse_alicemin2, y_train)', u\"new_feat_train['day0'] = train_df['time1'].app...'].apply(lambda ts: 1 if ts.weekday()==5 else 0)\", u\"X_train_sparse_alicemin2_dayall = csr_matrix(h...                                              ))\", u'get_auc_lr_valid(X_train_sparse_alicemin2_dayall, y_train)', ...], 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'LogisticRegressionCV': <class 'sklearn.linear_model.logistic.LogisticRegressionCV'>, 'OneHotEncoder': <class 'sklearn.preprocessing.data.OneHotEncoder'>, 'Out': {3:                                                 ...                         9zouxfza1h.s.ad6media.fr, 7: 0.96433761440091936, 12: 0.98650035989731588, 16: 0.98708576028395223, 19: 0.9910118176175845, 20: 0.9910118176175845, 23: 0.99119403526923877, 24: 0.99119403526923877, 32: 0.99287326517974273, 33:             site1               time1  site2    ...:22       0        24157  \n\n[5 rows x 22 columns], ...}, ...}\n   2882             finally:\n   2883                 # Reset our crash handler in place\n   2884                 sys.excepthook = old_excepthook\n   2885         except SystemExit as e:\n\n...........................................................................\nC:\\Anaconda2\\Scripts\\<ipython-input-156-855cb4505899> in <module>()\n----> 1 \n      2 \n      3 \n      4 \n      5 \n      6 get_ipython().run_cell_magic(u'time', u'', u\"\\ncv_scores = cross_val_score(cat, X_train_tfidf_alicemin2_ids_dayall_mm_September, y_train, cv=time_split_3, \\n                            scoring='roc_auc', n_jobs=2) # hangs with n_jobs > 1, and locally this runs much faster\")\n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\nC:\\Anaconda2\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_cell_magic(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, magic_name=u'time', line=u'', cell=u\"\\ncv_scores = cross_val_score(cat, X_train_tfi...th n_jobs > 1, and locally this runs much faster\")\n   2110             # This will need to be updated if the internal calling logic gets\n   2111             # refactored, or else we'll be expanding the wrong variables.\n   2112             stack_depth = 2\n   2113             magic_arg_s = self.var_expand(line, stack_depth)\n   2114             with self.builtin_trap:\n-> 2115                 result = fn(magic_arg_s, cell)\n        result = undefined\n        fn = <bound method ExecutionMagics.time of <IPython.core.magics.execution.ExecutionMagics object>>\n        magic_arg_s = u''\n        cell = u\"\\ncv_scores = cross_val_score(cat, X_train_tfi...th n_jobs > 1, and locally this runs much faster\"\n   2116             return result\n   2117 \n   2118     def find_line_magic(self, magic_name):\n   2119         \"\"\"Find and return a line magic by name.\n\n...........................................................................\nC:\\Anaconda2\\Scripts\\<decorator-gen-60> in time(self=<IPython.core.magics.execution.ExecutionMagics object>, line=u'', cell=u\"\\ncv_scores = cross_val_score(cat, X_train_tfi...th n_jobs > 1, and locally this runs much faster\", local_ns=None)\n      1 \n----> 2 \n      3 \n      4 \n      5 \n      6 \n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\nC:\\Anaconda2\\lib\\site-packages\\IPython\\core\\magic.py in <lambda>(f=<function time>, *a=(<IPython.core.magics.execution.ExecutionMagics object>, u'', u\"\\ncv_scores = cross_val_score(cat, X_train_tfi...th n_jobs > 1, and locally this runs much faster\", None), **k={})\n    183     validate_type(magic_kind)\n    184 \n    185     # This is a closure to capture the magic_kind.  We could also use a class,\n    186     # but it's overkill for just that one bit of state.\n    187     def magic_deco(arg):\n--> 188         call = lambda f, *a, **k: f(*a, **k)\n        f = <function time>\n        a = (<IPython.core.magics.execution.ExecutionMagics object>, u'', u\"\\ncv_scores = cross_val_score(cat, X_train_tfi...th n_jobs > 1, and locally this runs much faster\", None)\n        k = {}\n    189 \n    190         if callable(arg):\n    191             # \"Naked\" decorator call (just @foo, no args)\n    192             func = arg\n\n...........................................................................\nC:\\Anaconda2\\lib\\site-packages\\IPython\\core\\magics\\execution.py in time(self=<IPython.core.magics.execution.ExecutionMagics object>, line=u'', cell=u\"\\ncv_scores = cross_val_score(cat, X_train_tfi...th n_jobs > 1, and locally this runs much faster\", local_ns=None)\n   1180             st = clock2()\n   1181             out = eval(code, glob, local_ns)\n   1182             end = clock2()\n   1183         else:\n   1184             st = clock2()\n-> 1185             exec(code, glob, local_ns)\n        code = <code object <module> at 0000000046E660B0, file \"<timed exec>\", line 2>\n        glob = {'CatBoostClassifier': <class 'catboost.core.CatBoostClassifier'>, 'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'Counter': <class 'collections.Counter'>, 'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', u\"import pickle\\nimport numpy as np\\nimport pand...tlib import pyplot as plt\\nimport seaborn as sns\", u\"# \\u0437\\u0430\\u0433\\u0440\\u0443\\u0437\\u0438\\u...438\\ntrain_df = train_df.sort_values(by='time1')\", u'# \\u043f\\u0440\\u0438\\u0432\\u0435\\u0434\\u0435\\u... sites_dict_df.shape[0])\\n\\nsites_dict_df.head()', u\"# \\u043d\\u0430\\u0448\\u0430 \\u0446\\u0435\\u043b\\...]\\nX_test_sparse = full_sites_sparse[idx_split:]\", u'from sklearn.model_selection import train_test_split, GridSearchCV', u\"def get_auc_lr_valid(X, y, C=1.0, ratio = 0.9,... \\n    return roc_auc_score(y_valid, valid_pred)\", u'get_auc_lr_valid(X_train_sparse, y_train, ratio = 0.9)', u'# \\u0444\\u0443\\u043d\\u043a\\u0446\\u0438\\u044f \\...ted_df.to_csv(out_file, index_label=index_label)', u'new_feat_train = pd.DataFrame(index=train_df.i...ew_feat_test = pd.DataFrame(index=test_df.index)', u\"new_feat_train['alice_tminutes'] = train_df['t... >= 954 and ts.hour*60+ts.minute <=1100) else 0)\", u\"X_train_sparse_alicemin = csr_matrix(hstack([X..._test['alice_tminutes'].values.reshape(-1, 1)]))\", u'get_auc_lr_valid(X_train_sparse_alicemin, y_train)', u\"new_feat_train['alice_tminutes2'] = train_df['...e >= 548 and ts.hour*60+ts.minute <=559) else 0)\", u\"X_train_sparse_alicemin2 = csr_matrix(hstack([...test['alice_tminutes2'].values.reshape(-1, 1)]))\", u'get_auc_lr_valid(X_train_sparse_alicemin, y_train)', u'get_auc_lr_valid(X_train_sparse_alicemin2, y_train)', u\"new_feat_train['day0'] = train_df['time1'].app...'].apply(lambda ts: 1 if ts.weekday()==5 else 0)\", u\"X_train_sparse_alicemin2_dayall = csr_matrix(h...                                              ))\", u'get_auc_lr_valid(X_train_sparse_alicemin2_dayall, y_train)', ...], 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'LogisticRegressionCV': <class 'sklearn.linear_model.logistic.LogisticRegressionCV'>, 'OneHotEncoder': <class 'sklearn.preprocessing.data.OneHotEncoder'>, 'Out': {3:                                                 ...                         9zouxfza1h.s.ad6media.fr, 7: 0.96433761440091936, 12: 0.98650035989731588, 16: 0.98708576028395223, 19: 0.9910118176175845, 20: 0.9910118176175845, 23: 0.99119403526923877, 24: 0.99119403526923877, 32: 0.99287326517974273, 33:             site1               time1  site2    ...:22       0        24157  \n\n[5 rows x 22 columns], ...}, ...}\n        local_ns = None\n   1186             end = clock2()\n   1187             out = None\n   1188         wall_end = wtime()\n   1189         # Compute actual times and report\n\n...........................................................................\nC:\\Anaconda2\\Scripts\\<timed exec> in <module>()\n      1 \n      2 \n----> 3 \n      4 \n      5 \n      6 \n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\nC:\\Anaconda2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in cross_val_score(estimator=<catboost.core.CatBoostClassifier object>, X=<253561x148381 sparse matrix of type '<type 'num... stored elements in Compressed Sparse Row format>, y=session_id\n21669     0\n54843     0\n77292     0\n1...2    0\nName: target, Length: 253561, dtype: int64, groups=None, scoring='roc_auc', cv=TimeSeriesSplit(n_splits=3), n_jobs=2, verbose=0, fit_params=None, pre_dispatch='2*n_jobs')\n    135     parallel = Parallel(n_jobs=n_jobs, verbose=verbose,\n    136                         pre_dispatch=pre_dispatch)\n    137     scores = parallel(delayed(_fit_and_score)(clone(estimator), X, y, scorer,\n    138                                               train, test, verbose, None,\n    139                                               fit_params)\n--> 140                       for train, test in cv_iter)\n        cv_iter = [(array([    0,     1,     2, ..., 63388, 63389, 63390]), array([ 63391,  63392,  63393, ..., 126778, 126779, 126780])), (array([     0,      1,      2, ..., 126778, 126779, 126780]), array([126781, 126782, 126783, ..., 190168, 190169, 190170])), (array([     0,      1,      2, ..., 190168, 190169, 190170]), array([190171, 190172, 190173, ..., 253558, 253559, 253560]))]\n    141     return np.array(scores)[:, 0]\n    142 \n    143 \n    144 def _fit_and_score(estimator, X, y, scorer, train, test, verbose,\n\n...........................................................................\nC:\\Anaconda2\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=2), iterable=<generator object <genexpr>>)\n    763             if pre_dispatch == \"all\" or n_jobs == 1:\n    764                 # The iterable was consumed all at once by the above for loop.\n    765                 # No need to wait for async callbacks to trigger to\n    766                 # consumption.\n    767                 self._iterating = False\n--> 768             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=2)>\n    769             # Make sure that we get a last message telling us we are done\n    770             elapsed_time = time.time() - self._start_time\n    771             self._print('Done %3i out of %3i | elapsed: %s finished',\n    772                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nCatboostError                                      Sun Apr 22 11:43:49 2018\nPID: 17532                           Python 2.7.13: C:\\Anaconda2\\python.exe\n...........................................................................\nC:\\Anaconda2\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (<catboost.core.CatBoostClassifier object>, <253561x148381 sparse matrix of type '<type 'num... stored elements in Compressed Sparse Row format>, session_id\n21669     0\n54843     0\n77292     0\n1...2    0\nName: target, Length: 253561, dtype: int64, make_scorer(roc_auc_score, needs_threshold=True), array([    0,     1,     2, ..., 63388, 63389, 63390]), array([ 63391,  63392,  63393, ..., 126778, 126779, 126780]), 0, None, None)\n        kwargs = {}\n        self.items = [(<function _fit_and_score>, (<catboost.core.CatBoostClassifier object>, <253561x148381 sparse matrix of type '<type 'num... stored elements in Compressed Sparse Row format>, session_id\n21669     0\n54843     0\n77292     0\n1...2    0\nName: target, Length: 253561, dtype: int64, make_scorer(roc_auc_score, needs_threshold=True), array([    0,     1,     2, ..., 63388, 63389, 63390]), array([ 63391,  63392,  63393, ..., 126778, 126779, 126780]), 0, None, None), {})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Anaconda2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=<catboost.core.CatBoostClassifier object>, X=<253561x148381 sparse matrix of type '<type 'num... stored elements in Compressed Sparse Row format>, y=session_id\n21669     0\n54843     0\n77292     0\n1...2    0\nName: target, Length: 253561, dtype: int64, scorer=make_scorer(roc_auc_score, needs_threshold=True), train=array([    0,     1,     2, ..., 63388, 63389, 63390]), test=array([ 63391,  63392,  63393, ..., 126778, 126779, 126780]), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=False, error_score='raise')\n    233 \n    234     try:\n    235         if y_train is None:\n    236             estimator.fit(X_train, **fit_params)\n    237         else:\n--> 238             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method CatBoostClassifier.fit of <catboost.core.CatBoostClassifier object>>\n        X_train = <63391x148381 sparse matrix of type '<type 'nump... stored elements in Compressed Sparse Row format>\n        y_train = session_id\n21669     0\n54843     0\n77292     0\n1...24    0\nName: target, Length: 63391, dtype: int64\n        fit_params = {}\n    239 \n    240     except Exception as e:\n    241         # Note fit time as time until error\n    242         fit_time = time.time() - start_time\n\n...........................................................................\nC:\\Anaconda2\\lib\\site-packages\\catboost\\core.py in fit(self=<catboost.core.CatBoostClassifier object>, X=<63391x148381 sparse matrix of type '<type 'nump... stored elements in Compressed Sparse Row format>, y=session_id\n21669     0\n54843     0\n77292     0\n1...24    0\nName: target, Length: 63391, dtype: int64, cat_features=None, sample_weight=None, baseline=None, use_best_model=None, eval_set=None, verbose=None, logging_level=None, plot=False, column_description=None, verbose_eval=None)\n   1671 \n   1672         Returns\n   1673         -------\n   1674         model : CatBoost\n   1675         \"\"\"\n-> 1676         self._fit(X, y, cat_features, None, sample_weight, None, None, None, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval)\n        self._fit = <bound method CatBoostClassifier._fit of <catboost.core.CatBoostClassifier object>>\n        X = <63391x148381 sparse matrix of type '<type 'nump... stored elements in Compressed Sparse Row format>\n        y = session_id\n21669     0\n54843     0\n77292     0\n1...24    0\nName: target, Length: 63391, dtype: int64\n        cat_features = None\n        sample_weight = None\n        baseline = None\n        use_best_model = None\n        eval_set = None\n        verbose = None\n        logging_level = None\n        plot = False\n        column_description = None\n        verbose_eval = None\n   1677         return self\n   1678 \n   1679     def predict(self, data, prediction_type='Class', ntree_start=0, ntree_end=0, thread_count=-1, verbose=None):\n   1680         \"\"\"\n\n...........................................................................\nC:\\Anaconda2\\lib\\site-packages\\catboost\\core.py in _fit(self=<catboost.core.CatBoostClassifier object>, X=<63391x148381 sparse matrix of type '<type 'nump... stored elements in Compressed Sparse Row format>, y=session_id\n21669     0\n54843     0\n77292     0\n1...24    0\nName: target, Length: 63391, dtype: int64, cat_features=None, pairs=None, sample_weight=None, group_id=None, subgroup_id=None, pairs_weight=None, baseline=None, use_best_model=None, eval_set=None, verbose=None, logging_level=None, plot=False, column_description=None, verbose_eval=None)\n    747         if logging_level is not None:\n    748             params['logging_level'] = logging_level\n    749         if use_best_model is not None:\n    750             params['use_best_model'] = use_best_model\n    751 \n--> 752         train_pool = _build_train_pool(X, y, cat_features, pairs, sample_weight, group_id, subgroup_id, pairs_weight, baseline, column_description)\n        train_pool = undefined\n        X = <63391x148381 sparse matrix of type '<type 'nump... stored elements in Compressed Sparse Row format>\n        y = session_id\n21669     0\n54843     0\n77292     0\n1...24    0\nName: target, Length: 63391, dtype: int64\n        cat_features = None\n        pairs = None\n        sample_weight = None\n        group_id = None\n        subgroup_id = None\n        pairs_weight = None\n        baseline = None\n        column_description = None\n    753         if train_pool.is_empty_:\n    754             raise CatboostError(\"X is empty.\")\n    755 \n    756         if column_description is not None and not isinstance(X, STRING_TYPES) and not isinstance(eval_set, STRING_TYPES):\n\n...........................................................................\nC:\\Anaconda2\\lib\\site-packages\\catboost\\core.py in _build_train_pool(X=<63391x148381 sparse matrix of type '<type 'nump... stored elements in Compressed Sparse Row format>, y=session_id\n21669     0\n54843     0\n77292     0\n1...24    0\nName: target, Length: 63391, dtype: int64, cat_features=None, pairs=None, sample_weight=None, group_id=None, subgroup_id=None, pairs_weight=None, baseline=None, column_description=None)\n    549             train_pool = Pool(data=X, pairs=pairs, column_description=column_description)\n    550     else:\n    551         if y is None:\n    552             raise CatboostError(\"y has not initialized in fit(): X is not catboost.Pool object, y must be not None in fit().\")\n    553         train_pool = Pool(X, y, cat_features=cat_features, pairs=pairs, weight=sample_weight, group_id=group_id,\n--> 554                           subgroup_id=subgroup_id, pairs_weight=pairs_weight, baseline=baseline)\n        subgroup_id = None\n        pairs_weight = None\n        baseline = None\n    555     return train_pool\n    556 \n    557 \n    558 def _clear_training_files(train_dir):\n\n...........................................................................\nC:\\Anaconda2\\lib\\site-packages\\catboost\\core.py in __init__(self=<catboost.core.Pool object>, data=<63391x148381 sparse matrix of type '<type 'nump... stored elements in Compressed Sparse Row format>, label=session_id\n21669     0\n54843     0\n77292     0\n1...24    0\nName: target, Length: 63391, dtype: int64, cat_features=None, column_description=None, pairs=None, delimiter='\\t', has_header=False, weight=None, group_id=None, subgroup_id=None, pairs_weight=None, baseline=None, feature_names=None, thread_count=-1)\n    209             Thread count to read data from file.\n    210             Use only with reading data from file.\n    211             If -1, then the number of threads is set to the number of cores.\n    212         \"\"\"\n    213         if data is not None:\n--> 214             self._check_data_type(data)\n        self._check_data_type = <bound method Pool._check_data_type of <catboost.core.Pool object>>\n        data = <63391x148381 sparse matrix of type '<type 'nump... stored elements in Compressed Sparse Row format>\n    215             self._check_data_empty(data)\n    216             if pairs is not None and isinstance(data, STRING_TYPES) != isinstance(pairs, STRING_TYPES):\n    217                 raise CatboostError(\"Data and pairs should be the same types.\")\n    218             if isinstance(data, STRING_TYPES):\n\n...........................................................................\nC:\\Anaconda2\\lib\\site-packages\\catboost\\core.py in _check_data_type(self=<catboost.core.Pool object>, data=<63391x148381 sparse matrix of type '<type 'nump... stored elements in Compressed Sparse Row format>)\n    285     def _check_data_type(self, data):\n    286         \"\"\"\n    287         Check type of data.\n    288         \"\"\"\n    289         if not isinstance(data, (STRING_TYPES, ARRAY_TYPES)):\n--> 290             raise CatboostError(\"Invalid data type={}: data must be list(), np.ndarray(), DataFrame(), Series() or filename str().\".format(type(data)))\n        data = <63391x148381 sparse matrix of type '<type 'nump... stored elements in Compressed Sparse Row format>\n    291 \n    292     def _check_data_empty(self, data):\n    293         \"\"\"\n    294         Check data is not empty.\n\nCatboostError: Invalid data type=<class 'scipy.sparse.csr.csr_matrix'>: data must be list(), np.ndarray(), DataFrame(), Series() or filename str().\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mJoblibCatboostError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-156-855cb4505899>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mget_ipython\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun_cell_magic\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mu'time'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mu''\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34mu\"\\ncv_scores = cross_val_score(cat, X_train_tfidf_alicemin2_ids_dayall_mm_September, y_train, cv=time_split_3, \\n                            scoring='roc_auc', n_jobs=2) # hangs with n_jobs > 1, and locally this runs much faster\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\IPython\\core\\interactiveshell.pyc\u001b[0m in \u001b[0;36mrun_cell_magic\u001b[1;34m(self, magic_name, line, cell)\u001b[0m\n\u001b[0;32m   2113\u001b[0m             \u001b[0mmagic_arg_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvar_expand\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mline\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstack_depth\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2114\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuiltin_trap\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2115\u001b[1;33m                 \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmagic_arg_s\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2116\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2117\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<decorator-gen-60>\u001b[0m in \u001b[0;36mtime\u001b[1;34m(self, line, cell, local_ns)\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\IPython\\core\\magic.pyc\u001b[0m in \u001b[0;36m<lambda>\u001b[1;34m(f, *a, **k)\u001b[0m\n\u001b[0;32m    186\u001b[0m     \u001b[1;31m# but it's overkill for just that one bit of state.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    187\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mmagic_deco\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 188\u001b[1;33m         \u001b[0mcall\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mlambda\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\IPython\\core\\magics\\execution.pyc\u001b[0m in \u001b[0;36mtime\u001b[1;34m(self, line, cell, local_ns)\u001b[0m\n\u001b[0;32m   1183\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1184\u001b[0m             \u001b[0mst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1185\u001b[1;33m             \u001b[1;32mexec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocal_ns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1186\u001b[0m             \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclock2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1187\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\sklearn\\model_selection\\_validation.pyc\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[0;32m    138\u001b[0m                                               \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m                                               fit_params)\n\u001b[1;32m--> 140\u001b[1;33m                       for train, test in cv_iter)\n\u001b[0m\u001b[0;32m    141\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.pyc\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    766\u001b[0m                 \u001b[1;31m# consumption.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    767\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 768\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    769\u001b[0m             \u001b[1;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    770\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Anaconda2\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.pyc\u001b[0m in \u001b[0;36mretrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    717\u001b[0m                     \u001b[0mensure_ready\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_managed_backend\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m                     \u001b[0mbackend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabort_everything\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mensure_ready\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 719\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    720\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    721\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mJoblibCatboostError\u001b[0m: JoblibCatboostError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\nC:\\Anaconda2\\lib\\runpy.py in _run_module_as_main(mod_name='ipykernel_launcher', alter_argv=1)\n    169     pkg_name = mod_name.rpartition('.')[0]\n    170     main_globals = sys.modules[\"__main__\"].__dict__\n    171     if alter_argv:\n    172         sys.argv[0] = fname\n    173     return _run_code(code, main_globals, None,\n--> 174                      \"__main__\", fname, loader, pkg_name)\n        fname = r'C:\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py'\n        loader = <pkgutil.ImpLoader instance>\n        pkg_name = ''\n    175 \n    176 def run_module(mod_name, init_globals=None,\n    177                run_name=None, alter_sys=False):\n    178     \"\"\"Execute a module's code without importing it\n\n...........................................................................\nC:\\Anaconda2\\lib\\runpy.py in _run_code(code=<code object <module> at 0000000004749CB0, file ...lib\\site-packages\\ipykernel_launcher.py\", line 5>, run_globals={'__builtins__': <module '__builtin__' (built-in)>, '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': '', 'app': <module 'ipykernel.kernelapp' from 'C:\\Anaconda2\\lib\\site-packages\\ipykernel\\kernelapp.pyc'>, 'sys': <module 'sys' (built-in)>}, init_globals=None, mod_name='__main__', mod_fname=r'C:\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py', mod_loader=<pkgutil.ImpLoader instance>, pkg_name='')\n     67         run_globals.update(init_globals)\n     68     run_globals.update(__name__ = mod_name,\n     69                        __file__ = mod_fname,\n     70                        __loader__ = mod_loader,\n     71                        __package__ = pkg_name)\n---> 72     exec code in run_globals\n        code = <code object <module> at 0000000004749CB0, file ...lib\\site-packages\\ipykernel_launcher.py\", line 5>\n        run_globals = {'__builtins__': <module '__builtin__' (built-in)>, '__doc__': 'Entry point for launching an IPython kernel.\\n\\nTh...orts until\\nafter removing the cwd from sys.path.\\n', '__file__': r'C:\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py', '__loader__': <pkgutil.ImpLoader instance>, '__name__': '__main__', '__package__': '', 'app': <module 'ipykernel.kernelapp' from 'C:\\Anaconda2\\lib\\site-packages\\ipykernel\\kernelapp.pyc'>, 'sys': <module 'sys' (built-in)>}\n     73     return run_globals\n     74 \n     75 def _run_module_code(code, init_globals=None,\n     76                     mod_name=None, mod_fname=None,\n\n...........................................................................\nC:\\Anaconda2\\lib\\site-packages\\ipykernel_launcher.py in <module>()\n     11     # This is added back by InteractiveShellApp.init_path()\n     12     if sys.path[0] == '':\n     13         del sys.path[0]\n     14 \n     15     from ipykernel import kernelapp as app\n---> 16     app.launch_new_instance()\n     17 \n     18 \n     19 \n     20 \n\n...........................................................................\nC:\\Anaconda2\\lib\\site-packages\\traitlets\\config\\application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\nC:\\Anaconda2\\lib\\site-packages\\ipykernel\\kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    472             return self.subapp.start()\n    473         if self.poller is not None:\n    474             self.poller.start()\n    475         self.kernel.start()\n    476         try:\n--> 477             ioloop.IOLoop.instance().start()\n    478         except KeyboardInterrupt:\n    479             pass\n    480 \n    481 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\nC:\\Anaconda2\\lib\\site-packages\\zmq\\eventloop\\ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    172             )\n    173         return loop\n    174     \n    175     def start(self):\n    176         try:\n--> 177             super(ZMQIOLoop, self).start()\n        self.start = <bound method ZMQIOLoop.start of <zmq.eventloop.ioloop.ZMQIOLoop object>>\n    178         except ZMQError as e:\n    179             if e.errno == ETERM:\n    180                 # quietly return on ETERM\n    181                 pass\n\n...........................................................................\nC:\\Anaconda2\\lib\\site-packages\\tornado\\ioloop.py in start(self=<zmq.eventloop.ioloop.ZMQIOLoop object>)\n    883                 self._events.update(event_pairs)\n    884                 while self._events:\n    885                     fd, events = self._events.popitem()\n    886                     try:\n    887                         fd_obj, handler_func = self._handlers[fd]\n--> 888                         handler_func(fd_obj, events)\n        handler_func = <function null_wrapper>\n        fd_obj = <zmq.sugar.socket.Socket object>\n        events = 1\n    889                     except (OSError, IOError) as e:\n    890                         if errno_from_exception(e) == errno.EPIPE:\n    891                             # Happens when the client closes the connection\n    892                             pass\n\n...........................................................................\nC:\\Anaconda2\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=(<zmq.sugar.socket.Socket object>, 1), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = (<zmq.sugar.socket.Socket object>, 1)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\nC:\\Anaconda2\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=1)\n    435             # dispatch events:\n    436             if events & IOLoop.ERROR:\n    437                 gen_log.error(\"got POLLERR event on ZMQStream, which doesn't make sense\")\n    438                 return\n    439             if events & IOLoop.READ:\n--> 440                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    441                 if not self.socket:\n    442                     return\n    443             if events & IOLoop.WRITE:\n    444                 self._handle_send()\n\n...........................................................................\nC:\\Anaconda2\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    467                 gen_log.error(\"RECV Error: %s\"%zmq.strerror(e.errno))\n    468         else:\n    469             if self._recv_callback:\n    470                 callback = self._recv_callback\n    471                 # self._recv_callback = None\n--> 472                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    473                 \n    474         # self.update_state()\n    475         \n    476 \n\n...........................................................................\nC:\\Anaconda2\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    409         close our socket.\"\"\"\n    410         try:\n    411             # Use a NullContext to ensure that all StackContexts are run\n    412             # inside our blanket exception handler rather than outside.\n    413             with stack_context.NullContext():\n--> 414                 callback(*args, **kwargs)\n        callback = <function null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    415         except:\n    416             gen_log.error(\"Uncaught exception, closing connection.\",\n    417                           exc_info=True)\n    418             # Close the socket on an uncaught exception from a user callback\n\n...........................................................................\nC:\\Anaconda2\\lib\\site-packages\\tornado\\stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    272         # Fast path when there are no active contexts.\n    273         def null_wrapper(*args, **kwargs):\n    274             try:\n    275                 current_state = _state.contexts\n    276                 _state.contexts = cap_contexts[0]\n--> 277                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    278             finally:\n    279                 _state.contexts = current_state\n    280         null_wrapper._wrapped = True\n    281         return null_wrapper\n\n...........................................................................\nC:\\Anaconda2\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\nC:\\Anaconda2\\lib\\site-packages\\ipykernel\\kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {u'allow_stdin': True, u'code': u\"%%time\\n\\ncv_scores = cross_val_score(cat, X_t...th n_jobs > 1, and locally this runs much faster\", u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 4, 22, 6, 42, 47, 863000, tzinfo=tzutc()), u'msg_id': u'26D25904CA9D40D086BB07E192AE7CB8', u'msg_type': u'execute_request', u'session': u'B79998034CA04350A3C2C7605EF52F93', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'26D25904CA9D40D086BB07E192AE7CB8', 'msg_type': u'execute_request', 'parent_header': {}})\n    230             self.log.warn(\"Unknown message type: %r\", msg_type)\n    231         else:\n    232             self.log.debug(\"%s: %s\", msg_type, msg)\n    233             self.pre_handler_hook()\n    234             try:\n--> 235                 handler(stream, idents, msg)\n        handler = <bound method IPythonKernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = ['B79998034CA04350A3C2C7605EF52F93']\n        msg = {'buffers': [], 'content': {u'allow_stdin': True, u'code': u\"%%time\\n\\ncv_scores = cross_val_score(cat, X_t...th n_jobs > 1, and locally this runs much faster\", u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 4, 22, 6, 42, 47, 863000, tzinfo=tzutc()), u'msg_id': u'26D25904CA9D40D086BB07E192AE7CB8', u'msg_type': u'execute_request', u'session': u'B79998034CA04350A3C2C7605EF52F93', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'26D25904CA9D40D086BB07E192AE7CB8', 'msg_type': u'execute_request', 'parent_header': {}}\n    236             except Exception:\n    237                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    238             finally:\n    239                 self.post_handler_hook()\n\n...........................................................................\nC:\\Anaconda2\\lib\\site-packages\\ipykernel\\kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=['B79998034CA04350A3C2C7605EF52F93'], parent={'buffers': [], 'content': {u'allow_stdin': True, u'code': u\"%%time\\n\\ncv_scores = cross_val_score(cat, X_t...th n_jobs > 1, and locally this runs much faster\", u'silent': False, u'stop_on_error': True, u'store_history': True, u'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 4, 22, 6, 42, 47, 863000, tzinfo=tzutc()), u'msg_id': u'26D25904CA9D40D086BB07E192AE7CB8', u'msg_type': u'execute_request', u'session': u'B79998034CA04350A3C2C7605EF52F93', u'username': u'username', u'version': u'5.0'}, 'metadata': {}, 'msg_id': u'26D25904CA9D40D086BB07E192AE7CB8', 'msg_type': u'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\nC:\\Anaconda2\\lib\\site-packages\\ipykernel\\ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code=u\"%%time\\n\\ncv_scores = cross_val_score(cat, X_t...th n_jobs > 1, and locally this runs much faster\", silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    191 \n    192         self._forward_input(allow_stdin)\n    193 \n    194         reply_content = {}\n    195         try:\n--> 196             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = u\"%%time\\n\\ncv_scores = cross_val_score(cat, X_t...th n_jobs > 1, and locally this runs much faster\"\n        store_history = True\n        silent = False\n    197         finally:\n    198             self._restore_input()\n    199 \n    200         if res.error_before_exec is not None:\n\n...........................................................................\nC:\\Anaconda2\\lib\\site-packages\\ipykernel\\zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=(u\"%%time\\n\\ncv_scores = cross_val_score(cat, X_t...th n_jobs > 1, and locally this runs much faster\",), **kwargs={'silent': False, 'store_history': True})\n    528             )\n    529         self.payload_manager.write_payload(payload)\n    530 \n    531     def run_cell(self, *args, **kwargs):\n    532         self._last_traceback = None\n--> 533         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = (u\"%%time\\n\\ncv_scores = cross_val_score(cat, X_t...th n_jobs > 1, and locally this runs much faster\",)\n        kwargs = {'silent': False, 'store_history': True}\n    534 \n    535     def _showtraceback(self, etype, evalue, stb):\n    536         # try to preserve ordering of tracebacks and print statements\n    537         sys.stdout.flush()\n\n...........................................................................\nC:\\Anaconda2\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell=u\"%%time\\n\\ncv_scores = cross_val_score(cat, X_t...th n_jobs > 1, and locally this runs much faster\", store_history=True, silent=False, shell_futures=True)\n   2712                 self.displayhook.exec_result = result\n   2713 \n   2714                 # Execute the user code\n   2715                 interactivity = \"none\" if silent else self.ast_node_interactivity\n   2716                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2717                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler instance>\n   2718                 \n   2719                 self.last_execution_succeeded = not has_raised\n   2720 \n   2721                 # Reset this so later displayed values do not modify the\n\n...........................................................................\nC:\\Anaconda2\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Expr object>], cell_name='<ipython-input-156-855cb4505899>', interactivity='last', compiler=<IPython.core.compilerop.CachingCompiler instance>, result=<ExecutionResult object at 46e86940, execution_c..._before_exec=None error_in_exec=None result=None>)\n   2822                     return True\n   2823 \n   2824             for i, node in enumerate(to_run_interactive):\n   2825                 mod = ast.Interactive([node])\n   2826                 code = compiler(mod, cell_name, \"single\")\n-> 2827                 if self.run_code(code, result):\n        self.run_code = <bound method ZMQInteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0000000019441E30, file \"<ipython-input-156-855cb4505899>\", line 1>\n        result = <ExecutionResult object at 46e86940, execution_c..._before_exec=None error_in_exec=None result=None>\n   2828                     return True\n   2829 \n   2830             # Flush softspace\n   2831             if softspace(sys.stdout, 0):\n\n...........................................................................\nC:\\Anaconda2\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0000000019441E30, file \"<ipython-input-156-855cb4505899>\", line 1>, result=<ExecutionResult object at 46e86940, execution_c..._before_exec=None error_in_exec=None result=None>)\n   2876         outflag = 1  # happens in more places, so it's easier as default\n   2877         try:\n   2878             try:\n   2879                 self.hooks.pre_run_code_hook()\n   2880                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2881                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0000000019441E30, file \"<ipython-input-156-855cb4505899>\", line 1>\n        self.user_global_ns = {'CatBoostClassifier': <class 'catboost.core.CatBoostClassifier'>, 'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'Counter': <class 'collections.Counter'>, 'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', u\"import pickle\\nimport numpy as np\\nimport pand...tlib import pyplot as plt\\nimport seaborn as sns\", u\"# \\u0437\\u0430\\u0433\\u0440\\u0443\\u0437\\u0438\\u...438\\ntrain_df = train_df.sort_values(by='time1')\", u'# \\u043f\\u0440\\u0438\\u0432\\u0435\\u0434\\u0435\\u... sites_dict_df.shape[0])\\n\\nsites_dict_df.head()', u\"# \\u043d\\u0430\\u0448\\u0430 \\u0446\\u0435\\u043b\\...]\\nX_test_sparse = full_sites_sparse[idx_split:]\", u'from sklearn.model_selection import train_test_split, GridSearchCV', u\"def get_auc_lr_valid(X, y, C=1.0, ratio = 0.9,... \\n    return roc_auc_score(y_valid, valid_pred)\", u'get_auc_lr_valid(X_train_sparse, y_train, ratio = 0.9)', u'# \\u0444\\u0443\\u043d\\u043a\\u0446\\u0438\\u044f \\...ted_df.to_csv(out_file, index_label=index_label)', u'new_feat_train = pd.DataFrame(index=train_df.i...ew_feat_test = pd.DataFrame(index=test_df.index)', u\"new_feat_train['alice_tminutes'] = train_df['t... >= 954 and ts.hour*60+ts.minute <=1100) else 0)\", u\"X_train_sparse_alicemin = csr_matrix(hstack([X..._test['alice_tminutes'].values.reshape(-1, 1)]))\", u'get_auc_lr_valid(X_train_sparse_alicemin, y_train)', u\"new_feat_train['alice_tminutes2'] = train_df['...e >= 548 and ts.hour*60+ts.minute <=559) else 0)\", u\"X_train_sparse_alicemin2 = csr_matrix(hstack([...test['alice_tminutes2'].values.reshape(-1, 1)]))\", u'get_auc_lr_valid(X_train_sparse_alicemin, y_train)', u'get_auc_lr_valid(X_train_sparse_alicemin2, y_train)', u\"new_feat_train['day0'] = train_df['time1'].app...'].apply(lambda ts: 1 if ts.weekday()==5 else 0)\", u\"X_train_sparse_alicemin2_dayall = csr_matrix(h...                                              ))\", u'get_auc_lr_valid(X_train_sparse_alicemin2_dayall, y_train)', ...], 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'LogisticRegressionCV': <class 'sklearn.linear_model.logistic.LogisticRegressionCV'>, 'OneHotEncoder': <class 'sklearn.preprocessing.data.OneHotEncoder'>, 'Out': {3:                                                 ...                         9zouxfza1h.s.ad6media.fr, 7: 0.96433761440091936, 12: 0.98650035989731588, 16: 0.98708576028395223, 19: 0.9910118176175845, 20: 0.9910118176175845, 23: 0.99119403526923877, 24: 0.99119403526923877, 32: 0.99287326517974273, 33:             site1               time1  site2    ...:22       0        24157  \n\n[5 rows x 22 columns], ...}, ...}\n        self.user_ns = {'CatBoostClassifier': <class 'catboost.core.CatBoostClassifier'>, 'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'Counter': <class 'collections.Counter'>, 'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', u\"import pickle\\nimport numpy as np\\nimport pand...tlib import pyplot as plt\\nimport seaborn as sns\", u\"# \\u0437\\u0430\\u0433\\u0440\\u0443\\u0437\\u0438\\u...438\\ntrain_df = train_df.sort_values(by='time1')\", u'# \\u043f\\u0440\\u0438\\u0432\\u0435\\u0434\\u0435\\u... sites_dict_df.shape[0])\\n\\nsites_dict_df.head()', u\"# \\u043d\\u0430\\u0448\\u0430 \\u0446\\u0435\\u043b\\...]\\nX_test_sparse = full_sites_sparse[idx_split:]\", u'from sklearn.model_selection import train_test_split, GridSearchCV', u\"def get_auc_lr_valid(X, y, C=1.0, ratio = 0.9,... \\n    return roc_auc_score(y_valid, valid_pred)\", u'get_auc_lr_valid(X_train_sparse, y_train, ratio = 0.9)', u'# \\u0444\\u0443\\u043d\\u043a\\u0446\\u0438\\u044f \\...ted_df.to_csv(out_file, index_label=index_label)', u'new_feat_train = pd.DataFrame(index=train_df.i...ew_feat_test = pd.DataFrame(index=test_df.index)', u\"new_feat_train['alice_tminutes'] = train_df['t... >= 954 and ts.hour*60+ts.minute <=1100) else 0)\", u\"X_train_sparse_alicemin = csr_matrix(hstack([X..._test['alice_tminutes'].values.reshape(-1, 1)]))\", u'get_auc_lr_valid(X_train_sparse_alicemin, y_train)', u\"new_feat_train['alice_tminutes2'] = train_df['...e >= 548 and ts.hour*60+ts.minute <=559) else 0)\", u\"X_train_sparse_alicemin2 = csr_matrix(hstack([...test['alice_tminutes2'].values.reshape(-1, 1)]))\", u'get_auc_lr_valid(X_train_sparse_alicemin, y_train)', u'get_auc_lr_valid(X_train_sparse_alicemin2, y_train)', u\"new_feat_train['day0'] = train_df['time1'].app...'].apply(lambda ts: 1 if ts.weekday()==5 else 0)\", u\"X_train_sparse_alicemin2_dayall = csr_matrix(h...                                              ))\", u'get_auc_lr_valid(X_train_sparse_alicemin2_dayall, y_train)', ...], 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'LogisticRegressionCV': <class 'sklearn.linear_model.logistic.LogisticRegressionCV'>, 'OneHotEncoder': <class 'sklearn.preprocessing.data.OneHotEncoder'>, 'Out': {3:                                                 ...                         9zouxfza1h.s.ad6media.fr, 7: 0.96433761440091936, 12: 0.98650035989731588, 16: 0.98708576028395223, 19: 0.9910118176175845, 20: 0.9910118176175845, 23: 0.99119403526923877, 24: 0.99119403526923877, 32: 0.99287326517974273, 33:             site1               time1  site2    ...:22       0        24157  \n\n[5 rows x 22 columns], ...}, ...}\n   2882             finally:\n   2883                 # Reset our crash handler in place\n   2884                 sys.excepthook = old_excepthook\n   2885         except SystemExit as e:\n\n...........................................................................\nC:\\Anaconda2\\Scripts\\<ipython-input-156-855cb4505899> in <module>()\n----> 1 \n      2 \n      3 \n      4 \n      5 \n      6 get_ipython().run_cell_magic(u'time', u'', u\"\\ncv_scores = cross_val_score(cat, X_train_tfidf_alicemin2_ids_dayall_mm_September, y_train, cv=time_split_3, \\n                            scoring='roc_auc', n_jobs=2) # hangs with n_jobs > 1, and locally this runs much faster\")\n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\nC:\\Anaconda2\\lib\\site-packages\\IPython\\core\\interactiveshell.py in run_cell_magic(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, magic_name=u'time', line=u'', cell=u\"\\ncv_scores = cross_val_score(cat, X_train_tfi...th n_jobs > 1, and locally this runs much faster\")\n   2110             # This will need to be updated if the internal calling logic gets\n   2111             # refactored, or else we'll be expanding the wrong variables.\n   2112             stack_depth = 2\n   2113             magic_arg_s = self.var_expand(line, stack_depth)\n   2114             with self.builtin_trap:\n-> 2115                 result = fn(magic_arg_s, cell)\n        result = undefined\n        fn = <bound method ExecutionMagics.time of <IPython.core.magics.execution.ExecutionMagics object>>\n        magic_arg_s = u''\n        cell = u\"\\ncv_scores = cross_val_score(cat, X_train_tfi...th n_jobs > 1, and locally this runs much faster\"\n   2116             return result\n   2117 \n   2118     def find_line_magic(self, magic_name):\n   2119         \"\"\"Find and return a line magic by name.\n\n...........................................................................\nC:\\Anaconda2\\Scripts\\<decorator-gen-60> in time(self=<IPython.core.magics.execution.ExecutionMagics object>, line=u'', cell=u\"\\ncv_scores = cross_val_score(cat, X_train_tfi...th n_jobs > 1, and locally this runs much faster\", local_ns=None)\n      1 \n----> 2 \n      3 \n      4 \n      5 \n      6 \n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\nC:\\Anaconda2\\lib\\site-packages\\IPython\\core\\magic.py in <lambda>(f=<function time>, *a=(<IPython.core.magics.execution.ExecutionMagics object>, u'', u\"\\ncv_scores = cross_val_score(cat, X_train_tfi...th n_jobs > 1, and locally this runs much faster\", None), **k={})\n    183     validate_type(magic_kind)\n    184 \n    185     # This is a closure to capture the magic_kind.  We could also use a class,\n    186     # but it's overkill for just that one bit of state.\n    187     def magic_deco(arg):\n--> 188         call = lambda f, *a, **k: f(*a, **k)\n        f = <function time>\n        a = (<IPython.core.magics.execution.ExecutionMagics object>, u'', u\"\\ncv_scores = cross_val_score(cat, X_train_tfi...th n_jobs > 1, and locally this runs much faster\", None)\n        k = {}\n    189 \n    190         if callable(arg):\n    191             # \"Naked\" decorator call (just @foo, no args)\n    192             func = arg\n\n...........................................................................\nC:\\Anaconda2\\lib\\site-packages\\IPython\\core\\magics\\execution.py in time(self=<IPython.core.magics.execution.ExecutionMagics object>, line=u'', cell=u\"\\ncv_scores = cross_val_score(cat, X_train_tfi...th n_jobs > 1, and locally this runs much faster\", local_ns=None)\n   1180             st = clock2()\n   1181             out = eval(code, glob, local_ns)\n   1182             end = clock2()\n   1183         else:\n   1184             st = clock2()\n-> 1185             exec(code, glob, local_ns)\n        code = <code object <module> at 0000000046E660B0, file \"<timed exec>\", line 2>\n        glob = {'CatBoostClassifier': <class 'catboost.core.CatBoostClassifier'>, 'CountVectorizer': <class 'sklearn.feature_extraction.text.CountVectorizer'>, 'Counter': <class 'collections.Counter'>, 'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', u\"import pickle\\nimport numpy as np\\nimport pand...tlib import pyplot as plt\\nimport seaborn as sns\", u\"# \\u0437\\u0430\\u0433\\u0440\\u0443\\u0437\\u0438\\u...438\\ntrain_df = train_df.sort_values(by='time1')\", u'# \\u043f\\u0440\\u0438\\u0432\\u0435\\u0434\\u0435\\u... sites_dict_df.shape[0])\\n\\nsites_dict_df.head()', u\"# \\u043d\\u0430\\u0448\\u0430 \\u0446\\u0435\\u043b\\...]\\nX_test_sparse = full_sites_sparse[idx_split:]\", u'from sklearn.model_selection import train_test_split, GridSearchCV', u\"def get_auc_lr_valid(X, y, C=1.0, ratio = 0.9,... \\n    return roc_auc_score(y_valid, valid_pred)\", u'get_auc_lr_valid(X_train_sparse, y_train, ratio = 0.9)', u'# \\u0444\\u0443\\u043d\\u043a\\u0446\\u0438\\u044f \\...ted_df.to_csv(out_file, index_label=index_label)', u'new_feat_train = pd.DataFrame(index=train_df.i...ew_feat_test = pd.DataFrame(index=test_df.index)', u\"new_feat_train['alice_tminutes'] = train_df['t... >= 954 and ts.hour*60+ts.minute <=1100) else 0)\", u\"X_train_sparse_alicemin = csr_matrix(hstack([X..._test['alice_tminutes'].values.reshape(-1, 1)]))\", u'get_auc_lr_valid(X_train_sparse_alicemin, y_train)', u\"new_feat_train['alice_tminutes2'] = train_df['...e >= 548 and ts.hour*60+ts.minute <=559) else 0)\", u\"X_train_sparse_alicemin2 = csr_matrix(hstack([...test['alice_tminutes2'].values.reshape(-1, 1)]))\", u'get_auc_lr_valid(X_train_sparse_alicemin, y_train)', u'get_auc_lr_valid(X_train_sparse_alicemin2, y_train)', u\"new_feat_train['day0'] = train_df['time1'].app...'].apply(lambda ts: 1 if ts.weekday()==5 else 0)\", u\"X_train_sparse_alicemin2_dayall = csr_matrix(h...                                              ))\", u'get_auc_lr_valid(X_train_sparse_alicemin2_dayall, y_train)', ...], 'LogisticRegression': <class 'sklearn.linear_model.logistic.LogisticRegression'>, 'LogisticRegressionCV': <class 'sklearn.linear_model.logistic.LogisticRegressionCV'>, 'OneHotEncoder': <class 'sklearn.preprocessing.data.OneHotEncoder'>, 'Out': {3:                                                 ...                         9zouxfza1h.s.ad6media.fr, 7: 0.96433761440091936, 12: 0.98650035989731588, 16: 0.98708576028395223, 19: 0.9910118176175845, 20: 0.9910118176175845, 23: 0.99119403526923877, 24: 0.99119403526923877, 32: 0.99287326517974273, 33:             site1               time1  site2    ...:22       0        24157  \n\n[5 rows x 22 columns], ...}, ...}\n        local_ns = None\n   1186             end = clock2()\n   1187             out = None\n   1188         wall_end = wtime()\n   1189         # Compute actual times and report\n\n...........................................................................\nC:\\Anaconda2\\Scripts\\<timed exec> in <module>()\n      1 \n      2 \n----> 3 \n      4 \n      5 \n      6 \n      7 \n      8 \n      9 \n     10 \n\n...........................................................................\nC:\\Anaconda2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in cross_val_score(estimator=<catboost.core.CatBoostClassifier object>, X=<253561x148381 sparse matrix of type '<type 'num... stored elements in Compressed Sparse Row format>, y=session_id\n21669     0\n54843     0\n77292     0\n1...2    0\nName: target, Length: 253561, dtype: int64, groups=None, scoring='roc_auc', cv=TimeSeriesSplit(n_splits=3), n_jobs=2, verbose=0, fit_params=None, pre_dispatch='2*n_jobs')\n    135     parallel = Parallel(n_jobs=n_jobs, verbose=verbose,\n    136                         pre_dispatch=pre_dispatch)\n    137     scores = parallel(delayed(_fit_and_score)(clone(estimator), X, y, scorer,\n    138                                               train, test, verbose, None,\n    139                                               fit_params)\n--> 140                       for train, test in cv_iter)\n        cv_iter = [(array([    0,     1,     2, ..., 63388, 63389, 63390]), array([ 63391,  63392,  63393, ..., 126778, 126779, 126780])), (array([     0,      1,      2, ..., 126778, 126779, 126780]), array([126781, 126782, 126783, ..., 190168, 190169, 190170])), (array([     0,      1,      2, ..., 190168, 190169, 190170]), array([190171, 190172, 190173, ..., 253558, 253559, 253560]))]\n    141     return np.array(scores)[:, 0]\n    142 \n    143 \n    144 def _fit_and_score(estimator, X, y, scorer, train, test, verbose,\n\n...........................................................................\nC:\\Anaconda2\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=Parallel(n_jobs=2), iterable=<generator object <genexpr>>)\n    763             if pre_dispatch == \"all\" or n_jobs == 1:\n    764                 # The iterable was consumed all at once by the above for loop.\n    765                 # No need to wait for async callbacks to trigger to\n    766                 # consumption.\n    767                 self._iterating = False\n--> 768             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=2)>\n    769             # Make sure that we get a last message telling us we are done\n    770             elapsed_time = time.time() - self._start_time\n    771             self._print('Done %3i out of %3i | elapsed: %s finished',\n    772                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nCatboostError                                      Sun Apr 22 11:43:49 2018\nPID: 17532                           Python 2.7.13: C:\\Anaconda2\\python.exe\n...........................................................................\nC:\\Anaconda2\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (<catboost.core.CatBoostClassifier object>, <253561x148381 sparse matrix of type '<type 'num... stored elements in Compressed Sparse Row format>, session_id\n21669     0\n54843     0\n77292     0\n1...2    0\nName: target, Length: 253561, dtype: int64, make_scorer(roc_auc_score, needs_threshold=True), array([    0,     1,     2, ..., 63388, 63389, 63390]), array([ 63391,  63392,  63393, ..., 126778, 126779, 126780]), 0, None, None)\n        kwargs = {}\n        self.items = [(<function _fit_and_score>, (<catboost.core.CatBoostClassifier object>, <253561x148381 sparse matrix of type '<type 'num... stored elements in Compressed Sparse Row format>, session_id\n21669     0\n54843     0\n77292     0\n1...2    0\nName: target, Length: 253561, dtype: int64, make_scorer(roc_auc_score, needs_threshold=True), array([    0,     1,     2, ..., 63388, 63389, 63390]), array([ 63391,  63392,  63393, ..., 126778, 126779, 126780]), 0, None, None), {})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\nC:\\Anaconda2\\lib\\site-packages\\sklearn\\model_selection\\_validation.py in _fit_and_score(estimator=<catboost.core.CatBoostClassifier object>, X=<253561x148381 sparse matrix of type '<type 'num... stored elements in Compressed Sparse Row format>, y=session_id\n21669     0\n54843     0\n77292     0\n1...2    0\nName: target, Length: 253561, dtype: int64, scorer=make_scorer(roc_auc_score, needs_threshold=True), train=array([    0,     1,     2, ..., 63388, 63389, 63390]), test=array([ 63391,  63392,  63393, ..., 126778, 126779, 126780]), verbose=0, parameters=None, fit_params={}, return_train_score=False, return_parameters=False, return_n_test_samples=False, return_times=False, error_score='raise')\n    233 \n    234     try:\n    235         if y_train is None:\n    236             estimator.fit(X_train, **fit_params)\n    237         else:\n--> 238             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method CatBoostClassifier.fit of <catboost.core.CatBoostClassifier object>>\n        X_train = <63391x148381 sparse matrix of type '<type 'nump... stored elements in Compressed Sparse Row format>\n        y_train = session_id\n21669     0\n54843     0\n77292     0\n1...24    0\nName: target, Length: 63391, dtype: int64\n        fit_params = {}\n    239 \n    240     except Exception as e:\n    241         # Note fit time as time until error\n    242         fit_time = time.time() - start_time\n\n...........................................................................\nC:\\Anaconda2\\lib\\site-packages\\catboost\\core.py in fit(self=<catboost.core.CatBoostClassifier object>, X=<63391x148381 sparse matrix of type '<type 'nump... stored elements in Compressed Sparse Row format>, y=session_id\n21669     0\n54843     0\n77292     0\n1...24    0\nName: target, Length: 63391, dtype: int64, cat_features=None, sample_weight=None, baseline=None, use_best_model=None, eval_set=None, verbose=None, logging_level=None, plot=False, column_description=None, verbose_eval=None)\n   1671 \n   1672         Returns\n   1673         -------\n   1674         model : CatBoost\n   1675         \"\"\"\n-> 1676         self._fit(X, y, cat_features, None, sample_weight, None, None, None, baseline, use_best_model, eval_set, verbose, logging_level, plot, column_description, verbose_eval)\n        self._fit = <bound method CatBoostClassifier._fit of <catboost.core.CatBoostClassifier object>>\n        X = <63391x148381 sparse matrix of type '<type 'nump... stored elements in Compressed Sparse Row format>\n        y = session_id\n21669     0\n54843     0\n77292     0\n1...24    0\nName: target, Length: 63391, dtype: int64\n        cat_features = None\n        sample_weight = None\n        baseline = None\n        use_best_model = None\n        eval_set = None\n        verbose = None\n        logging_level = None\n        plot = False\n        column_description = None\n        verbose_eval = None\n   1677         return self\n   1678 \n   1679     def predict(self, data, prediction_type='Class', ntree_start=0, ntree_end=0, thread_count=-1, verbose=None):\n   1680         \"\"\"\n\n...........................................................................\nC:\\Anaconda2\\lib\\site-packages\\catboost\\core.py in _fit(self=<catboost.core.CatBoostClassifier object>, X=<63391x148381 sparse matrix of type '<type 'nump... stored elements in Compressed Sparse Row format>, y=session_id\n21669     0\n54843     0\n77292     0\n1...24    0\nName: target, Length: 63391, dtype: int64, cat_features=None, pairs=None, sample_weight=None, group_id=None, subgroup_id=None, pairs_weight=None, baseline=None, use_best_model=None, eval_set=None, verbose=None, logging_level=None, plot=False, column_description=None, verbose_eval=None)\n    747         if logging_level is not None:\n    748             params['logging_level'] = logging_level\n    749         if use_best_model is not None:\n    750             params['use_best_model'] = use_best_model\n    751 \n--> 752         train_pool = _build_train_pool(X, y, cat_features, pairs, sample_weight, group_id, subgroup_id, pairs_weight, baseline, column_description)\n        train_pool = undefined\n        X = <63391x148381 sparse matrix of type '<type 'nump... stored elements in Compressed Sparse Row format>\n        y = session_id\n21669     0\n54843     0\n77292     0\n1...24    0\nName: target, Length: 63391, dtype: int64\n        cat_features = None\n        pairs = None\n        sample_weight = None\n        group_id = None\n        subgroup_id = None\n        pairs_weight = None\n        baseline = None\n        column_description = None\n    753         if train_pool.is_empty_:\n    754             raise CatboostError(\"X is empty.\")\n    755 \n    756         if column_description is not None and not isinstance(X, STRING_TYPES) and not isinstance(eval_set, STRING_TYPES):\n\n...........................................................................\nC:\\Anaconda2\\lib\\site-packages\\catboost\\core.py in _build_train_pool(X=<63391x148381 sparse matrix of type '<type 'nump... stored elements in Compressed Sparse Row format>, y=session_id\n21669     0\n54843     0\n77292     0\n1...24    0\nName: target, Length: 63391, dtype: int64, cat_features=None, pairs=None, sample_weight=None, group_id=None, subgroup_id=None, pairs_weight=None, baseline=None, column_description=None)\n    549             train_pool = Pool(data=X, pairs=pairs, column_description=column_description)\n    550     else:\n    551         if y is None:\n    552             raise CatboostError(\"y has not initialized in fit(): X is not catboost.Pool object, y must be not None in fit().\")\n    553         train_pool = Pool(X, y, cat_features=cat_features, pairs=pairs, weight=sample_weight, group_id=group_id,\n--> 554                           subgroup_id=subgroup_id, pairs_weight=pairs_weight, baseline=baseline)\n        subgroup_id = None\n        pairs_weight = None\n        baseline = None\n    555     return train_pool\n    556 \n    557 \n    558 def _clear_training_files(train_dir):\n\n...........................................................................\nC:\\Anaconda2\\lib\\site-packages\\catboost\\core.py in __init__(self=<catboost.core.Pool object>, data=<63391x148381 sparse matrix of type '<type 'nump... stored elements in Compressed Sparse Row format>, label=session_id\n21669     0\n54843     0\n77292     0\n1...24    0\nName: target, Length: 63391, dtype: int64, cat_features=None, column_description=None, pairs=None, delimiter='\\t', has_header=False, weight=None, group_id=None, subgroup_id=None, pairs_weight=None, baseline=None, feature_names=None, thread_count=-1)\n    209             Thread count to read data from file.\n    210             Use only with reading data from file.\n    211             If -1, then the number of threads is set to the number of cores.\n    212         \"\"\"\n    213         if data is not None:\n--> 214             self._check_data_type(data)\n        self._check_data_type = <bound method Pool._check_data_type of <catboost.core.Pool object>>\n        data = <63391x148381 sparse matrix of type '<type 'nump... stored elements in Compressed Sparse Row format>\n    215             self._check_data_empty(data)\n    216             if pairs is not None and isinstance(data, STRING_TYPES) != isinstance(pairs, STRING_TYPES):\n    217                 raise CatboostError(\"Data and pairs should be the same types.\")\n    218             if isinstance(data, STRING_TYPES):\n\n...........................................................................\nC:\\Anaconda2\\lib\\site-packages\\catboost\\core.py in _check_data_type(self=<catboost.core.Pool object>, data=<63391x148381 sparse matrix of type '<type 'nump... stored elements in Compressed Sparse Row format>)\n    285     def _check_data_type(self, data):\n    286         \"\"\"\n    287         Check type of data.\n    288         \"\"\"\n    289         if not isinstance(data, (STRING_TYPES, ARRAY_TYPES)):\n--> 290             raise CatboostError(\"Invalid data type={}: data must be list(), np.ndarray(), DataFrame(), Series() or filename str().\".format(type(data)))\n        data = <63391x148381 sparse matrix of type '<type 'nump... stored elements in Compressed Sparse Row format>\n    291 \n    292     def _check_data_empty(self, data):\n    293         \"\"\"\n    294         Check data is not empty.\n\nCatboostError: Invalid data type=<class 'scipy.sparse.csr.csr_matrix'>: data must be list(), np.ndarray(), DataFrame(), Series() or filename str().\n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "cv_scores = cross_val_score(cat, X_train_tfidf_alicemin2_ids_dayall_mm_September, y_train, cv=time_split_3, \n",
    "                            scoring='roc_auc', n_jobs=2) # hangs with n_jobs > 1, and locally this runs much faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv_scores, cv_scores.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading https://files.pythonhosted.org/packages/4b/c4/57e246bc99e45c048f9805f2773e7369f0d30896d19fa089fa1794c7b246/xgboost-0.71.tar.gz (494kB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No files/directories in c:\\temp\\pip-build-7p3d2d\\xgboost\\pip-egg-info (from PKG-INFO)\n",
      "You are using pip version 9.0.3, however version 10.0.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pip\n",
      "  Downloading https://files.pythonhosted.org/packages/0f/74/ecd13431bcc456ed390b44c8a6e917c1820365cbebcb6a8974d1cd045ab4/pip-10.0.1-py2.py3-none-any.whl (1.3MB)\n",
      "Installing collected packages: pip\n",
      "  Found existing installation: pip 9.0.3\n",
      "    Uninstalling pip-9.0.3:\n",
      "      Successfully uninstalled pip-9.0.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\anaconda2\\lib\\site-packages\\pip\\basecommand.py\", line 215, in main\n",
      "  File \"c:\\anaconda2\\lib\\site-packages\\pip\\commands\\install.py\", line 342, in run\n",
      "  File \"c:\\anaconda2\\lib\\site-packages\\pip\\req\\req_set.py\", line 795, in install\n",
      "  File \"c:\\anaconda2\\lib\\site-packages\\pip\\req\\req_install.py\", line 767, in commit_uninstall\n",
      "  File \"c:\\anaconda2\\lib\\site-packages\\pip\\req\\req_uninstall.py\", line 142, in commit\n",
      "  File \"c:\\anaconda2\\lib\\site-packages\\pip\\_vendor\\retrying.py\", line 49, in wrapped_f\n",
      "    return Retrying(*dargs, **dkw).call(f, *args, **kw)\n",
      "  File \"c:\\anaconda2\\lib\\site-packages\\pip\\_vendor\\retrying.py\", line 212, in call\n",
      "    raise attempt.get()\n",
      "  File \"c:\\anaconda2\\lib\\site-packages\\pip\\_vendor\\retrying.py\", line 247, in get\n",
      "    six.reraise(self.value[0], self.value[1], self.value[2])\n",
      "  File \"c:\\anaconda2\\lib\\site-packages\\pip\\_vendor\\retrying.py\", line 200, in call\n",
      "    attempt = Attempt(fn(*args, **kwargs), attempt_number, False)\n",
      "  File \"c:\\anaconda2\\lib\\site-packages\\pip\\utils\\__init__.py\", line 102, in rmtree\n",
      "  File \"c:\\anaconda2\\lib\\shutil.py\", line 247, in rmtree\n",
      "    rmtree(fullname, ignore_errors, onerror)\n",
      "  File \"c:\\anaconda2\\lib\\shutil.py\", line 247, in rmtree\n",
      "    rmtree(fullname, ignore_errors, onerror)\n",
      "  File \"c:\\anaconda2\\lib\\shutil.py\", line 252, in rmtree\n",
      "    onerror(os.remove, fullname, sys.exc_info())\n",
      "  File \"c:\\anaconda2\\lib\\site-packages\\pip\\utils\\__init__.py\", line 114, in rmtree_errorhandler\n",
      "WindowsError: [Error 5] : 'c:\\\\temp\\\\pip-ojm97i-uninstall\\\\anaconda2\\\\scripts\\\\pip.exe'\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting catboost\n",
      "  Downloading https://files.pythonhosted.org/packages/14/46/8c07f889bdab1bce31ae7a30d08f8087dc68b37990e8760f719893c25bd6/catboost-0.8-cp27-none-win_amd64.whl (32.3MB)\n",
      "Requirement already satisfied: numpy in c:\\anaconda2\\lib\\site-packages (from catboost)\n",
      "Requirement already satisfied: six in c:\\anaconda2\\lib\\site-packages (from catboost)\n",
      "Requirement already satisfied: pandas in c:\\anaconda2\\lib\\site-packages (from catboost)\n",
      "Requirement already satisfied: python-dateutil in c:\\anaconda2\\lib\\site-packages (from pandas->catboost)\n",
      "Requirement already satisfied: pytz>=2011k in c:\\anaconda2\\lib\\site-packages (from pandas->catboost)\n",
      "Installing collected packages: catboost\n",
      "Successfully installed catboost-0.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using pip version 9.0.3, however version 10.0.1 is available.\n",
      "You should consider upgrading via the 'python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "!pip install catboost"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
